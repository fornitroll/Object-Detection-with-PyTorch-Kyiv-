{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Quantization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fornitroll/Object-Detection-with-PyTorch-Kyiv-/blob/master/PyTorch_Quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okhqb73zWWev",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MuBbPc1WgDe",
        "colab_type": "text"
      },
      "source": [
        "Quantization - is a process of mapping values from bigget set to the smaller one. \n",
        "In ML this process is done for 2 reason:\n",
        "1. Lower model size. In most cases size of the model decrese in 2-6 times.\n",
        "2. Make model to inference faster on CPU, because of limmiting amount of data, and more simpler and faster operations on int8.\n",
        "\n",
        "In our case we will be mapping values from float32(-3.4E+38 to +3.4E+38) to the int8(-128 to +128). As you can see difference is quite big and that's means that we will get accuracy drops(but not always, sometimes small models can increase accuracy, some sort of regularization)\n",
        "\n",
        "There are two ways of model quantization:\n",
        "1. Post-training quantization\n",
        "2. Quantization-aware training\n",
        "\n",
        "Today we will cover both of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgX05CneYie_",
        "colab_type": "text"
      },
      "source": [
        "## Post-training quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj8TzBfI3TXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jotONn6w3qvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqvU38ZA3rpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for real use please use installation with CUDA and CPP\n",
        "!pip install -v --no-cache-dir ./"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qobVLKkq5PMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrVLt9sKHFMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "from torchvision.models.resnet import Bottleneck, BasicBlock, ResNet, model_urls\n",
        "import torch.nn as nn\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "from torch.quantization import QuantStub, DeQuantStub, fuse_modules"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKMoZ5B3WPW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class QuantizableBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, groups=None, base_width=None, previous_dilation=None, norm_layer=None, dilation=None):\n",
        "        super(QuantizableBasicBlock, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels, momentum=0.1)\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels, momentum=0.1)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        # used to wrap some simple float operations like add, mul, relu, etc.\n",
        "        self.skip_add_relu = torch.nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.skip_add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        torch.quantization.fuse_modules(self, [['conv1', 'bn1', 'relu'],\n",
        "                                               ['conv2', 'bn2']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "class QuantizableBottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    __constants__ = ['downsample']\n",
        "\n",
        "    def __init__(self, in_channels, channels, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None, **kwargs):\n",
        "        super(QuantizableBottleneck, self).__init__()\n",
        "\n",
        "        width = make_divisible(int(channels * (base_width / 64.)) * groups, 8)\n",
        "        self.conv1 = nn.Conv2d(in_channels, width, 1, stride=stride, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(width, momentum=0.1)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(width, width, 3, stride=stride, padding=1, groups=groups, dilation=dilation, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(width, momentum=0.1)\n",
        "\n",
        "        out_channels = make_divisible(channels * self.expansion, 8)\n",
        "        self.conv3 = nn.Conv2d(width, out_channels, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels, momentum=0.1)\n",
        "\n",
        "        self.relu1 = nn.ReLU(inplace=False)\n",
        "        self.relu2 = nn.ReLU(inplace=False)\n",
        "\n",
        "        self.skip_add_relu = nn.quantized.FloatFunctional()\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.skip_add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        torch.quantization.fuse_modules(self, [['conv1', 'bn1', 'relu1'],\n",
        "                                               ['conv2', 'bn2', 'relu2'],\n",
        "                                               ['conv3', 'bn3']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "class QuantizableResNet(ResNet):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableResNet, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "        self.relu = nn.ReLU(inplace=False)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self._forward_impl(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "    def fuse_model(self):\n",
        "        # fuse first layers\n",
        "        fuse_modules(self, ['conv1', 'bn1', 'relu'], inplace=True)\n",
        "        for m in self.modules():\n",
        "            if type(m) == QuantizableBottleneck or type(m) == QuantizableBasicBlock:\n",
        "                m.fuse_model()\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = QuantizableResNet(block, layers, **kwargs)\n",
        "\n",
        "    if pretrained:\n",
        "        model_url = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'\n",
        "        state_dict = load_state_dict_from_url(model_url,\n",
        "                                              progress=progress)\n",
        "\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', QuantizableBasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIIqEgKyps_V",
        "colab_type": "text"
      },
      "source": [
        "#### Fusing\n",
        "Fusing is process to replace time-consuming operations with more faster but freezed or approximated. Currently we use fuze only on convolution and batchnorm layers.\n",
        "\n",
        "You can read more about it here:\n",
        "http://learnml.today/speeding-up-model-with-fusing-batch-normalization-and-convolution-3\n",
        "\n",
        "So what we do above is added `fuse_model` method to fuse layers and replaces residual operation with `nn.quantized.FloatFunctional()`.\n",
        "\n",
        "Also we set all `ReLU(inplace=False)`, this needed for quantizitaion module. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roZlNwumqcx4",
        "colab_type": "text"
      },
      "source": [
        "Now let's try quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaRhNYbYIYpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MeanMetric(object):\n",
        "    \"\"\"Computes accuracy mean\"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.clear()\n",
        "\n",
        "    def clear(self):\n",
        "        self.val = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val):\n",
        "        self.val += val\n",
        "        self.count += 1\n",
        "\n",
        "    def __str__(self):\n",
        "        return f'{self.name}={round(self.val/self.count, 2)}'\n",
        "\n",
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size = ('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "    return size\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "def evaluate(model, criterion, data_loader, device, eval_steps=10):\n",
        "    model.eval().to(device)\n",
        "    top1 = MeanMetric('Acc@1')\n",
        "    top5 = MeanMetric('Acc@5')\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        for image, target in data_loader:\n",
        "            image, target = image.to(device), target.to(device)\n",
        "            output = model(image)\n",
        "            loss = criterion(output, target)\n",
        "            cnt += 1\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            top1.update(acc1[0].detach().cpu().item())\n",
        "            top5.update(acc5[0].detach().cpu().item())\n",
        "            if cnt >= eval_steps:\n",
        "                 return top1, top5\n",
        "\n",
        "    return top1, top5\n",
        "\n",
        "def load_model(model_file, classes=100):\n",
        "    model = resnet18(num_classes=classes)\n",
        "    state_dict = torch.load(model_file)\n",
        "    model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSC5S6aGGAhU",
        "colab_type": "code",
        "outputId": "fe3eb703-90b3-41a6-ad8e-a27e581d804b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def get_loaders(data_path, batch_size=8):\n",
        "\n",
        "    traindir = os.path.join(data_path, 'train')\n",
        "    valdir = os.path.join(data_path, 'val')\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "    \n",
        "    # We want to say how we happy to know that in 21st cetury people still \n",
        "    # blocking other people from getting data to learn. That definitelly what \n",
        "    # will make our world better. Our thanks goes to the guys from ImageNet\n",
        "    # who locked down public access to the ImageNet Dataset.\n",
        "\n",
        "    dataset = torchvision.datasets.CIFAR100(\n",
        "        './cifar100',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n",
        "    )\n",
        "        \n",
        "    dataset_test = torchvision.datasets.CIFAR100(\n",
        "        './cifar100',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n",
        "    )\n",
        "\n",
        "    train_sampler = torch.utils.data.RandomSampler(dataset)\n",
        "    test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=batch_size,\n",
        "        sampler=train_sampler)\n",
        "\n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "        dataset_test, batch_size=batch_size,\n",
        "        sampler=test_sampler)\n",
        "\n",
        "    return data_loader, data_loader_test\n",
        "\n",
        "train, test = get_loaders('imagenet_1k')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar100/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "169009152it [00:04, 37868417.69it/s]                               \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./cifar100/cifar-100-python.tar.gz to ./cifar100\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wIHBohkIJB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_one_epoch(model, criterion, optimizer, data_loader, device, log_steps=30):\n",
        "    model.train().to(device)\n",
        "    top1 = MeanMetric('Acc@1')\n",
        "    top5 = MeanMetric('Acc@5')\n",
        "    avgloss = MeanMetric('Loss')\n",
        "\n",
        "    cnt = 0\n",
        "    for image, target in data_loader:\n",
        "        start_time = time.time()\n",
        "        cnt += 1\n",
        "        \n",
        "        image, target = image.to(device), target.to(device)\n",
        "        output = model(image)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0].detach().cpu().item())\n",
        "        top5.update(acc5[0].detach().cpu().item())\n",
        "        avgloss.update(loss.detach().cpu().item())\n",
        "\n",
        "        if cnt % log_steps == 0 and cnt:\n",
        "            print(f'Training {cnt}: {avgloss} {top1} {top5}')\n",
        "            \n",
        "            avgloss.clear()\n",
        "            top1.clear()\n",
        "            top5.clear()\n",
        "\n",
        "                \n",
        "    top1, top5 = evaluate(model, criterion, data_loader, device)\n",
        "    print(f'Full imagenet train set: {top1} {top5}')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfVfbsWgpTuz",
        "colab_type": "text"
      },
      "source": [
        "Let's train a bit our model on CIFAR100 dataset to get some basic accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvQwvtbOLr9R",
        "colab_type": "code",
        "outputId": "a40dfc9a-d773-435e-830f-9544d92e6d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = resnet18(pretrained=False, num_classes=100).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=5e-4)\n",
        "\n",
        "\n",
        "for i in range(20):\n",
        "    print(f'Epoch: {i} ######################################################')\n",
        "    model = train_one_epoch(model, criterion, optimizer, train, device='cuda')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 ######################################################\n",
            "Training 30: Loss=4.9 Acc@1=0.83 Acc@5=5.0\n",
            "Training 60: Loss=4.82 Acc@1=2.08 Acc@5=7.92\n",
            "Training 90: Loss=4.68 Acc@1=2.5 Acc@5=11.67\n",
            "Training 120: Loss=4.68 Acc@1=0.83 Acc@5=9.58\n",
            "Training 150: Loss=4.64 Acc@1=0.42 Acc@5=9.17\n",
            "Training 180: Loss=4.63 Acc@1=3.75 Acc@5=10.83\n",
            "Training 210: Loss=4.67 Acc@1=2.92 Acc@5=11.25\n",
            "Training 240: Loss=4.62 Acc@1=3.75 Acc@5=10.42\n",
            "Training 270: Loss=4.53 Acc@1=3.75 Acc@5=11.25\n",
            "Training 300: Loss=4.39 Acc@1=5.42 Acc@5=16.25\n",
            "Training 330: Loss=4.51 Acc@1=3.33 Acc@5=15.42\n",
            "Training 360: Loss=4.43 Acc@1=4.17 Acc@5=17.08\n",
            "Training 390: Loss=4.55 Acc@1=4.17 Acc@5=12.92\n",
            "Training 420: Loss=4.47 Acc@1=5.42 Acc@5=17.08\n",
            "Training 450: Loss=4.41 Acc@1=4.58 Acc@5=16.67\n",
            "Training 480: Loss=4.43 Acc@1=4.17 Acc@5=15.83\n",
            "Training 510: Loss=4.32 Acc@1=5.42 Acc@5=21.25\n",
            "Training 540: Loss=4.38 Acc@1=4.58 Acc@5=18.33\n",
            "Training 570: Loss=4.35 Acc@1=4.17 Acc@5=18.33\n",
            "Training 600: Loss=4.41 Acc@1=3.33 Acc@5=13.75\n",
            "Training 630: Loss=4.35 Acc@1=4.17 Acc@5=17.5\n",
            "Training 660: Loss=4.35 Acc@1=5.83 Acc@5=19.58\n",
            "Training 690: Loss=4.37 Acc@1=4.58 Acc@5=16.67\n",
            "Training 720: Loss=4.36 Acc@1=7.5 Acc@5=20.0\n",
            "Training 750: Loss=4.19 Acc@1=5.42 Acc@5=21.67\n",
            "Training 780: Loss=4.33 Acc@1=2.08 Acc@5=19.17\n",
            "Training 810: Loss=4.28 Acc@1=4.58 Acc@5=22.5\n",
            "Training 840: Loss=4.33 Acc@1=4.58 Acc@5=15.42\n",
            "Training 870: Loss=4.24 Acc@1=5.83 Acc@5=20.83\n",
            "Training 900: Loss=4.25 Acc@1=5.42 Acc@5=20.0\n",
            "Training 930: Loss=4.22 Acc@1=7.5 Acc@5=18.33\n",
            "Training 960: Loss=4.25 Acc@1=8.33 Acc@5=18.75\n",
            "Training 990: Loss=4.12 Acc@1=8.33 Acc@5=26.25\n",
            "Training 1020: Loss=4.1 Acc@1=5.42 Acc@5=28.75\n",
            "Training 1050: Loss=4.26 Acc@1=5.83 Acc@5=22.5\n",
            "Training 1080: Loss=4.19 Acc@1=5.42 Acc@5=21.67\n",
            "Training 1110: Loss=4.2 Acc@1=5.0 Acc@5=25.0\n",
            "Training 1140: Loss=4.22 Acc@1=5.83 Acc@5=22.08\n",
            "Training 1170: Loss=4.26 Acc@1=7.5 Acc@5=20.42\n",
            "Training 1200: Loss=4.16 Acc@1=7.08 Acc@5=20.0\n",
            "Training 1230: Loss=4.2 Acc@1=9.58 Acc@5=25.0\n",
            "Training 1260: Loss=4.19 Acc@1=6.25 Acc@5=22.5\n",
            "Training 1290: Loss=4.29 Acc@1=6.25 Acc@5=20.42\n",
            "Training 1320: Loss=4.21 Acc@1=6.67 Acc@5=23.33\n",
            "Training 1350: Loss=4.18 Acc@1=5.0 Acc@5=20.0\n",
            "Training 1380: Loss=4.11 Acc@1=8.75 Acc@5=26.25\n",
            "Training 1410: Loss=4.1 Acc@1=9.17 Acc@5=24.17\n",
            "Training 1440: Loss=4.12 Acc@1=7.08 Acc@5=22.08\n",
            "Training 1470: Loss=4.21 Acc@1=5.42 Acc@5=22.92\n",
            "Training 1500: Loss=4.23 Acc@1=6.67 Acc@5=21.67\n",
            "Training 1530: Loss=4.14 Acc@1=7.5 Acc@5=25.0\n",
            "Training 1560: Loss=4.11 Acc@1=8.75 Acc@5=24.58\n",
            "Training 1590: Loss=4.18 Acc@1=3.75 Acc@5=21.25\n",
            "Training 1620: Loss=4.21 Acc@1=6.25 Acc@5=19.17\n",
            "Training 1650: Loss=4.15 Acc@1=7.92 Acc@5=25.0\n",
            "Training 1680: Loss=4.03 Acc@1=10.0 Acc@5=27.08\n",
            "Training 1710: Loss=4.12 Acc@1=5.83 Acc@5=24.17\n",
            "Training 1740: Loss=4.18 Acc@1=7.5 Acc@5=24.17\n",
            "Training 1770: Loss=4.17 Acc@1=8.33 Acc@5=24.17\n",
            "Training 1800: Loss=4.0 Acc@1=6.25 Acc@5=30.0\n",
            "Training 1830: Loss=4.01 Acc@1=10.0 Acc@5=29.58\n",
            "Training 1860: Loss=3.99 Acc@1=7.08 Acc@5=28.75\n",
            "Training 1890: Loss=4.05 Acc@1=9.58 Acc@5=29.17\n",
            "Training 1920: Loss=4.02 Acc@1=10.83 Acc@5=28.75\n",
            "Training 1950: Loss=3.93 Acc@1=10.0 Acc@5=30.42\n",
            "Training 1980: Loss=3.91 Acc@1=7.5 Acc@5=31.25\n",
            "Training 2010: Loss=4.08 Acc@1=10.83 Acc@5=30.42\n",
            "Training 2040: Loss=3.99 Acc@1=9.58 Acc@5=30.42\n",
            "Training 2070: Loss=3.99 Acc@1=10.0 Acc@5=30.42\n",
            "Training 2100: Loss=4.15 Acc@1=8.75 Acc@5=20.83\n",
            "Training 2130: Loss=3.85 Acc@1=11.25 Acc@5=35.42\n",
            "Training 2160: Loss=4.05 Acc@1=7.92 Acc@5=27.5\n",
            "Training 2190: Loss=4.11 Acc@1=10.0 Acc@5=24.58\n",
            "Training 2220: Loss=3.87 Acc@1=10.0 Acc@5=32.92\n",
            "Training 2250: Loss=3.99 Acc@1=9.58 Acc@5=27.08\n",
            "Training 2280: Loss=4.09 Acc@1=7.5 Acc@5=23.33\n",
            "Training 2310: Loss=3.94 Acc@1=10.0 Acc@5=30.83\n",
            "Training 2340: Loss=3.9 Acc@1=9.17 Acc@5=33.75\n",
            "Training 2370: Loss=3.98 Acc@1=9.58 Acc@5=27.08\n",
            "Training 2400: Loss=3.9 Acc@1=11.25 Acc@5=30.83\n",
            "Training 2430: Loss=3.82 Acc@1=10.83 Acc@5=30.83\n",
            "Training 2460: Loss=3.94 Acc@1=8.75 Acc@5=28.33\n",
            "Training 2490: Loss=3.91 Acc@1=10.83 Acc@5=30.42\n",
            "Training 2520: Loss=3.9 Acc@1=8.75 Acc@5=33.33\n",
            "Training 2550: Loss=3.78 Acc@1=12.5 Acc@5=34.17\n",
            "Training 2580: Loss=3.93 Acc@1=8.75 Acc@5=29.17\n",
            "Training 2610: Loss=3.96 Acc@1=8.33 Acc@5=30.42\n",
            "Training 2640: Loss=3.94 Acc@1=11.25 Acc@5=32.5\n",
            "Training 2670: Loss=3.97 Acc@1=12.92 Acc@5=29.17\n",
            "Training 2700: Loss=3.84 Acc@1=10.42 Acc@5=32.92\n",
            "Training 2730: Loss=3.93 Acc@1=10.42 Acc@5=31.25\n",
            "Training 2760: Loss=3.88 Acc@1=11.67 Acc@5=29.58\n",
            "Training 2790: Loss=3.84 Acc@1=11.25 Acc@5=31.25\n",
            "Training 2820: Loss=4.14 Acc@1=8.75 Acc@5=23.33\n",
            "Training 2850: Loss=3.76 Acc@1=13.75 Acc@5=37.5\n",
            "Training 2880: Loss=3.91 Acc@1=8.75 Acc@5=27.92\n",
            "Training 2910: Loss=3.97 Acc@1=8.75 Acc@5=29.58\n",
            "Training 2940: Loss=3.86 Acc@1=10.42 Acc@5=29.58\n",
            "Training 2970: Loss=3.84 Acc@1=9.17 Acc@5=34.17\n",
            "Training 3000: Loss=3.94 Acc@1=10.83 Acc@5=33.75\n",
            "Training 3030: Loss=3.76 Acc@1=14.58 Acc@5=31.67\n",
            "Training 3060: Loss=4.08 Acc@1=8.75 Acc@5=25.0\n",
            "Training 3090: Loss=3.85 Acc@1=11.67 Acc@5=29.58\n",
            "Training 3120: Loss=3.98 Acc@1=8.33 Acc@5=25.42\n",
            "Training 3150: Loss=3.83 Acc@1=12.92 Acc@5=37.5\n",
            "Training 3180: Loss=3.87 Acc@1=13.75 Acc@5=33.75\n",
            "Training 3210: Loss=3.87 Acc@1=11.25 Acc@5=32.08\n",
            "Training 3240: Loss=3.92 Acc@1=10.42 Acc@5=28.75\n",
            "Training 3270: Loss=3.89 Acc@1=12.08 Acc@5=31.67\n",
            "Training 3300: Loss=3.8 Acc@1=12.08 Acc@5=35.83\n",
            "Training 3330: Loss=4.01 Acc@1=9.17 Acc@5=26.25\n",
            "Training 3360: Loss=3.88 Acc@1=7.92 Acc@5=30.83\n",
            "Training 3390: Loss=3.82 Acc@1=11.67 Acc@5=36.25\n",
            "Training 3420: Loss=3.67 Acc@1=14.17 Acc@5=35.83\n",
            "Training 3450: Loss=3.9 Acc@1=10.42 Acc@5=31.25\n",
            "Training 3480: Loss=3.84 Acc@1=12.08 Acc@5=33.33\n",
            "Training 3510: Loss=3.81 Acc@1=9.58 Acc@5=36.67\n",
            "Training 3540: Loss=3.97 Acc@1=7.92 Acc@5=31.25\n",
            "Training 3570: Loss=3.74 Acc@1=10.42 Acc@5=36.67\n",
            "Training 3600: Loss=3.76 Acc@1=13.75 Acc@5=38.33\n",
            "Training 3630: Loss=3.85 Acc@1=10.83 Acc@5=31.67\n",
            "Training 3660: Loss=3.74 Acc@1=12.92 Acc@5=36.67\n",
            "Training 3690: Loss=3.79 Acc@1=10.42 Acc@5=32.92\n",
            "Training 3720: Loss=3.83 Acc@1=10.0 Acc@5=32.92\n",
            "Training 3750: Loss=3.77 Acc@1=14.58 Acc@5=34.17\n",
            "Training 3780: Loss=3.66 Acc@1=17.08 Acc@5=37.08\n",
            "Training 3810: Loss=3.71 Acc@1=14.17 Acc@5=35.42\n",
            "Training 3840: Loss=3.62 Acc@1=17.08 Acc@5=39.17\n",
            "Training 3870: Loss=3.75 Acc@1=13.33 Acc@5=30.83\n",
            "Training 3900: Loss=3.74 Acc@1=13.75 Acc@5=35.0\n",
            "Training 3930: Loss=3.8 Acc@1=12.5 Acc@5=35.0\n",
            "Training 3960: Loss=3.86 Acc@1=12.5 Acc@5=30.42\n",
            "Training 3990: Loss=3.74 Acc@1=14.58 Acc@5=34.17\n",
            "Training 4020: Loss=3.72 Acc@1=13.33 Acc@5=38.33\n",
            "Training 4050: Loss=3.76 Acc@1=12.5 Acc@5=33.33\n",
            "Training 4080: Loss=3.82 Acc@1=8.33 Acc@5=32.92\n",
            "Training 4110: Loss=3.77 Acc@1=14.58 Acc@5=35.0\n",
            "Training 4140: Loss=3.86 Acc@1=14.58 Acc@5=30.42\n",
            "Training 4170: Loss=3.62 Acc@1=16.67 Acc@5=39.17\n",
            "Training 4200: Loss=3.91 Acc@1=12.08 Acc@5=35.42\n",
            "Training 4230: Loss=3.71 Acc@1=14.17 Acc@5=34.17\n",
            "Training 4260: Loss=3.73 Acc@1=15.83 Acc@5=37.92\n",
            "Training 4290: Loss=3.8 Acc@1=10.42 Acc@5=32.5\n",
            "Training 4320: Loss=3.77 Acc@1=12.92 Acc@5=34.17\n",
            "Training 4350: Loss=3.88 Acc@1=9.17 Acc@5=30.42\n",
            "Training 4380: Loss=3.71 Acc@1=13.33 Acc@5=33.75\n",
            "Training 4410: Loss=3.72 Acc@1=14.58 Acc@5=33.33\n",
            "Training 4440: Loss=3.82 Acc@1=13.33 Acc@5=35.83\n",
            "Training 4470: Loss=3.85 Acc@1=9.17 Acc@5=33.33\n",
            "Training 4500: Loss=3.81 Acc@1=12.92 Acc@5=31.67\n",
            "Training 4530: Loss=3.71 Acc@1=13.33 Acc@5=37.5\n",
            "Training 4560: Loss=3.75 Acc@1=11.67 Acc@5=38.33\n",
            "Training 4590: Loss=3.83 Acc@1=10.0 Acc@5=35.83\n",
            "Training 4620: Loss=3.73 Acc@1=14.17 Acc@5=36.67\n",
            "Training 4650: Loss=3.63 Acc@1=12.92 Acc@5=39.17\n",
            "Training 4680: Loss=3.64 Acc@1=13.75 Acc@5=39.17\n",
            "Training 4710: Loss=3.7 Acc@1=12.08 Acc@5=36.25\n",
            "Training 4740: Loss=3.57 Acc@1=15.42 Acc@5=43.33\n",
            "Training 4770: Loss=3.79 Acc@1=12.08 Acc@5=32.92\n",
            "Training 4800: Loss=3.73 Acc@1=11.67 Acc@5=35.42\n",
            "Training 4830: Loss=3.72 Acc@1=15.42 Acc@5=35.0\n",
            "Training 4860: Loss=3.68 Acc@1=13.75 Acc@5=38.33\n",
            "Training 4890: Loss=3.75 Acc@1=15.0 Acc@5=34.58\n",
            "Training 4920: Loss=3.61 Acc@1=15.0 Acc@5=40.42\n",
            "Training 4950: Loss=3.58 Acc@1=17.5 Acc@5=42.92\n",
            "Training 4980: Loss=3.92 Acc@1=9.17 Acc@5=28.33\n",
            "Training 5010: Loss=3.7 Acc@1=16.67 Acc@5=34.17\n",
            "Training 5040: Loss=3.42 Acc@1=15.83 Acc@5=46.67\n",
            "Training 5070: Loss=3.67 Acc@1=12.92 Acc@5=33.33\n",
            "Training 5100: Loss=3.78 Acc@1=14.17 Acc@5=36.25\n",
            "Training 5130: Loss=3.79 Acc@1=13.75 Acc@5=37.5\n",
            "Training 5160: Loss=3.6 Acc@1=15.0 Acc@5=35.83\n",
            "Training 5190: Loss=3.65 Acc@1=12.08 Acc@5=38.75\n",
            "Training 5220: Loss=3.68 Acc@1=13.33 Acc@5=38.75\n",
            "Training 5250: Loss=3.73 Acc@1=11.67 Acc@5=36.67\n",
            "Training 5280: Loss=3.67 Acc@1=12.08 Acc@5=39.58\n",
            "Training 5310: Loss=3.75 Acc@1=12.5 Acc@5=36.25\n",
            "Training 5340: Loss=3.59 Acc@1=16.67 Acc@5=40.83\n",
            "Training 5370: Loss=3.72 Acc@1=16.25 Acc@5=35.42\n",
            "Training 5400: Loss=3.61 Acc@1=12.92 Acc@5=38.33\n",
            "Training 5430: Loss=3.76 Acc@1=13.33 Acc@5=33.33\n",
            "Training 5460: Loss=3.79 Acc@1=12.92 Acc@5=35.83\n",
            "Training 5490: Loss=3.56 Acc@1=17.08 Acc@5=42.5\n",
            "Training 5520: Loss=3.76 Acc@1=15.42 Acc@5=37.08\n",
            "Training 5550: Loss=3.69 Acc@1=16.25 Acc@5=37.08\n",
            "Training 5580: Loss=3.8 Acc@1=9.17 Acc@5=35.83\n",
            "Training 5610: Loss=3.55 Acc@1=13.33 Acc@5=39.58\n",
            "Training 5640: Loss=3.78 Acc@1=13.33 Acc@5=34.58\n",
            "Training 5670: Loss=3.48 Acc@1=17.92 Acc@5=44.17\n",
            "Training 5700: Loss=3.42 Acc@1=17.92 Acc@5=44.17\n",
            "Training 5730: Loss=3.56 Acc@1=15.0 Acc@5=38.75\n",
            "Training 5760: Loss=3.62 Acc@1=16.67 Acc@5=40.0\n",
            "Training 5790: Loss=3.6 Acc@1=12.92 Acc@5=39.17\n",
            "Training 5820: Loss=3.56 Acc@1=18.33 Acc@5=42.08\n",
            "Training 5850: Loss=3.57 Acc@1=17.08 Acc@5=37.92\n",
            "Training 5880: Loss=3.69 Acc@1=15.0 Acc@5=39.17\n",
            "Training 5910: Loss=3.57 Acc@1=14.17 Acc@5=36.67\n",
            "Training 5940: Loss=3.51 Acc@1=17.92 Acc@5=43.33\n",
            "Training 5970: Loss=3.7 Acc@1=15.42 Acc@5=35.0\n",
            "Training 6000: Loss=3.62 Acc@1=18.75 Acc@5=43.75\n",
            "Training 6030: Loss=3.58 Acc@1=14.58 Acc@5=39.58\n",
            "Training 6060: Loss=3.8 Acc@1=11.67 Acc@5=37.08\n",
            "Training 6090: Loss=3.69 Acc@1=12.08 Acc@5=35.42\n",
            "Training 6120: Loss=3.65 Acc@1=17.5 Acc@5=39.17\n",
            "Training 6150: Loss=3.55 Acc@1=14.58 Acc@5=42.92\n",
            "Training 6180: Loss=3.57 Acc@1=17.08 Acc@5=40.83\n",
            "Training 6210: Loss=3.57 Acc@1=15.0 Acc@5=39.17\n",
            "Training 6240: Loss=3.58 Acc@1=16.67 Acc@5=40.0\n",
            "Full imagenet train set: Acc@1=18.75 Acc@5=50.0\n",
            "Epoch: 1 ######################################################\n",
            "Training 30: Loss=3.57 Acc@1=13.75 Acc@5=36.25\n",
            "Training 60: Loss=3.73 Acc@1=13.75 Acc@5=34.17\n",
            "Training 90: Loss=3.52 Acc@1=18.33 Acc@5=40.42\n",
            "Training 120: Loss=3.57 Acc@1=17.92 Acc@5=39.58\n",
            "Training 150: Loss=3.44 Acc@1=19.58 Acc@5=41.25\n",
            "Training 180: Loss=3.54 Acc@1=21.25 Acc@5=40.0\n",
            "Training 210: Loss=3.64 Acc@1=16.25 Acc@5=36.25\n",
            "Training 240: Loss=3.58 Acc@1=15.83 Acc@5=40.0\n",
            "Training 270: Loss=3.52 Acc@1=15.0 Acc@5=39.58\n",
            "Training 300: Loss=3.48 Acc@1=17.08 Acc@5=46.25\n",
            "Training 330: Loss=3.36 Acc@1=21.25 Acc@5=40.83\n",
            "Training 360: Loss=3.4 Acc@1=18.75 Acc@5=42.08\n",
            "Training 390: Loss=3.67 Acc@1=14.58 Acc@5=39.17\n",
            "Training 420: Loss=3.66 Acc@1=12.08 Acc@5=40.83\n",
            "Training 450: Loss=3.5 Acc@1=13.33 Acc@5=41.25\n",
            "Training 480: Loss=3.56 Acc@1=17.92 Acc@5=40.42\n",
            "Training 510: Loss=3.51 Acc@1=20.0 Acc@5=43.75\n",
            "Training 540: Loss=3.73 Acc@1=10.0 Acc@5=36.67\n",
            "Training 570: Loss=3.53 Acc@1=17.92 Acc@5=40.83\n",
            "Training 600: Loss=3.64 Acc@1=14.17 Acc@5=39.17\n",
            "Training 630: Loss=3.63 Acc@1=15.0 Acc@5=38.75\n",
            "Training 660: Loss=3.32 Acc@1=18.33 Acc@5=48.33\n",
            "Training 690: Loss=3.49 Acc@1=16.25 Acc@5=42.5\n",
            "Training 720: Loss=3.49 Acc@1=17.92 Acc@5=45.42\n",
            "Training 750: Loss=3.46 Acc@1=20.0 Acc@5=46.25\n",
            "Training 780: Loss=3.45 Acc@1=17.08 Acc@5=42.5\n",
            "Training 810: Loss=3.47 Acc@1=15.42 Acc@5=42.08\n",
            "Training 840: Loss=3.39 Acc@1=21.25 Acc@5=45.42\n",
            "Training 870: Loss=3.4 Acc@1=16.67 Acc@5=47.08\n",
            "Training 900: Loss=3.37 Acc@1=18.33 Acc@5=47.08\n",
            "Training 930: Loss=3.46 Acc@1=20.42 Acc@5=47.5\n",
            "Training 960: Loss=3.54 Acc@1=16.67 Acc@5=40.0\n",
            "Training 990: Loss=3.41 Acc@1=19.58 Acc@5=44.58\n",
            "Training 1020: Loss=3.5 Acc@1=17.08 Acc@5=45.0\n",
            "Training 1050: Loss=3.46 Acc@1=17.92 Acc@5=42.92\n",
            "Training 1080: Loss=3.48 Acc@1=14.17 Acc@5=43.33\n",
            "Training 1110: Loss=3.44 Acc@1=17.08 Acc@5=49.58\n",
            "Training 1140: Loss=3.63 Acc@1=14.17 Acc@5=37.08\n",
            "Training 1170: Loss=3.49 Acc@1=12.08 Acc@5=42.92\n",
            "Training 1200: Loss=3.46 Acc@1=19.58 Acc@5=45.42\n",
            "Training 1230: Loss=3.45 Acc@1=16.25 Acc@5=41.25\n",
            "Training 1260: Loss=3.5 Acc@1=19.58 Acc@5=47.5\n",
            "Training 1290: Loss=3.48 Acc@1=17.92 Acc@5=41.67\n",
            "Training 1320: Loss=3.64 Acc@1=11.67 Acc@5=37.08\n",
            "Training 1350: Loss=3.59 Acc@1=17.08 Acc@5=40.0\n",
            "Training 1380: Loss=3.52 Acc@1=13.33 Acc@5=37.92\n",
            "Training 1410: Loss=3.33 Acc@1=17.5 Acc@5=48.75\n",
            "Training 1440: Loss=3.34 Acc@1=23.33 Acc@5=47.08\n",
            "Training 1470: Loss=3.71 Acc@1=15.0 Acc@5=40.0\n",
            "Training 1500: Loss=3.41 Acc@1=20.0 Acc@5=48.33\n",
            "Training 1530: Loss=3.52 Acc@1=15.42 Acc@5=40.42\n",
            "Training 1560: Loss=3.27 Acc@1=21.25 Acc@5=51.67\n",
            "Training 1590: Loss=3.43 Acc@1=21.67 Acc@5=43.75\n",
            "Training 1620: Loss=3.39 Acc@1=17.5 Acc@5=48.33\n",
            "Training 1650: Loss=3.49 Acc@1=16.25 Acc@5=40.42\n",
            "Training 1680: Loss=3.63 Acc@1=15.0 Acc@5=41.25\n",
            "Training 1710: Loss=3.46 Acc@1=17.5 Acc@5=41.25\n",
            "Training 1740: Loss=3.57 Acc@1=13.33 Acc@5=39.17\n",
            "Training 1770: Loss=3.41 Acc@1=15.83 Acc@5=47.08\n",
            "Training 1800: Loss=3.17 Acc@1=22.92 Acc@5=52.08\n",
            "Training 1830: Loss=3.49 Acc@1=12.5 Acc@5=45.0\n",
            "Training 1860: Loss=3.51 Acc@1=16.25 Acc@5=44.17\n",
            "Training 1890: Loss=3.49 Acc@1=15.83 Acc@5=43.33\n",
            "Training 1920: Loss=3.46 Acc@1=16.25 Acc@5=39.58\n",
            "Training 1950: Loss=3.62 Acc@1=17.08 Acc@5=40.42\n",
            "Training 1980: Loss=3.48 Acc@1=17.5 Acc@5=40.83\n",
            "Training 2010: Loss=3.44 Acc@1=17.08 Acc@5=43.75\n",
            "Training 2040: Loss=3.33 Acc@1=21.67 Acc@5=46.25\n",
            "Training 2070: Loss=3.33 Acc@1=21.67 Acc@5=47.92\n",
            "Training 2100: Loss=3.48 Acc@1=15.42 Acc@5=40.42\n",
            "Training 2130: Loss=3.3 Acc@1=21.67 Acc@5=46.25\n",
            "Training 2160: Loss=3.5 Acc@1=15.83 Acc@5=41.25\n",
            "Training 2190: Loss=3.47 Acc@1=17.5 Acc@5=40.83\n",
            "Training 2220: Loss=3.65 Acc@1=15.42 Acc@5=34.17\n",
            "Training 2250: Loss=3.64 Acc@1=14.17 Acc@5=42.08\n",
            "Training 2280: Loss=3.34 Acc@1=22.5 Acc@5=47.92\n",
            "Training 2310: Loss=3.18 Acc@1=24.58 Acc@5=53.75\n",
            "Training 2340: Loss=3.46 Acc@1=17.08 Acc@5=43.33\n",
            "Training 2370: Loss=3.23 Acc@1=22.08 Acc@5=49.58\n",
            "Training 2400: Loss=3.32 Acc@1=20.83 Acc@5=45.0\n",
            "Training 2430: Loss=3.47 Acc@1=18.75 Acc@5=42.92\n",
            "Training 2460: Loss=3.35 Acc@1=18.75 Acc@5=48.33\n",
            "Training 2490: Loss=3.3 Acc@1=21.25 Acc@5=47.5\n",
            "Training 2520: Loss=3.33 Acc@1=21.25 Acc@5=49.17\n",
            "Training 2550: Loss=3.54 Acc@1=19.58 Acc@5=42.08\n",
            "Training 2580: Loss=3.39 Acc@1=15.83 Acc@5=45.42\n",
            "Training 2610: Loss=3.48 Acc@1=17.08 Acc@5=43.75\n",
            "Training 2640: Loss=3.28 Acc@1=20.83 Acc@5=50.0\n",
            "Training 2670: Loss=3.37 Acc@1=20.0 Acc@5=45.83\n",
            "Training 2700: Loss=3.4 Acc@1=18.75 Acc@5=49.17\n",
            "Training 2730: Loss=3.46 Acc@1=17.08 Acc@5=42.92\n",
            "Training 2760: Loss=3.34 Acc@1=20.42 Acc@5=47.08\n",
            "Training 2790: Loss=3.32 Acc@1=23.75 Acc@5=52.08\n",
            "Training 2820: Loss=3.4 Acc@1=21.67 Acc@5=44.17\n",
            "Training 2850: Loss=3.43 Acc@1=18.75 Acc@5=43.75\n",
            "Training 2880: Loss=3.39 Acc@1=19.17 Acc@5=43.33\n",
            "Training 2910: Loss=3.29 Acc@1=19.17 Acc@5=46.67\n",
            "Training 2940: Loss=3.41 Acc@1=18.33 Acc@5=47.5\n",
            "Training 2970: Loss=3.42 Acc@1=16.25 Acc@5=47.08\n",
            "Training 3000: Loss=3.29 Acc@1=19.17 Acc@5=46.67\n",
            "Training 3030: Loss=3.28 Acc@1=17.92 Acc@5=46.67\n",
            "Training 3060: Loss=3.25 Acc@1=20.0 Acc@5=48.75\n",
            "Training 3090: Loss=3.33 Acc@1=17.08 Acc@5=47.08\n",
            "Training 3120: Loss=3.42 Acc@1=18.75 Acc@5=43.33\n",
            "Training 3150: Loss=3.51 Acc@1=16.67 Acc@5=40.0\n",
            "Training 3180: Loss=3.45 Acc@1=17.5 Acc@5=45.0\n",
            "Training 3210: Loss=3.47 Acc@1=20.42 Acc@5=43.33\n",
            "Training 3240: Loss=3.27 Acc@1=20.83 Acc@5=50.83\n",
            "Training 3270: Loss=3.33 Acc@1=18.75 Acc@5=43.75\n",
            "Training 3300: Loss=3.39 Acc@1=19.17 Acc@5=44.58\n",
            "Training 3330: Loss=3.51 Acc@1=17.08 Acc@5=41.67\n",
            "Training 3360: Loss=3.33 Acc@1=21.67 Acc@5=47.5\n",
            "Training 3390: Loss=3.29 Acc@1=19.17 Acc@5=48.33\n",
            "Training 3420: Loss=3.29 Acc@1=19.58 Acc@5=43.33\n",
            "Training 3450: Loss=3.45 Acc@1=16.67 Acc@5=44.17\n",
            "Training 3480: Loss=3.45 Acc@1=16.25 Acc@5=42.5\n",
            "Training 3510: Loss=3.35 Acc@1=22.08 Acc@5=46.25\n",
            "Training 3540: Loss=3.34 Acc@1=19.17 Acc@5=44.17\n",
            "Training 3570: Loss=3.54 Acc@1=13.75 Acc@5=41.67\n",
            "Training 3600: Loss=3.31 Acc@1=25.0 Acc@5=48.33\n",
            "Training 3630: Loss=3.35 Acc@1=24.58 Acc@5=49.58\n",
            "Training 3660: Loss=3.4 Acc@1=16.25 Acc@5=44.17\n",
            "Training 3690: Loss=3.18 Acc@1=25.83 Acc@5=47.92\n",
            "Training 3720: Loss=3.27 Acc@1=22.08 Acc@5=47.5\n",
            "Training 3750: Loss=3.41 Acc@1=19.58 Acc@5=43.33\n",
            "Training 3780: Loss=3.59 Acc@1=15.0 Acc@5=42.08\n",
            "Training 3810: Loss=3.36 Acc@1=21.25 Acc@5=47.08\n",
            "Training 3840: Loss=3.26 Acc@1=18.33 Acc@5=52.5\n",
            "Training 3870: Loss=3.22 Acc@1=20.42 Acc@5=46.25\n",
            "Training 3900: Loss=3.14 Acc@1=26.67 Acc@5=57.5\n",
            "Training 3930: Loss=3.11 Acc@1=25.0 Acc@5=52.5\n",
            "Training 3960: Loss=3.34 Acc@1=17.5 Acc@5=46.25\n",
            "Training 3990: Loss=3.32 Acc@1=20.42 Acc@5=48.33\n",
            "Training 4020: Loss=3.2 Acc@1=19.58 Acc@5=51.25\n",
            "Training 4050: Loss=3.45 Acc@1=16.25 Acc@5=43.75\n",
            "Training 4080: Loss=3.19 Acc@1=27.92 Acc@5=50.42\n",
            "Training 4110: Loss=3.25 Acc@1=20.0 Acc@5=47.92\n",
            "Training 4140: Loss=3.41 Acc@1=18.75 Acc@5=46.67\n",
            "Training 4170: Loss=3.31 Acc@1=19.17 Acc@5=50.42\n",
            "Training 4200: Loss=3.3 Acc@1=22.5 Acc@5=44.58\n",
            "Training 4230: Loss=3.35 Acc@1=19.58 Acc@5=50.83\n",
            "Training 4260: Loss=3.21 Acc@1=20.42 Acc@5=48.33\n",
            "Training 4290: Loss=3.14 Acc@1=23.75 Acc@5=51.67\n",
            "Training 4320: Loss=3.47 Acc@1=19.58 Acc@5=46.25\n",
            "Training 4350: Loss=3.38 Acc@1=17.5 Acc@5=45.0\n",
            "Training 4380: Loss=3.39 Acc@1=19.17 Acc@5=43.75\n",
            "Training 4410: Loss=3.29 Acc@1=21.25 Acc@5=45.0\n",
            "Training 4440: Loss=3.35 Acc@1=18.33 Acc@5=43.33\n",
            "Training 4470: Loss=3.23 Acc@1=23.33 Acc@5=48.33\n",
            "Training 4500: Loss=3.2 Acc@1=21.25 Acc@5=48.33\n",
            "Training 4530: Loss=3.16 Acc@1=20.83 Acc@5=51.25\n",
            "Training 4560: Loss=3.36 Acc@1=22.92 Acc@5=46.25\n",
            "Training 4590: Loss=3.17 Acc@1=23.75 Acc@5=52.5\n",
            "Training 4620: Loss=3.35 Acc@1=20.0 Acc@5=45.83\n",
            "Training 4650: Loss=3.39 Acc@1=18.33 Acc@5=46.25\n",
            "Training 4680: Loss=3.19 Acc@1=21.67 Acc@5=51.25\n",
            "Training 4710: Loss=3.27 Acc@1=22.5 Acc@5=48.33\n",
            "Training 4740: Loss=3.31 Acc@1=20.42 Acc@5=47.5\n",
            "Training 4770: Loss=3.13 Acc@1=26.25 Acc@5=50.83\n",
            "Training 4800: Loss=3.46 Acc@1=20.42 Acc@5=39.58\n",
            "Training 4830: Loss=3.55 Acc@1=16.67 Acc@5=40.0\n",
            "Training 4860: Loss=3.42 Acc@1=18.75 Acc@5=43.75\n",
            "Training 4890: Loss=3.42 Acc@1=17.92 Acc@5=45.0\n",
            "Training 4920: Loss=3.41 Acc@1=17.92 Acc@5=43.75\n",
            "Training 4950: Loss=3.28 Acc@1=21.67 Acc@5=44.17\n",
            "Training 4980: Loss=3.28 Acc@1=20.0 Acc@5=54.58\n",
            "Training 5010: Loss=3.28 Acc@1=21.25 Acc@5=49.58\n",
            "Training 5040: Loss=3.51 Acc@1=18.75 Acc@5=42.92\n",
            "Training 5070: Loss=3.24 Acc@1=23.75 Acc@5=47.92\n",
            "Training 5100: Loss=3.47 Acc@1=18.33 Acc@5=42.08\n",
            "Training 5130: Loss=3.15 Acc@1=25.42 Acc@5=50.42\n",
            "Training 5160: Loss=3.39 Acc@1=20.0 Acc@5=49.58\n",
            "Training 5190: Loss=3.28 Acc@1=23.33 Acc@5=49.58\n",
            "Training 5220: Loss=3.36 Acc@1=20.0 Acc@5=47.08\n",
            "Training 5250: Loss=3.29 Acc@1=16.25 Acc@5=50.0\n",
            "Training 5280: Loss=3.45 Acc@1=20.0 Acc@5=45.83\n",
            "Training 5310: Loss=3.25 Acc@1=17.08 Acc@5=49.17\n",
            "Training 5340: Loss=3.05 Acc@1=27.08 Acc@5=52.5\n",
            "Training 5370: Loss=3.27 Acc@1=16.67 Acc@5=45.83\n",
            "Training 5400: Loss=3.2 Acc@1=22.5 Acc@5=51.25\n",
            "Training 5430: Loss=3.37 Acc@1=20.0 Acc@5=48.75\n",
            "Training 5460: Loss=3.33 Acc@1=22.5 Acc@5=47.92\n",
            "Training 5490: Loss=3.17 Acc@1=23.75 Acc@5=52.92\n",
            "Training 5520: Loss=3.29 Acc@1=22.5 Acc@5=49.58\n",
            "Training 5550: Loss=3.15 Acc@1=24.17 Acc@5=52.92\n",
            "Training 5580: Loss=3.52 Acc@1=15.42 Acc@5=45.42\n",
            "Training 5610: Loss=3.34 Acc@1=19.17 Acc@5=45.83\n",
            "Training 5640: Loss=3.24 Acc@1=23.33 Acc@5=48.75\n",
            "Training 5670: Loss=3.36 Acc@1=20.83 Acc@5=45.42\n",
            "Training 5700: Loss=3.19 Acc@1=19.58 Acc@5=50.83\n",
            "Training 5730: Loss=3.03 Acc@1=26.67 Acc@5=53.33\n",
            "Training 5760: Loss=3.15 Acc@1=24.17 Acc@5=52.08\n",
            "Training 5790: Loss=3.53 Acc@1=14.58 Acc@5=42.92\n",
            "Training 5820: Loss=3.35 Acc@1=19.17 Acc@5=46.25\n",
            "Training 5850: Loss=3.21 Acc@1=24.58 Acc@5=49.17\n",
            "Training 5880: Loss=3.25 Acc@1=20.0 Acc@5=50.83\n",
            "Training 5910: Loss=3.11 Acc@1=26.25 Acc@5=55.42\n",
            "Training 5940: Loss=3.23 Acc@1=20.0 Acc@5=49.17\n",
            "Training 5970: Loss=3.27 Acc@1=20.0 Acc@5=50.0\n",
            "Training 6000: Loss=3.14 Acc@1=23.33 Acc@5=52.92\n",
            "Training 6030: Loss=3.42 Acc@1=15.42 Acc@5=47.08\n",
            "Training 6060: Loss=3.11 Acc@1=21.67 Acc@5=49.17\n",
            "Training 6090: Loss=3.14 Acc@1=23.33 Acc@5=52.08\n",
            "Training 6120: Loss=3.19 Acc@1=24.17 Acc@5=55.0\n",
            "Training 6150: Loss=3.26 Acc@1=23.75 Acc@5=51.67\n",
            "Training 6180: Loss=3.29 Acc@1=22.92 Acc@5=48.33\n",
            "Training 6210: Loss=3.21 Acc@1=19.17 Acc@5=52.08\n",
            "Training 6240: Loss=3.1 Acc@1=22.5 Acc@5=52.5\n",
            "Full imagenet train set: Acc@1=35.0 Acc@5=60.0\n",
            "Epoch: 2 ######################################################\n",
            "Training 30: Loss=3.09 Acc@1=25.0 Acc@5=58.33\n",
            "Training 60: Loss=3.24 Acc@1=20.83 Acc@5=48.75\n",
            "Training 90: Loss=3.21 Acc@1=22.92 Acc@5=48.33\n",
            "Training 120: Loss=3.18 Acc@1=22.92 Acc@5=50.83\n",
            "Training 150: Loss=3.05 Acc@1=19.58 Acc@5=55.83\n",
            "Training 180: Loss=3.26 Acc@1=20.42 Acc@5=49.17\n",
            "Training 210: Loss=3.16 Acc@1=19.58 Acc@5=52.08\n",
            "Training 240: Loss=3.04 Acc@1=23.75 Acc@5=52.5\n",
            "Training 270: Loss=3.04 Acc@1=25.83 Acc@5=52.08\n",
            "Training 300: Loss=3.23 Acc@1=19.58 Acc@5=47.5\n",
            "Training 330: Loss=3.09 Acc@1=20.83 Acc@5=49.17\n",
            "Training 360: Loss=3.13 Acc@1=23.75 Acc@5=49.17\n",
            "Training 390: Loss=3.31 Acc@1=24.58 Acc@5=45.42\n",
            "Training 420: Loss=3.06 Acc@1=25.0 Acc@5=51.25\n",
            "Training 450: Loss=3.04 Acc@1=23.75 Acc@5=54.17\n",
            "Training 480: Loss=3.18 Acc@1=23.33 Acc@5=51.67\n",
            "Training 510: Loss=2.96 Acc@1=29.17 Acc@5=55.0\n",
            "Training 540: Loss=3.1 Acc@1=29.17 Acc@5=53.75\n",
            "Training 570: Loss=3.11 Acc@1=25.42 Acc@5=51.25\n",
            "Training 600: Loss=3.19 Acc@1=20.42 Acc@5=50.0\n",
            "Training 630: Loss=2.89 Acc@1=26.25 Acc@5=60.0\n",
            "Training 660: Loss=3.2 Acc@1=21.25 Acc@5=53.75\n",
            "Training 690: Loss=3.31 Acc@1=20.83 Acc@5=47.08\n",
            "Training 720: Loss=3.09 Acc@1=25.83 Acc@5=50.42\n",
            "Training 750: Loss=3.03 Acc@1=22.08 Acc@5=55.42\n",
            "Training 780: Loss=3.24 Acc@1=19.58 Acc@5=47.08\n",
            "Training 810: Loss=3.05 Acc@1=26.67 Acc@5=54.17\n",
            "Training 840: Loss=3.06 Acc@1=24.58 Acc@5=55.0\n",
            "Training 870: Loss=3.0 Acc@1=24.58 Acc@5=54.58\n",
            "Training 900: Loss=3.19 Acc@1=23.33 Acc@5=53.75\n",
            "Training 930: Loss=2.99 Acc@1=26.25 Acc@5=57.08\n",
            "Training 960: Loss=3.2 Acc@1=25.42 Acc@5=50.0\n",
            "Training 990: Loss=3.05 Acc@1=26.25 Acc@5=53.75\n",
            "Training 1020: Loss=3.13 Acc@1=24.58 Acc@5=55.83\n",
            "Training 1050: Loss=3.08 Acc@1=25.42 Acc@5=54.58\n",
            "Training 1080: Loss=3.16 Acc@1=21.67 Acc@5=52.92\n",
            "Training 1110: Loss=3.11 Acc@1=25.0 Acc@5=54.58\n",
            "Training 1140: Loss=3.12 Acc@1=22.08 Acc@5=53.75\n",
            "Training 1170: Loss=3.07 Acc@1=25.0 Acc@5=52.92\n",
            "Training 1200: Loss=3.02 Acc@1=25.42 Acc@5=52.08\n",
            "Training 1230: Loss=2.99 Acc@1=24.58 Acc@5=55.83\n",
            "Training 1260: Loss=3.27 Acc@1=18.75 Acc@5=49.58\n",
            "Training 1290: Loss=3.08 Acc@1=22.08 Acc@5=55.42\n",
            "Training 1320: Loss=3.26 Acc@1=19.58 Acc@5=51.25\n",
            "Training 1350: Loss=3.21 Acc@1=21.67 Acc@5=47.08\n",
            "Training 1380: Loss=2.91 Acc@1=27.5 Acc@5=57.5\n",
            "Training 1410: Loss=3.22 Acc@1=19.17 Acc@5=54.17\n",
            "Training 1440: Loss=3.23 Acc@1=25.83 Acc@5=52.5\n",
            "Training 1470: Loss=3.1 Acc@1=23.33 Acc@5=54.17\n",
            "Training 1500: Loss=2.96 Acc@1=23.75 Acc@5=51.67\n",
            "Training 1530: Loss=3.25 Acc@1=22.08 Acc@5=50.42\n",
            "Training 1560: Loss=3.12 Acc@1=22.92 Acc@5=54.17\n",
            "Training 1590: Loss=3.16 Acc@1=23.33 Acc@5=55.0\n",
            "Training 1620: Loss=3.22 Acc@1=19.17 Acc@5=51.25\n",
            "Training 1650: Loss=3.14 Acc@1=21.67 Acc@5=48.75\n",
            "Training 1680: Loss=3.18 Acc@1=24.17 Acc@5=52.92\n",
            "Training 1710: Loss=3.04 Acc@1=29.58 Acc@5=55.0\n",
            "Training 1740: Loss=3.06 Acc@1=24.17 Acc@5=51.67\n",
            "Training 1770: Loss=3.08 Acc@1=25.83 Acc@5=52.08\n",
            "Training 1800: Loss=3.15 Acc@1=24.17 Acc@5=51.25\n",
            "Training 1830: Loss=3.01 Acc@1=22.08 Acc@5=56.67\n",
            "Training 1860: Loss=3.31 Acc@1=21.25 Acc@5=47.08\n",
            "Training 1890: Loss=3.0 Acc@1=23.75 Acc@5=57.08\n",
            "Training 1920: Loss=3.07 Acc@1=26.67 Acc@5=51.67\n",
            "Training 1950: Loss=2.92 Acc@1=26.67 Acc@5=56.67\n",
            "Training 1980: Loss=3.1 Acc@1=22.92 Acc@5=52.92\n",
            "Training 2010: Loss=3.19 Acc@1=24.17 Acc@5=49.58\n",
            "Training 2040: Loss=3.08 Acc@1=26.67 Acc@5=51.25\n",
            "Training 2070: Loss=3.2 Acc@1=23.33 Acc@5=52.92\n",
            "Training 2100: Loss=3.2 Acc@1=22.5 Acc@5=53.75\n",
            "Training 2130: Loss=3.08 Acc@1=25.0 Acc@5=50.0\n",
            "Training 2160: Loss=3.0 Acc@1=32.08 Acc@5=52.92\n",
            "Training 2190: Loss=3.19 Acc@1=25.0 Acc@5=50.0\n",
            "Training 2220: Loss=3.13 Acc@1=22.92 Acc@5=51.25\n",
            "Training 2250: Loss=3.06 Acc@1=26.25 Acc@5=54.58\n",
            "Training 2280: Loss=3.09 Acc@1=27.5 Acc@5=55.42\n",
            "Training 2310: Loss=3.01 Acc@1=25.42 Acc@5=57.5\n",
            "Training 2340: Loss=3.28 Acc@1=22.92 Acc@5=48.75\n",
            "Training 2370: Loss=3.15 Acc@1=20.42 Acc@5=50.0\n",
            "Training 2400: Loss=2.93 Acc@1=32.5 Acc@5=58.33\n",
            "Training 2430: Loss=3.11 Acc@1=24.58 Acc@5=51.25\n",
            "Training 2460: Loss=3.09 Acc@1=27.5 Acc@5=52.5\n",
            "Training 2490: Loss=3.03 Acc@1=25.0 Acc@5=52.5\n",
            "Training 2520: Loss=3.14 Acc@1=24.58 Acc@5=50.0\n",
            "Training 2550: Loss=3.09 Acc@1=25.0 Acc@5=52.5\n",
            "Training 2580: Loss=3.19 Acc@1=22.92 Acc@5=47.92\n",
            "Training 2610: Loss=2.92 Acc@1=25.0 Acc@5=56.25\n",
            "Training 2640: Loss=3.08 Acc@1=23.75 Acc@5=52.08\n",
            "Training 2670: Loss=2.82 Acc@1=30.0 Acc@5=60.83\n",
            "Training 2700: Loss=3.04 Acc@1=25.0 Acc@5=54.58\n",
            "Training 2730: Loss=2.88 Acc@1=26.67 Acc@5=57.5\n",
            "Training 2760: Loss=3.15 Acc@1=25.0 Acc@5=49.58\n",
            "Training 2790: Loss=3.11 Acc@1=24.58 Acc@5=52.92\n",
            "Training 2820: Loss=3.08 Acc@1=27.08 Acc@5=52.92\n",
            "Training 2850: Loss=3.14 Acc@1=23.75 Acc@5=51.67\n",
            "Training 2880: Loss=2.91 Acc@1=29.17 Acc@5=59.58\n",
            "Training 2910: Loss=3.28 Acc@1=21.25 Acc@5=47.92\n",
            "Training 2940: Loss=3.0 Acc@1=27.08 Acc@5=53.75\n",
            "Training 2970: Loss=3.07 Acc@1=25.42 Acc@5=54.17\n",
            "Training 3000: Loss=3.05 Acc@1=24.17 Acc@5=53.75\n",
            "Training 3030: Loss=3.03 Acc@1=24.58 Acc@5=53.33\n",
            "Training 3060: Loss=3.08 Acc@1=22.92 Acc@5=55.83\n",
            "Training 3090: Loss=2.97 Acc@1=25.42 Acc@5=54.58\n",
            "Training 3120: Loss=3.0 Acc@1=20.83 Acc@5=57.92\n",
            "Training 3150: Loss=3.08 Acc@1=28.33 Acc@5=55.83\n",
            "Training 3180: Loss=2.92 Acc@1=30.83 Acc@5=57.5\n",
            "Training 3210: Loss=3.11 Acc@1=25.42 Acc@5=52.92\n",
            "Training 3240: Loss=3.26 Acc@1=18.33 Acc@5=50.83\n",
            "Training 3270: Loss=3.12 Acc@1=18.33 Acc@5=53.75\n",
            "Training 3300: Loss=3.24 Acc@1=21.67 Acc@5=47.5\n",
            "Training 3330: Loss=2.83 Acc@1=31.25 Acc@5=56.67\n",
            "Training 3360: Loss=2.86 Acc@1=28.33 Acc@5=57.5\n",
            "Training 3390: Loss=3.07 Acc@1=20.42 Acc@5=52.08\n",
            "Training 3420: Loss=3.02 Acc@1=27.08 Acc@5=55.0\n",
            "Training 3450: Loss=3.15 Acc@1=25.42 Acc@5=48.75\n",
            "Training 3480: Loss=3.05 Acc@1=27.08 Acc@5=52.92\n",
            "Training 3510: Loss=3.2 Acc@1=21.67 Acc@5=49.17\n",
            "Training 3540: Loss=2.99 Acc@1=26.25 Acc@5=54.58\n",
            "Training 3570: Loss=3.13 Acc@1=24.58 Acc@5=50.83\n",
            "Training 3600: Loss=3.06 Acc@1=25.42 Acc@5=52.92\n",
            "Training 3630: Loss=3.16 Acc@1=24.58 Acc@5=51.25\n",
            "Training 3660: Loss=3.0 Acc@1=25.42 Acc@5=56.67\n",
            "Training 3690: Loss=2.88 Acc@1=30.0 Acc@5=60.0\n",
            "Training 3720: Loss=2.9 Acc@1=29.17 Acc@5=59.17\n",
            "Training 3750: Loss=3.05 Acc@1=26.25 Acc@5=50.42\n",
            "Training 3780: Loss=3.0 Acc@1=24.58 Acc@5=54.17\n",
            "Training 3810: Loss=2.92 Acc@1=26.25 Acc@5=58.33\n",
            "Training 3840: Loss=2.95 Acc@1=27.5 Acc@5=57.08\n",
            "Training 3870: Loss=3.22 Acc@1=20.42 Acc@5=47.5\n",
            "Training 3900: Loss=3.16 Acc@1=24.58 Acc@5=51.67\n",
            "Training 3930: Loss=2.96 Acc@1=23.75 Acc@5=55.83\n",
            "Training 3960: Loss=3.37 Acc@1=20.0 Acc@5=45.42\n",
            "Training 3990: Loss=3.11 Acc@1=25.83 Acc@5=54.17\n",
            "Training 4020: Loss=2.93 Acc@1=27.08 Acc@5=57.08\n",
            "Training 4050: Loss=2.92 Acc@1=28.33 Acc@5=57.5\n",
            "Training 4080: Loss=3.05 Acc@1=24.17 Acc@5=52.92\n",
            "Training 4110: Loss=3.12 Acc@1=20.0 Acc@5=52.5\n",
            "Training 4140: Loss=2.99 Acc@1=29.58 Acc@5=57.92\n",
            "Training 4170: Loss=3.17 Acc@1=21.25 Acc@5=50.0\n",
            "Training 4200: Loss=3.05 Acc@1=24.17 Acc@5=53.75\n",
            "Training 4230: Loss=3.12 Acc@1=27.5 Acc@5=54.58\n",
            "Training 4260: Loss=2.87 Acc@1=29.17 Acc@5=58.75\n",
            "Training 4290: Loss=3.11 Acc@1=24.58 Acc@5=52.5\n",
            "Training 4320: Loss=3.07 Acc@1=25.0 Acc@5=54.58\n",
            "Training 4350: Loss=3.12 Acc@1=26.25 Acc@5=49.17\n",
            "Training 4380: Loss=3.11 Acc@1=26.25 Acc@5=54.58\n",
            "Training 4410: Loss=3.2 Acc@1=25.0 Acc@5=52.5\n",
            "Training 4440: Loss=2.77 Acc@1=25.42 Acc@5=63.75\n",
            "Training 4470: Loss=2.87 Acc@1=29.17 Acc@5=57.08\n",
            "Training 4500: Loss=3.07 Acc@1=27.08 Acc@5=54.17\n",
            "Training 4530: Loss=3.19 Acc@1=22.92 Acc@5=50.83\n",
            "Training 4560: Loss=3.0 Acc@1=27.5 Acc@5=53.75\n",
            "Training 4590: Loss=3.09 Acc@1=25.0 Acc@5=54.58\n",
            "Training 4620: Loss=3.17 Acc@1=24.17 Acc@5=52.08\n",
            "Training 4650: Loss=2.94 Acc@1=28.75 Acc@5=56.25\n",
            "Training 4680: Loss=3.03 Acc@1=27.08 Acc@5=53.75\n",
            "Training 4710: Loss=3.28 Acc@1=24.58 Acc@5=46.25\n",
            "Training 4740: Loss=2.79 Acc@1=27.92 Acc@5=58.33\n",
            "Training 4770: Loss=3.16 Acc@1=25.0 Acc@5=50.83\n",
            "Training 4800: Loss=3.18 Acc@1=23.75 Acc@5=52.92\n",
            "Training 4830: Loss=3.18 Acc@1=22.08 Acc@5=48.33\n",
            "Training 4860: Loss=3.02 Acc@1=29.17 Acc@5=51.67\n",
            "Training 4890: Loss=3.22 Acc@1=24.58 Acc@5=52.08\n",
            "Training 4920: Loss=3.08 Acc@1=23.33 Acc@5=50.0\n",
            "Training 4950: Loss=2.93 Acc@1=23.33 Acc@5=55.42\n",
            "Training 4980: Loss=2.87 Acc@1=24.17 Acc@5=61.25\n",
            "Training 5010: Loss=2.92 Acc@1=28.75 Acc@5=55.0\n",
            "Training 5040: Loss=2.97 Acc@1=27.5 Acc@5=57.92\n",
            "Training 5070: Loss=2.81 Acc@1=29.58 Acc@5=56.25\n",
            "Training 5100: Loss=2.95 Acc@1=27.92 Acc@5=56.67\n",
            "Training 5130: Loss=3.18 Acc@1=24.17 Acc@5=49.58\n",
            "Training 5160: Loss=3.16 Acc@1=24.17 Acc@5=49.17\n",
            "Training 5190: Loss=2.97 Acc@1=27.5 Acc@5=61.25\n",
            "Training 5220: Loss=3.08 Acc@1=24.58 Acc@5=52.08\n",
            "Training 5250: Loss=2.82 Acc@1=27.92 Acc@5=57.92\n",
            "Training 5280: Loss=3.28 Acc@1=25.0 Acc@5=47.5\n",
            "Training 5310: Loss=2.86 Acc@1=25.42 Acc@5=60.83\n",
            "Training 5340: Loss=3.08 Acc@1=24.17 Acc@5=52.92\n",
            "Training 5370: Loss=3.0 Acc@1=26.67 Acc@5=56.25\n",
            "Training 5400: Loss=2.99 Acc@1=27.5 Acc@5=58.75\n",
            "Training 5430: Loss=3.06 Acc@1=25.83 Acc@5=55.0\n",
            "Training 5460: Loss=3.05 Acc@1=24.58 Acc@5=56.67\n",
            "Training 5490: Loss=2.85 Acc@1=26.67 Acc@5=57.5\n",
            "Training 5520: Loss=3.04 Acc@1=25.42 Acc@5=53.33\n",
            "Training 5550: Loss=2.96 Acc@1=26.67 Acc@5=56.25\n",
            "Training 5580: Loss=2.99 Acc@1=26.25 Acc@5=57.5\n",
            "Training 5610: Loss=3.11 Acc@1=27.08 Acc@5=56.67\n",
            "Training 5640: Loss=2.69 Acc@1=34.58 Acc@5=62.5\n",
            "Training 5670: Loss=2.93 Acc@1=25.83 Acc@5=53.75\n",
            "Training 5700: Loss=2.93 Acc@1=28.33 Acc@5=56.25\n",
            "Training 5730: Loss=3.22 Acc@1=23.75 Acc@5=50.42\n",
            "Training 5760: Loss=2.98 Acc@1=24.17 Acc@5=54.17\n",
            "Training 5790: Loss=3.15 Acc@1=27.5 Acc@5=50.83\n",
            "Training 5820: Loss=2.96 Acc@1=29.58 Acc@5=55.0\n",
            "Training 5850: Loss=2.92 Acc@1=28.33 Acc@5=57.08\n",
            "Training 5880: Loss=2.95 Acc@1=27.08 Acc@5=52.5\n",
            "Training 5910: Loss=2.81 Acc@1=28.75 Acc@5=60.42\n",
            "Training 5940: Loss=2.89 Acc@1=26.67 Acc@5=54.58\n",
            "Training 5970: Loss=2.79 Acc@1=27.08 Acc@5=58.33\n",
            "Training 6000: Loss=2.79 Acc@1=28.75 Acc@5=62.08\n",
            "Training 6030: Loss=2.93 Acc@1=26.67 Acc@5=56.67\n",
            "Training 6060: Loss=3.17 Acc@1=22.5 Acc@5=52.92\n",
            "Training 6090: Loss=2.92 Acc@1=25.83 Acc@5=60.83\n",
            "Training 6120: Loss=2.84 Acc@1=29.58 Acc@5=62.5\n",
            "Training 6150: Loss=3.03 Acc@1=27.5 Acc@5=49.17\n",
            "Training 6180: Loss=2.98 Acc@1=25.83 Acc@5=54.58\n",
            "Training 6210: Loss=2.81 Acc@1=26.67 Acc@5=57.92\n",
            "Training 6240: Loss=3.08 Acc@1=25.83 Acc@5=53.33\n",
            "Full imagenet train set: Acc@1=42.5 Acc@5=75.0\n",
            "Epoch: 3 ######################################################\n",
            "Training 30: Loss=2.66 Acc@1=30.0 Acc@5=67.08\n",
            "Training 60: Loss=2.98 Acc@1=24.58 Acc@5=56.25\n",
            "Training 90: Loss=2.83 Acc@1=27.92 Acc@5=56.25\n",
            "Training 120: Loss=2.93 Acc@1=25.42 Acc@5=58.75\n",
            "Training 150: Loss=3.06 Acc@1=27.5 Acc@5=53.75\n",
            "Training 180: Loss=3.05 Acc@1=24.17 Acc@5=54.17\n",
            "Training 210: Loss=2.85 Acc@1=30.0 Acc@5=61.67\n",
            "Training 240: Loss=2.75 Acc@1=28.75 Acc@5=64.58\n",
            "Training 270: Loss=2.85 Acc@1=27.92 Acc@5=60.0\n",
            "Training 300: Loss=2.83 Acc@1=30.83 Acc@5=60.83\n",
            "Training 330: Loss=2.83 Acc@1=25.42 Acc@5=61.25\n",
            "Training 360: Loss=2.94 Acc@1=27.08 Acc@5=55.83\n",
            "Training 390: Loss=2.9 Acc@1=25.83 Acc@5=55.83\n",
            "Training 420: Loss=2.88 Acc@1=28.75 Acc@5=56.25\n",
            "Training 450: Loss=2.91 Acc@1=26.25 Acc@5=58.75\n",
            "Training 480: Loss=2.84 Acc@1=28.75 Acc@5=59.17\n",
            "Training 510: Loss=2.76 Acc@1=27.5 Acc@5=63.75\n",
            "Training 540: Loss=2.63 Acc@1=31.67 Acc@5=64.17\n",
            "Training 570: Loss=2.78 Acc@1=32.92 Acc@5=58.75\n",
            "Training 600: Loss=2.78 Acc@1=28.33 Acc@5=62.5\n",
            "Training 630: Loss=2.77 Acc@1=30.0 Acc@5=57.5\n",
            "Training 660: Loss=2.77 Acc@1=27.92 Acc@5=59.17\n",
            "Training 690: Loss=2.81 Acc@1=27.92 Acc@5=59.58\n",
            "Training 720: Loss=2.89 Acc@1=28.75 Acc@5=59.58\n",
            "Training 750: Loss=2.76 Acc@1=31.67 Acc@5=60.83\n",
            "Training 780: Loss=2.96 Acc@1=30.0 Acc@5=56.25\n",
            "Training 810: Loss=2.98 Acc@1=26.25 Acc@5=54.58\n",
            "Training 840: Loss=2.88 Acc@1=28.75 Acc@5=58.33\n",
            "Training 870: Loss=2.94 Acc@1=26.67 Acc@5=55.83\n",
            "Training 900: Loss=2.92 Acc@1=31.67 Acc@5=59.58\n",
            "Training 930: Loss=2.78 Acc@1=28.75 Acc@5=58.75\n",
            "Training 960: Loss=2.84 Acc@1=27.5 Acc@5=57.08\n",
            "Training 990: Loss=2.97 Acc@1=21.67 Acc@5=56.67\n",
            "Training 1020: Loss=2.82 Acc@1=28.33 Acc@5=60.83\n",
            "Training 1050: Loss=2.81 Acc@1=30.0 Acc@5=56.25\n",
            "Training 1080: Loss=2.86 Acc@1=29.17 Acc@5=55.0\n",
            "Training 1110: Loss=2.96 Acc@1=27.08 Acc@5=53.75\n",
            "Training 1140: Loss=2.82 Acc@1=30.0 Acc@5=58.33\n",
            "Training 1170: Loss=3.04 Acc@1=28.33 Acc@5=54.58\n",
            "Training 1200: Loss=2.85 Acc@1=27.5 Acc@5=59.58\n",
            "Training 1230: Loss=3.03 Acc@1=20.83 Acc@5=53.33\n",
            "Training 1260: Loss=2.67 Acc@1=32.92 Acc@5=64.17\n",
            "Training 1290: Loss=3.02 Acc@1=23.33 Acc@5=56.67\n",
            "Training 1320: Loss=2.98 Acc@1=25.0 Acc@5=52.5\n",
            "Training 1350: Loss=2.96 Acc@1=27.08 Acc@5=57.08\n",
            "Training 1380: Loss=2.91 Acc@1=28.75 Acc@5=57.08\n",
            "Training 1410: Loss=2.82 Acc@1=32.5 Acc@5=57.08\n",
            "Training 1440: Loss=2.89 Acc@1=26.25 Acc@5=56.25\n",
            "Training 1470: Loss=2.78 Acc@1=30.83 Acc@5=60.0\n",
            "Training 1500: Loss=2.83 Acc@1=30.83 Acc@5=54.17\n",
            "Training 1530: Loss=3.12 Acc@1=22.08 Acc@5=55.0\n",
            "Training 1560: Loss=2.82 Acc@1=28.75 Acc@5=57.92\n",
            "Training 1590: Loss=2.97 Acc@1=26.67 Acc@5=55.0\n",
            "Training 1620: Loss=2.77 Acc@1=29.58 Acc@5=59.17\n",
            "Training 1650: Loss=2.8 Acc@1=31.25 Acc@5=61.25\n",
            "Training 1680: Loss=2.91 Acc@1=23.75 Acc@5=61.25\n",
            "Training 1710: Loss=2.68 Acc@1=35.83 Acc@5=62.08\n",
            "Training 1740: Loss=2.95 Acc@1=24.58 Acc@5=58.75\n",
            "Training 1770: Loss=2.75 Acc@1=32.5 Acc@5=59.17\n",
            "Training 1800: Loss=2.98 Acc@1=23.75 Acc@5=55.42\n",
            "Training 1830: Loss=3.0 Acc@1=27.92 Acc@5=55.83\n",
            "Training 1860: Loss=2.83 Acc@1=27.92 Acc@5=58.75\n",
            "Training 1890: Loss=2.89 Acc@1=28.33 Acc@5=56.25\n",
            "Training 1920: Loss=2.9 Acc@1=27.5 Acc@5=55.83\n",
            "Training 1950: Loss=2.98 Acc@1=28.33 Acc@5=55.83\n",
            "Training 1980: Loss=2.84 Acc@1=29.17 Acc@5=58.33\n",
            "Training 2010: Loss=2.8 Acc@1=32.08 Acc@5=58.75\n",
            "Training 2040: Loss=3.02 Acc@1=26.67 Acc@5=58.33\n",
            "Training 2070: Loss=2.85 Acc@1=27.5 Acc@5=62.08\n",
            "Training 2100: Loss=2.81 Acc@1=29.58 Acc@5=58.33\n",
            "Training 2130: Loss=2.87 Acc@1=32.92 Acc@5=59.17\n",
            "Training 2160: Loss=2.94 Acc@1=27.5 Acc@5=57.08\n",
            "Training 2190: Loss=2.67 Acc@1=31.25 Acc@5=67.08\n",
            "Training 2220: Loss=2.84 Acc@1=30.0 Acc@5=55.83\n",
            "Training 2250: Loss=2.82 Acc@1=29.17 Acc@5=59.17\n",
            "Training 2280: Loss=2.77 Acc@1=30.83 Acc@5=59.58\n",
            "Training 2310: Loss=2.8 Acc@1=28.75 Acc@5=62.92\n",
            "Training 2340: Loss=2.92 Acc@1=27.5 Acc@5=57.92\n",
            "Training 2370: Loss=2.7 Acc@1=34.58 Acc@5=60.42\n",
            "Training 2400: Loss=2.78 Acc@1=30.83 Acc@5=60.42\n",
            "Training 2430: Loss=2.88 Acc@1=30.83 Acc@5=60.42\n",
            "Training 2460: Loss=2.72 Acc@1=30.42 Acc@5=59.58\n",
            "Training 2490: Loss=3.14 Acc@1=22.92 Acc@5=49.58\n",
            "Training 2520: Loss=2.76 Acc@1=27.5 Acc@5=61.25\n",
            "Training 2550: Loss=2.82 Acc@1=33.33 Acc@5=62.08\n",
            "Training 2580: Loss=2.79 Acc@1=32.5 Acc@5=61.25\n",
            "Training 2610: Loss=2.78 Acc@1=30.42 Acc@5=62.08\n",
            "Training 2640: Loss=2.7 Acc@1=32.5 Acc@5=63.75\n",
            "Training 2670: Loss=2.92 Acc@1=25.42 Acc@5=56.25\n",
            "Training 2700: Loss=2.94 Acc@1=27.92 Acc@5=54.17\n",
            "Training 2730: Loss=2.91 Acc@1=24.58 Acc@5=57.92\n",
            "Training 2760: Loss=2.84 Acc@1=28.75 Acc@5=58.33\n",
            "Training 2790: Loss=2.78 Acc@1=28.75 Acc@5=59.58\n",
            "Training 2820: Loss=2.87 Acc@1=30.42 Acc@5=57.08\n",
            "Training 2850: Loss=3.05 Acc@1=25.42 Acc@5=56.25\n",
            "Training 2880: Loss=2.84 Acc@1=30.0 Acc@5=58.33\n",
            "Training 2910: Loss=2.81 Acc@1=28.75 Acc@5=57.08\n",
            "Training 2940: Loss=3.01 Acc@1=30.0 Acc@5=52.5\n",
            "Training 2970: Loss=3.01 Acc@1=27.92 Acc@5=55.83\n",
            "Training 3000: Loss=2.76 Acc@1=27.92 Acc@5=60.83\n",
            "Training 3030: Loss=2.91 Acc@1=29.17 Acc@5=55.83\n",
            "Training 3060: Loss=2.83 Acc@1=34.17 Acc@5=60.0\n",
            "Training 3090: Loss=2.88 Acc@1=25.42 Acc@5=59.17\n",
            "Training 3120: Loss=2.95 Acc@1=25.83 Acc@5=57.08\n",
            "Training 3150: Loss=2.82 Acc@1=29.17 Acc@5=60.83\n",
            "Training 3180: Loss=2.83 Acc@1=27.92 Acc@5=56.67\n",
            "Training 3210: Loss=2.92 Acc@1=27.08 Acc@5=55.42\n",
            "Training 3240: Loss=2.83 Acc@1=26.67 Acc@5=61.67\n",
            "Training 3270: Loss=2.81 Acc@1=28.75 Acc@5=57.92\n",
            "Training 3300: Loss=2.75 Acc@1=31.67 Acc@5=63.75\n",
            "Training 3330: Loss=2.69 Acc@1=29.17 Acc@5=65.0\n",
            "Training 3360: Loss=2.81 Acc@1=27.92 Acc@5=59.58\n",
            "Training 3390: Loss=3.26 Acc@1=23.33 Acc@5=50.0\n",
            "Training 3420: Loss=3.07 Acc@1=27.08 Acc@5=52.5\n",
            "Training 3450: Loss=2.81 Acc@1=30.42 Acc@5=59.17\n",
            "Training 3480: Loss=2.61 Acc@1=32.5 Acc@5=63.33\n",
            "Training 3510: Loss=2.77 Acc@1=27.08 Acc@5=62.92\n",
            "Training 3540: Loss=2.83 Acc@1=29.58 Acc@5=60.0\n",
            "Training 3570: Loss=2.78 Acc@1=29.17 Acc@5=61.67\n",
            "Training 3600: Loss=2.97 Acc@1=27.5 Acc@5=55.83\n",
            "Training 3630: Loss=3.0 Acc@1=23.75 Acc@5=55.0\n",
            "Training 3660: Loss=2.9 Acc@1=26.67 Acc@5=56.67\n",
            "Training 3690: Loss=3.02 Acc@1=27.08 Acc@5=56.67\n",
            "Training 3720: Loss=2.72 Acc@1=31.67 Acc@5=62.92\n",
            "Training 3750: Loss=2.81 Acc@1=27.5 Acc@5=57.92\n",
            "Training 3780: Loss=2.82 Acc@1=25.42 Acc@5=60.83\n",
            "Training 3810: Loss=2.99 Acc@1=25.42 Acc@5=53.33\n",
            "Training 3840: Loss=2.93 Acc@1=28.75 Acc@5=62.08\n",
            "Training 3870: Loss=2.86 Acc@1=25.0 Acc@5=60.83\n",
            "Training 3900: Loss=2.94 Acc@1=25.0 Acc@5=56.25\n",
            "Training 3930: Loss=2.94 Acc@1=25.42 Acc@5=57.5\n",
            "Training 3960: Loss=2.92 Acc@1=30.42 Acc@5=57.08\n",
            "Training 3990: Loss=2.72 Acc@1=29.17 Acc@5=60.83\n",
            "Training 4020: Loss=3.03 Acc@1=23.75 Acc@5=55.0\n",
            "Training 4050: Loss=2.99 Acc@1=27.92 Acc@5=53.75\n",
            "Training 4080: Loss=2.62 Acc@1=33.75 Acc@5=61.25\n",
            "Training 4110: Loss=2.76 Acc@1=27.08 Acc@5=65.0\n",
            "Training 4140: Loss=2.69 Acc@1=34.17 Acc@5=59.58\n",
            "Training 4170: Loss=2.93 Acc@1=29.17 Acc@5=60.0\n",
            "Training 4200: Loss=2.8 Acc@1=30.83 Acc@5=58.75\n",
            "Training 4230: Loss=2.79 Acc@1=30.42 Acc@5=61.67\n",
            "Training 4260: Loss=2.78 Acc@1=25.0 Acc@5=60.42\n",
            "Training 4290: Loss=2.92 Acc@1=30.42 Acc@5=54.58\n",
            "Training 4320: Loss=2.7 Acc@1=29.58 Acc@5=64.17\n",
            "Training 4350: Loss=2.89 Acc@1=31.67 Acc@5=58.33\n",
            "Training 4380: Loss=2.72 Acc@1=29.17 Acc@5=63.75\n",
            "Training 4410: Loss=2.69 Acc@1=29.58 Acc@5=63.75\n",
            "Training 4440: Loss=2.84 Acc@1=26.25 Acc@5=60.83\n",
            "Training 4470: Loss=2.76 Acc@1=31.25 Acc@5=58.75\n",
            "Training 4500: Loss=2.75 Acc@1=30.0 Acc@5=62.92\n",
            "Training 4530: Loss=2.87 Acc@1=29.58 Acc@5=57.92\n",
            "Training 4560: Loss=2.96 Acc@1=22.5 Acc@5=56.25\n",
            "Training 4590: Loss=2.72 Acc@1=31.67 Acc@5=65.0\n",
            "Training 4620: Loss=2.8 Acc@1=28.75 Acc@5=57.5\n",
            "Training 4650: Loss=2.69 Acc@1=30.83 Acc@5=62.08\n",
            "Training 4680: Loss=2.59 Acc@1=34.58 Acc@5=64.58\n",
            "Training 4710: Loss=2.84 Acc@1=26.67 Acc@5=60.42\n",
            "Training 4740: Loss=2.87 Acc@1=27.92 Acc@5=61.25\n",
            "Training 4770: Loss=2.94 Acc@1=27.92 Acc@5=59.17\n",
            "Training 4800: Loss=2.79 Acc@1=32.92 Acc@5=59.17\n",
            "Training 4830: Loss=2.61 Acc@1=36.25 Acc@5=63.33\n",
            "Training 4860: Loss=2.68 Acc@1=30.83 Acc@5=61.67\n",
            "Training 4890: Loss=2.78 Acc@1=32.08 Acc@5=59.58\n",
            "Training 4920: Loss=3.01 Acc@1=26.25 Acc@5=56.25\n",
            "Training 4950: Loss=2.73 Acc@1=27.5 Acc@5=60.42\n",
            "Training 4980: Loss=2.75 Acc@1=31.67 Acc@5=60.0\n",
            "Training 5010: Loss=2.8 Acc@1=29.58 Acc@5=59.58\n",
            "Training 5040: Loss=2.69 Acc@1=27.5 Acc@5=63.75\n",
            "Training 5070: Loss=2.77 Acc@1=33.75 Acc@5=60.0\n",
            "Training 5100: Loss=2.68 Acc@1=32.5 Acc@5=59.58\n",
            "Training 5130: Loss=2.7 Acc@1=31.67 Acc@5=60.0\n",
            "Training 5160: Loss=2.85 Acc@1=28.75 Acc@5=61.67\n",
            "Training 5190: Loss=2.68 Acc@1=27.92 Acc@5=62.08\n",
            "Training 5220: Loss=2.92 Acc@1=30.83 Acc@5=57.08\n",
            "Training 5250: Loss=2.83 Acc@1=26.25 Acc@5=60.42\n",
            "Training 5280: Loss=2.62 Acc@1=31.67 Acc@5=62.08\n",
            "Training 5310: Loss=2.64 Acc@1=31.25 Acc@5=62.08\n",
            "Training 5340: Loss=2.71 Acc@1=32.5 Acc@5=61.67\n",
            "Training 5370: Loss=2.64 Acc@1=30.83 Acc@5=65.0\n",
            "Training 5400: Loss=2.78 Acc@1=33.33 Acc@5=59.58\n",
            "Training 5430: Loss=2.73 Acc@1=29.58 Acc@5=60.83\n",
            "Training 5460: Loss=2.92 Acc@1=30.42 Acc@5=56.67\n",
            "Training 5490: Loss=2.71 Acc@1=29.17 Acc@5=60.83\n",
            "Training 5520: Loss=2.81 Acc@1=30.0 Acc@5=59.17\n",
            "Training 5550: Loss=2.93 Acc@1=27.08 Acc@5=58.33\n",
            "Training 5580: Loss=2.87 Acc@1=28.75 Acc@5=58.75\n",
            "Training 5610: Loss=2.84 Acc@1=27.08 Acc@5=61.25\n",
            "Training 5640: Loss=2.72 Acc@1=31.67 Acc@5=62.08\n",
            "Training 5670: Loss=2.74 Acc@1=32.5 Acc@5=63.75\n",
            "Training 5700: Loss=2.74 Acc@1=34.58 Acc@5=62.08\n",
            "Training 5730: Loss=2.77 Acc@1=32.5 Acc@5=59.58\n",
            "Training 5760: Loss=2.79 Acc@1=29.17 Acc@5=62.5\n",
            "Training 5790: Loss=2.76 Acc@1=25.83 Acc@5=54.17\n",
            "Training 5820: Loss=2.8 Acc@1=32.5 Acc@5=62.08\n",
            "Training 5850: Loss=2.74 Acc@1=32.92 Acc@5=63.33\n",
            "Training 5880: Loss=2.77 Acc@1=32.92 Acc@5=64.17\n",
            "Training 5910: Loss=2.82 Acc@1=33.33 Acc@5=59.17\n",
            "Training 5940: Loss=2.76 Acc@1=32.92 Acc@5=60.42\n",
            "Training 5970: Loss=2.83 Acc@1=31.67 Acc@5=61.25\n",
            "Training 6000: Loss=2.86 Acc@1=29.17 Acc@5=60.42\n",
            "Training 6030: Loss=2.95 Acc@1=26.25 Acc@5=58.75\n",
            "Training 6060: Loss=2.75 Acc@1=32.08 Acc@5=61.67\n",
            "Training 6090: Loss=2.82 Acc@1=31.67 Acc@5=62.08\n",
            "Training 6120: Loss=2.66 Acc@1=33.75 Acc@5=63.75\n",
            "Training 6150: Loss=2.75 Acc@1=32.92 Acc@5=62.5\n",
            "Training 6180: Loss=2.77 Acc@1=29.58 Acc@5=61.25\n",
            "Training 6210: Loss=2.62 Acc@1=33.75 Acc@5=66.67\n",
            "Training 6240: Loss=2.76 Acc@1=33.75 Acc@5=61.67\n",
            "Full imagenet train set: Acc@1=33.75 Acc@5=67.5\n",
            "Epoch: 4 ######################################################\n",
            "Training 30: Loss=2.64 Acc@1=32.5 Acc@5=63.75\n",
            "Training 60: Loss=2.71 Acc@1=35.42 Acc@5=64.17\n",
            "Training 90: Loss=2.64 Acc@1=32.08 Acc@5=61.67\n",
            "Training 120: Loss=2.49 Acc@1=36.25 Acc@5=69.17\n",
            "Training 150: Loss=2.59 Acc@1=35.42 Acc@5=67.5\n",
            "Training 180: Loss=2.62 Acc@1=31.67 Acc@5=62.5\n",
            "Training 210: Loss=2.6 Acc@1=29.58 Acc@5=62.92\n",
            "Training 240: Loss=2.67 Acc@1=29.58 Acc@5=64.17\n",
            "Training 270: Loss=2.76 Acc@1=30.42 Acc@5=59.58\n",
            "Training 300: Loss=2.53 Acc@1=36.25 Acc@5=63.33\n",
            "Training 330: Loss=2.65 Acc@1=39.58 Acc@5=62.5\n",
            "Training 360: Loss=2.72 Acc@1=31.67 Acc@5=60.42\n",
            "Training 390: Loss=2.62 Acc@1=33.75 Acc@5=65.42\n",
            "Training 420: Loss=2.63 Acc@1=34.58 Acc@5=64.58\n",
            "Training 450: Loss=2.63 Acc@1=34.17 Acc@5=65.42\n",
            "Training 480: Loss=2.6 Acc@1=35.0 Acc@5=63.33\n",
            "Training 510: Loss=2.8 Acc@1=31.25 Acc@5=61.67\n",
            "Training 540: Loss=2.51 Acc@1=34.17 Acc@5=64.58\n",
            "Training 570: Loss=2.81 Acc@1=25.0 Acc@5=58.33\n",
            "Training 600: Loss=2.86 Acc@1=29.58 Acc@5=57.08\n",
            "Training 630: Loss=2.94 Acc@1=27.08 Acc@5=56.25\n",
            "Training 660: Loss=2.64 Acc@1=36.25 Acc@5=60.83\n",
            "Training 690: Loss=2.62 Acc@1=30.83 Acc@5=66.25\n",
            "Training 720: Loss=2.45 Acc@1=35.83 Acc@5=70.83\n",
            "Training 750: Loss=2.86 Acc@1=27.5 Acc@5=57.92\n",
            "Training 780: Loss=2.51 Acc@1=33.33 Acc@5=68.75\n",
            "Training 810: Loss=2.62 Acc@1=33.75 Acc@5=62.5\n",
            "Training 840: Loss=2.73 Acc@1=34.58 Acc@5=61.25\n",
            "Training 870: Loss=2.88 Acc@1=28.33 Acc@5=58.33\n",
            "Training 900: Loss=2.82 Acc@1=29.17 Acc@5=58.33\n",
            "Training 930: Loss=2.64 Acc@1=32.5 Acc@5=63.33\n",
            "Training 960: Loss=2.76 Acc@1=34.17 Acc@5=60.83\n",
            "Training 990: Loss=2.62 Acc@1=30.42 Acc@5=65.42\n",
            "Training 1020: Loss=2.48 Acc@1=35.83 Acc@5=66.25\n",
            "Training 1050: Loss=2.49 Acc@1=35.83 Acc@5=66.25\n",
            "Training 1080: Loss=2.77 Acc@1=30.0 Acc@5=61.67\n",
            "Training 1110: Loss=2.69 Acc@1=34.58 Acc@5=59.58\n",
            "Training 1140: Loss=2.72 Acc@1=32.92 Acc@5=60.42\n",
            "Training 1170: Loss=2.82 Acc@1=26.67 Acc@5=61.67\n",
            "Training 1200: Loss=2.85 Acc@1=26.25 Acc@5=56.25\n",
            "Training 1230: Loss=2.62 Acc@1=32.92 Acc@5=67.92\n",
            "Training 1260: Loss=2.78 Acc@1=29.17 Acc@5=60.83\n",
            "Training 1290: Loss=2.68 Acc@1=32.08 Acc@5=61.25\n",
            "Training 1320: Loss=2.8 Acc@1=25.83 Acc@5=59.17\n",
            "Training 1350: Loss=2.72 Acc@1=33.33 Acc@5=60.83\n",
            "Training 1380: Loss=2.69 Acc@1=30.42 Acc@5=62.92\n",
            "Training 1410: Loss=2.57 Acc@1=32.5 Acc@5=64.58\n",
            "Training 1440: Loss=2.87 Acc@1=28.75 Acc@5=59.17\n",
            "Training 1470: Loss=2.79 Acc@1=32.5 Acc@5=59.17\n",
            "Training 1500: Loss=2.7 Acc@1=34.17 Acc@5=62.08\n",
            "Training 1530: Loss=2.64 Acc@1=36.67 Acc@5=63.75\n",
            "Training 1560: Loss=2.55 Acc@1=34.58 Acc@5=67.5\n",
            "Training 1590: Loss=2.58 Acc@1=32.5 Acc@5=67.92\n",
            "Training 1620: Loss=2.66 Acc@1=29.17 Acc@5=65.42\n",
            "Training 1650: Loss=2.48 Acc@1=37.08 Acc@5=69.58\n",
            "Training 1680: Loss=2.56 Acc@1=36.67 Acc@5=61.67\n",
            "Training 1710: Loss=2.72 Acc@1=27.92 Acc@5=62.08\n",
            "Training 1740: Loss=2.63 Acc@1=31.67 Acc@5=60.83\n",
            "Training 1770: Loss=2.67 Acc@1=32.92 Acc@5=62.5\n",
            "Training 1800: Loss=2.72 Acc@1=32.92 Acc@5=63.33\n",
            "Training 1830: Loss=2.85 Acc@1=28.75 Acc@5=56.25\n",
            "Training 1860: Loss=2.48 Acc@1=39.58 Acc@5=67.08\n",
            "Training 1890: Loss=2.78 Acc@1=31.67 Acc@5=63.75\n",
            "Training 1920: Loss=2.78 Acc@1=32.92 Acc@5=62.08\n",
            "Training 1950: Loss=2.7 Acc@1=29.17 Acc@5=63.33\n",
            "Training 1980: Loss=2.76 Acc@1=29.17 Acc@5=62.92\n",
            "Training 2010: Loss=2.45 Acc@1=34.58 Acc@5=67.5\n",
            "Training 2040: Loss=2.97 Acc@1=30.83 Acc@5=57.5\n",
            "Training 2070: Loss=2.71 Acc@1=27.92 Acc@5=65.0\n",
            "Training 2100: Loss=2.59 Acc@1=33.75 Acc@5=65.0\n",
            "Training 2130: Loss=2.63 Acc@1=36.25 Acc@5=64.58\n",
            "Training 2160: Loss=2.83 Acc@1=34.58 Acc@5=57.5\n",
            "Training 2190: Loss=2.96 Acc@1=28.33 Acc@5=54.17\n",
            "Training 2220: Loss=2.71 Acc@1=29.17 Acc@5=59.17\n",
            "Training 2250: Loss=2.74 Acc@1=27.5 Acc@5=60.83\n",
            "Training 2280: Loss=2.66 Acc@1=32.92 Acc@5=63.33\n",
            "Training 2310: Loss=2.91 Acc@1=28.75 Acc@5=57.92\n",
            "Training 2340: Loss=2.7 Acc@1=33.33 Acc@5=64.58\n",
            "Training 2370: Loss=2.63 Acc@1=31.25 Acc@5=64.58\n",
            "Training 2400: Loss=2.7 Acc@1=33.33 Acc@5=62.5\n",
            "Training 2430: Loss=2.73 Acc@1=34.17 Acc@5=55.42\n",
            "Training 2460: Loss=2.73 Acc@1=30.0 Acc@5=62.5\n",
            "Training 2490: Loss=2.68 Acc@1=31.67 Acc@5=64.17\n",
            "Training 2520: Loss=2.69 Acc@1=35.0 Acc@5=62.5\n",
            "Training 2550: Loss=2.8 Acc@1=31.25 Acc@5=56.67\n",
            "Training 2580: Loss=2.71 Acc@1=29.17 Acc@5=60.83\n",
            "Training 2610: Loss=2.65 Acc@1=31.25 Acc@5=60.42\n",
            "Training 2640: Loss=2.64 Acc@1=34.58 Acc@5=62.92\n",
            "Training 2670: Loss=2.62 Acc@1=33.33 Acc@5=58.75\n",
            "Training 2700: Loss=2.59 Acc@1=32.5 Acc@5=63.75\n",
            "Training 2730: Loss=2.61 Acc@1=32.5 Acc@5=60.83\n",
            "Training 2760: Loss=2.58 Acc@1=35.83 Acc@5=66.25\n",
            "Training 2790: Loss=2.55 Acc@1=33.33 Acc@5=65.0\n",
            "Training 2820: Loss=2.66 Acc@1=30.83 Acc@5=63.33\n",
            "Training 2850: Loss=2.77 Acc@1=27.92 Acc@5=57.08\n",
            "Training 2880: Loss=2.74 Acc@1=34.58 Acc@5=59.58\n",
            "Training 2910: Loss=2.59 Acc@1=33.75 Acc@5=62.92\n",
            "Training 2940: Loss=2.71 Acc@1=27.92 Acc@5=62.92\n",
            "Training 2970: Loss=2.7 Acc@1=30.83 Acc@5=62.92\n",
            "Training 3000: Loss=2.66 Acc@1=31.25 Acc@5=61.67\n",
            "Training 3030: Loss=2.49 Acc@1=36.67 Acc@5=62.5\n",
            "Training 3060: Loss=2.47 Acc@1=37.5 Acc@5=68.75\n",
            "Training 3090: Loss=2.8 Acc@1=30.42 Acc@5=61.67\n",
            "Training 3120: Loss=2.83 Acc@1=31.67 Acc@5=58.33\n",
            "Training 3150: Loss=2.61 Acc@1=36.25 Acc@5=63.75\n",
            "Training 3180: Loss=2.78 Acc@1=30.83 Acc@5=58.75\n",
            "Training 3210: Loss=2.63 Acc@1=35.42 Acc@5=62.08\n",
            "Training 3240: Loss=2.61 Acc@1=37.08 Acc@5=63.33\n",
            "Training 3270: Loss=2.7 Acc@1=30.42 Acc@5=63.33\n",
            "Training 3300: Loss=2.55 Acc@1=35.83 Acc@5=63.33\n",
            "Training 3330: Loss=2.91 Acc@1=25.0 Acc@5=60.0\n",
            "Training 3360: Loss=2.73 Acc@1=35.83 Acc@5=61.67\n",
            "Training 3390: Loss=2.68 Acc@1=32.5 Acc@5=64.58\n",
            "Training 3420: Loss=2.56 Acc@1=37.08 Acc@5=63.33\n",
            "Training 3450: Loss=2.48 Acc@1=38.33 Acc@5=67.08\n",
            "Training 3480: Loss=2.66 Acc@1=32.5 Acc@5=62.5\n",
            "Training 3510: Loss=2.57 Acc@1=34.58 Acc@5=64.58\n",
            "Training 3540: Loss=2.57 Acc@1=37.08 Acc@5=66.67\n",
            "Training 3570: Loss=3.02 Acc@1=26.25 Acc@5=56.67\n",
            "Training 3600: Loss=2.73 Acc@1=28.75 Acc@5=62.92\n",
            "Training 3630: Loss=2.76 Acc@1=34.17 Acc@5=61.25\n",
            "Training 3660: Loss=2.65 Acc@1=32.5 Acc@5=60.0\n",
            "Training 3690: Loss=2.62 Acc@1=33.75 Acc@5=63.75\n",
            "Training 3720: Loss=2.81 Acc@1=29.17 Acc@5=56.25\n",
            "Training 3750: Loss=2.78 Acc@1=30.0 Acc@5=58.33\n",
            "Training 3780: Loss=2.84 Acc@1=28.75 Acc@5=61.25\n",
            "Training 3810: Loss=2.72 Acc@1=31.25 Acc@5=60.83\n",
            "Training 3840: Loss=2.66 Acc@1=29.17 Acc@5=61.67\n",
            "Training 3870: Loss=2.52 Acc@1=35.0 Acc@5=66.67\n",
            "Training 3900: Loss=2.68 Acc@1=30.42 Acc@5=66.67\n",
            "Training 3930: Loss=2.74 Acc@1=28.33 Acc@5=58.75\n",
            "Training 3960: Loss=2.91 Acc@1=29.58 Acc@5=56.25\n",
            "Training 3990: Loss=2.53 Acc@1=36.67 Acc@5=64.58\n",
            "Training 4020: Loss=2.78 Acc@1=30.0 Acc@5=58.75\n",
            "Training 4050: Loss=2.73 Acc@1=33.75 Acc@5=61.67\n",
            "Training 4080: Loss=2.82 Acc@1=28.33 Acc@5=57.92\n",
            "Training 4110: Loss=2.82 Acc@1=26.67 Acc@5=60.42\n",
            "Training 4140: Loss=2.85 Acc@1=30.83 Acc@5=63.75\n",
            "Training 4170: Loss=2.73 Acc@1=32.08 Acc@5=60.42\n",
            "Training 4200: Loss=2.56 Acc@1=31.67 Acc@5=65.83\n",
            "Training 4230: Loss=2.49 Acc@1=33.33 Acc@5=63.75\n",
            "Training 4260: Loss=2.71 Acc@1=30.42 Acc@5=64.17\n",
            "Training 4290: Loss=2.55 Acc@1=29.58 Acc@5=65.0\n",
            "Training 4320: Loss=2.63 Acc@1=30.0 Acc@5=67.08\n",
            "Training 4350: Loss=2.78 Acc@1=31.67 Acc@5=59.17\n",
            "Training 4380: Loss=2.54 Acc@1=36.67 Acc@5=67.08\n",
            "Training 4410: Loss=2.65 Acc@1=33.75 Acc@5=64.58\n",
            "Training 4440: Loss=2.65 Acc@1=35.83 Acc@5=60.83\n",
            "Training 4470: Loss=2.66 Acc@1=31.67 Acc@5=61.67\n",
            "Training 4500: Loss=2.48 Acc@1=38.75 Acc@5=68.33\n",
            "Training 4530: Loss=2.5 Acc@1=34.58 Acc@5=65.83\n",
            "Training 4560: Loss=2.66 Acc@1=35.42 Acc@5=64.17\n",
            "Training 4590: Loss=2.7 Acc@1=30.83 Acc@5=65.0\n",
            "Training 4620: Loss=2.59 Acc@1=32.92 Acc@5=65.42\n",
            "Training 4650: Loss=2.84 Acc@1=29.17 Acc@5=60.83\n",
            "Training 4680: Loss=2.7 Acc@1=30.42 Acc@5=63.33\n",
            "Training 4710: Loss=2.67 Acc@1=32.5 Acc@5=61.25\n",
            "Training 4740: Loss=2.75 Acc@1=30.42 Acc@5=65.0\n",
            "Training 4770: Loss=2.73 Acc@1=32.5 Acc@5=64.17\n",
            "Training 4800: Loss=2.65 Acc@1=33.33 Acc@5=63.33\n",
            "Training 4830: Loss=2.56 Acc@1=34.58 Acc@5=66.25\n",
            "Training 4860: Loss=2.85 Acc@1=31.25 Acc@5=57.5\n",
            "Training 4890: Loss=2.55 Acc@1=35.83 Acc@5=64.17\n",
            "Training 4920: Loss=2.65 Acc@1=33.33 Acc@5=62.5\n",
            "Training 4950: Loss=2.6 Acc@1=36.67 Acc@5=65.83\n",
            "Training 4980: Loss=2.77 Acc@1=32.5 Acc@5=61.67\n",
            "Training 5010: Loss=2.7 Acc@1=33.33 Acc@5=62.5\n",
            "Training 5040: Loss=2.74 Acc@1=30.42 Acc@5=65.83\n",
            "Training 5070: Loss=2.72 Acc@1=28.33 Acc@5=61.25\n",
            "Training 5100: Loss=2.78 Acc@1=31.25 Acc@5=59.17\n",
            "Training 5130: Loss=2.74 Acc@1=33.75 Acc@5=61.67\n",
            "Training 5160: Loss=2.64 Acc@1=32.92 Acc@5=63.75\n",
            "Training 5190: Loss=2.58 Acc@1=34.58 Acc@5=62.92\n",
            "Training 5220: Loss=2.69 Acc@1=32.92 Acc@5=66.25\n",
            "Training 5250: Loss=2.47 Acc@1=37.08 Acc@5=66.67\n",
            "Training 5280: Loss=2.62 Acc@1=36.25 Acc@5=67.5\n",
            "Training 5310: Loss=2.45 Acc@1=36.67 Acc@5=64.58\n",
            "Training 5340: Loss=2.73 Acc@1=32.92 Acc@5=61.25\n",
            "Training 5370: Loss=2.55 Acc@1=33.75 Acc@5=65.83\n",
            "Training 5400: Loss=2.42 Acc@1=38.33 Acc@5=72.08\n",
            "Training 5430: Loss=2.59 Acc@1=31.25 Acc@5=66.67\n",
            "Training 5460: Loss=2.56 Acc@1=32.08 Acc@5=65.83\n",
            "Training 5490: Loss=2.64 Acc@1=32.5 Acc@5=65.0\n",
            "Training 5520: Loss=2.58 Acc@1=32.08 Acc@5=60.83\n",
            "Training 5550: Loss=2.56 Acc@1=37.08 Acc@5=67.08\n",
            "Training 5580: Loss=2.7 Acc@1=31.67 Acc@5=61.67\n",
            "Training 5610: Loss=2.61 Acc@1=36.25 Acc@5=66.25\n",
            "Training 5640: Loss=2.67 Acc@1=34.58 Acc@5=63.33\n",
            "Training 5670: Loss=2.47 Acc@1=37.5 Acc@5=66.25\n",
            "Training 5700: Loss=2.61 Acc@1=28.33 Acc@5=65.42\n",
            "Training 5730: Loss=2.68 Acc@1=35.42 Acc@5=64.58\n",
            "Training 5760: Loss=2.57 Acc@1=35.42 Acc@5=63.33\n",
            "Training 5790: Loss=2.55 Acc@1=35.42 Acc@5=64.58\n",
            "Training 5820: Loss=2.44 Acc@1=31.67 Acc@5=67.08\n",
            "Training 5850: Loss=2.69 Acc@1=28.75 Acc@5=64.58\n",
            "Training 5880: Loss=2.61 Acc@1=34.17 Acc@5=67.5\n",
            "Training 5910: Loss=2.47 Acc@1=38.75 Acc@5=67.08\n",
            "Training 5940: Loss=2.59 Acc@1=34.17 Acc@5=66.25\n",
            "Training 5970: Loss=2.59 Acc@1=32.08 Acc@5=65.42\n",
            "Training 6000: Loss=2.57 Acc@1=33.75 Acc@5=65.0\n",
            "Training 6030: Loss=2.6 Acc@1=35.42 Acc@5=66.67\n",
            "Training 6060: Loss=2.71 Acc@1=32.08 Acc@5=60.83\n",
            "Training 6090: Loss=2.61 Acc@1=35.0 Acc@5=67.5\n",
            "Training 6120: Loss=2.46 Acc@1=41.25 Acc@5=64.58\n",
            "Training 6150: Loss=2.58 Acc@1=32.08 Acc@5=66.67\n",
            "Training 6180: Loss=2.73 Acc@1=32.5 Acc@5=60.0\n",
            "Training 6210: Loss=2.68 Acc@1=36.25 Acc@5=61.25\n",
            "Training 6240: Loss=2.55 Acc@1=34.58 Acc@5=66.25\n",
            "Full imagenet train set: Acc@1=40.0 Acc@5=71.25\n",
            "Epoch: 5 ######################################################\n",
            "Training 30: Loss=2.51 Acc@1=35.42 Acc@5=65.42\n",
            "Training 60: Loss=2.51 Acc@1=37.08 Acc@5=66.25\n",
            "Training 90: Loss=2.44 Acc@1=36.67 Acc@5=72.92\n",
            "Training 120: Loss=2.51 Acc@1=37.5 Acc@5=63.75\n",
            "Training 150: Loss=2.52 Acc@1=37.08 Acc@5=69.17\n",
            "Training 180: Loss=2.59 Acc@1=30.42 Acc@5=63.33\n",
            "Training 210: Loss=2.62 Acc@1=34.58 Acc@5=64.58\n",
            "Training 240: Loss=2.47 Acc@1=36.25 Acc@5=69.17\n",
            "Training 270: Loss=2.55 Acc@1=35.42 Acc@5=66.25\n",
            "Training 300: Loss=2.3 Acc@1=41.67 Acc@5=72.5\n",
            "Training 330: Loss=2.69 Acc@1=29.17 Acc@5=62.5\n",
            "Training 360: Loss=2.37 Acc@1=40.0 Acc@5=69.58\n",
            "Training 390: Loss=2.28 Acc@1=41.25 Acc@5=72.5\n",
            "Training 420: Loss=2.38 Acc@1=42.5 Acc@5=71.25\n",
            "Training 450: Loss=2.45 Acc@1=37.5 Acc@5=70.0\n",
            "Training 480: Loss=2.55 Acc@1=33.33 Acc@5=67.08\n",
            "Training 510: Loss=2.54 Acc@1=35.0 Acc@5=65.0\n",
            "Training 540: Loss=2.3 Acc@1=40.0 Acc@5=72.08\n",
            "Training 570: Loss=2.49 Acc@1=35.42 Acc@5=66.25\n",
            "Training 600: Loss=2.56 Acc@1=32.08 Acc@5=66.67\n",
            "Training 630: Loss=2.51 Acc@1=33.75 Acc@5=70.42\n",
            "Training 660: Loss=2.35 Acc@1=38.75 Acc@5=68.33\n",
            "Training 690: Loss=2.34 Acc@1=41.25 Acc@5=67.92\n",
            "Training 720: Loss=2.56 Acc@1=34.58 Acc@5=68.33\n",
            "Training 750: Loss=2.62 Acc@1=35.0 Acc@5=62.92\n",
            "Training 780: Loss=2.48 Acc@1=40.83 Acc@5=66.67\n",
            "Training 810: Loss=2.54 Acc@1=38.75 Acc@5=67.08\n",
            "Training 840: Loss=2.7 Acc@1=33.33 Acc@5=61.25\n",
            "Training 870: Loss=2.53 Acc@1=35.0 Acc@5=63.75\n",
            "Training 900: Loss=2.72 Acc@1=32.08 Acc@5=61.25\n",
            "Training 930: Loss=2.47 Acc@1=40.0 Acc@5=70.0\n",
            "Training 960: Loss=2.54 Acc@1=34.58 Acc@5=65.42\n",
            "Training 990: Loss=2.61 Acc@1=32.92 Acc@5=65.42\n",
            "Training 1020: Loss=2.53 Acc@1=37.5 Acc@5=65.0\n",
            "Training 1050: Loss=2.53 Acc@1=37.5 Acc@5=61.67\n",
            "Training 1080: Loss=2.52 Acc@1=42.08 Acc@5=64.17\n",
            "Training 1110: Loss=2.39 Acc@1=36.25 Acc@5=68.75\n",
            "Training 1140: Loss=2.54 Acc@1=34.17 Acc@5=64.58\n",
            "Training 1170: Loss=2.51 Acc@1=37.92 Acc@5=65.42\n",
            "Training 1200: Loss=2.72 Acc@1=29.58 Acc@5=62.92\n",
            "Training 1230: Loss=2.52 Acc@1=36.25 Acc@5=69.58\n",
            "Training 1260: Loss=2.69 Acc@1=33.33 Acc@5=59.17\n",
            "Training 1290: Loss=2.46 Acc@1=37.5 Acc@5=66.67\n",
            "Training 1320: Loss=2.51 Acc@1=35.42 Acc@5=65.0\n",
            "Training 1350: Loss=2.58 Acc@1=35.42 Acc@5=64.17\n",
            "Training 1380: Loss=2.57 Acc@1=31.67 Acc@5=67.5\n",
            "Training 1410: Loss=2.28 Acc@1=40.83 Acc@5=72.5\n",
            "Training 1440: Loss=2.39 Acc@1=36.67 Acc@5=69.17\n",
            "Training 1470: Loss=2.73 Acc@1=29.17 Acc@5=62.92\n",
            "Training 1500: Loss=2.43 Acc@1=34.17 Acc@5=71.67\n",
            "Training 1530: Loss=2.58 Acc@1=34.17 Acc@5=68.33\n",
            "Training 1560: Loss=2.63 Acc@1=32.08 Acc@5=65.83\n",
            "Training 1590: Loss=2.36 Acc@1=40.42 Acc@5=71.25\n",
            "Training 1620: Loss=2.71 Acc@1=32.92 Acc@5=63.75\n",
            "Training 1650: Loss=2.56 Acc@1=34.58 Acc@5=68.75\n",
            "Training 1680: Loss=2.67 Acc@1=29.17 Acc@5=62.08\n",
            "Training 1710: Loss=2.48 Acc@1=36.25 Acc@5=67.92\n",
            "Training 1740: Loss=2.61 Acc@1=36.67 Acc@5=62.92\n",
            "Training 1770: Loss=2.58 Acc@1=33.75 Acc@5=62.5\n",
            "Training 1800: Loss=2.77 Acc@1=29.58 Acc@5=58.33\n",
            "Training 1830: Loss=2.48 Acc@1=36.67 Acc@5=69.17\n",
            "Training 1860: Loss=2.76 Acc@1=34.58 Acc@5=62.92\n",
            "Training 1890: Loss=2.57 Acc@1=40.42 Acc@5=64.58\n",
            "Training 1920: Loss=2.72 Acc@1=30.83 Acc@5=60.0\n",
            "Training 1950: Loss=2.53 Acc@1=32.5 Acc@5=67.08\n",
            "Training 1980: Loss=2.54 Acc@1=35.83 Acc@5=67.08\n",
            "Training 2010: Loss=2.63 Acc@1=34.58 Acc@5=59.58\n",
            "Training 2040: Loss=2.49 Acc@1=35.83 Acc@5=68.75\n",
            "Training 2070: Loss=2.29 Acc@1=37.08 Acc@5=74.58\n",
            "Training 2100: Loss=2.6 Acc@1=38.33 Acc@5=65.83\n",
            "Training 2130: Loss=2.47 Acc@1=35.83 Acc@5=67.08\n",
            "Training 2160: Loss=2.5 Acc@1=37.92 Acc@5=65.83\n",
            "Training 2190: Loss=2.52 Acc@1=36.67 Acc@5=65.0\n",
            "Training 2220: Loss=2.4 Acc@1=35.0 Acc@5=66.67\n",
            "Training 2250: Loss=2.62 Acc@1=30.0 Acc@5=62.08\n",
            "Training 2280: Loss=2.57 Acc@1=36.25 Acc@5=65.0\n",
            "Training 2310: Loss=2.64 Acc@1=33.33 Acc@5=61.25\n",
            "Training 2340: Loss=2.42 Acc@1=40.42 Acc@5=69.17\n",
            "Training 2370: Loss=2.47 Acc@1=37.5 Acc@5=67.08\n",
            "Training 2400: Loss=2.58 Acc@1=34.17 Acc@5=67.5\n",
            "Training 2430: Loss=2.56 Acc@1=32.08 Acc@5=67.5\n",
            "Training 2460: Loss=2.46 Acc@1=37.92 Acc@5=67.08\n",
            "Training 2490: Loss=2.55 Acc@1=35.42 Acc@5=62.5\n",
            "Training 2520: Loss=2.7 Acc@1=33.33 Acc@5=64.58\n",
            "Training 2550: Loss=2.53 Acc@1=33.75 Acc@5=62.92\n",
            "Training 2580: Loss=2.65 Acc@1=36.25 Acc@5=65.42\n",
            "Training 2610: Loss=2.5 Acc@1=39.17 Acc@5=65.83\n",
            "Training 2640: Loss=2.37 Acc@1=37.5 Acc@5=70.42\n",
            "Training 2670: Loss=2.65 Acc@1=33.33 Acc@5=63.75\n",
            "Training 2700: Loss=2.46 Acc@1=36.67 Acc@5=71.25\n",
            "Training 2730: Loss=2.56 Acc@1=36.67 Acc@5=65.42\n",
            "Training 2760: Loss=2.49 Acc@1=33.75 Acc@5=67.08\n",
            "Training 2790: Loss=2.64 Acc@1=32.5 Acc@5=60.83\n",
            "Training 2820: Loss=2.58 Acc@1=36.25 Acc@5=65.42\n",
            "Training 2850: Loss=2.39 Acc@1=37.92 Acc@5=69.17\n",
            "Training 2880: Loss=2.41 Acc@1=38.75 Acc@5=69.17\n",
            "Training 2910: Loss=2.39 Acc@1=37.5 Acc@5=68.75\n",
            "Training 2940: Loss=2.53 Acc@1=35.83 Acc@5=63.33\n",
            "Training 2970: Loss=2.51 Acc@1=33.33 Acc@5=66.67\n",
            "Training 3000: Loss=2.25 Acc@1=41.25 Acc@5=74.17\n",
            "Training 3030: Loss=2.68 Acc@1=34.17 Acc@5=66.25\n",
            "Training 3060: Loss=2.33 Acc@1=40.83 Acc@5=71.25\n",
            "Training 3090: Loss=2.36 Acc@1=41.67 Acc@5=68.75\n",
            "Training 3120: Loss=2.6 Acc@1=34.58 Acc@5=63.33\n",
            "Training 3150: Loss=2.42 Acc@1=40.83 Acc@5=67.5\n",
            "Training 3180: Loss=2.58 Acc@1=37.08 Acc@5=62.08\n",
            "Training 3210: Loss=2.53 Acc@1=40.83 Acc@5=67.08\n",
            "Training 3240: Loss=2.45 Acc@1=32.92 Acc@5=67.5\n",
            "Training 3270: Loss=2.47 Acc@1=36.25 Acc@5=67.08\n",
            "Training 3300: Loss=2.61 Acc@1=34.58 Acc@5=63.75\n",
            "Training 3330: Loss=2.78 Acc@1=30.83 Acc@5=58.75\n",
            "Training 3360: Loss=2.51 Acc@1=34.17 Acc@5=65.0\n",
            "Training 3390: Loss=2.62 Acc@1=40.42 Acc@5=62.92\n",
            "Training 3420: Loss=2.35 Acc@1=40.83 Acc@5=65.83\n",
            "Training 3450: Loss=2.67 Acc@1=29.58 Acc@5=64.17\n",
            "Training 3480: Loss=2.88 Acc@1=26.25 Acc@5=60.83\n",
            "Training 3510: Loss=2.45 Acc@1=33.75 Acc@5=66.67\n",
            "Training 3540: Loss=2.56 Acc@1=34.17 Acc@5=68.33\n",
            "Training 3570: Loss=2.51 Acc@1=33.75 Acc@5=61.67\n",
            "Training 3600: Loss=2.5 Acc@1=35.0 Acc@5=65.0\n",
            "Training 3630: Loss=2.47 Acc@1=36.67 Acc@5=67.5\n",
            "Training 3660: Loss=2.74 Acc@1=30.0 Acc@5=63.33\n",
            "Training 3690: Loss=2.45 Acc@1=36.67 Acc@5=66.67\n",
            "Training 3720: Loss=2.6 Acc@1=33.33 Acc@5=64.58\n",
            "Training 3750: Loss=2.5 Acc@1=37.08 Acc@5=65.83\n",
            "Training 3780: Loss=2.46 Acc@1=35.0 Acc@5=70.42\n",
            "Training 3810: Loss=2.42 Acc@1=41.25 Acc@5=68.75\n",
            "Training 3840: Loss=2.53 Acc@1=34.17 Acc@5=63.75\n",
            "Training 3870: Loss=2.64 Acc@1=30.0 Acc@5=67.92\n",
            "Training 3900: Loss=2.49 Acc@1=32.5 Acc@5=70.42\n",
            "Training 3930: Loss=2.5 Acc@1=39.17 Acc@5=68.75\n",
            "Training 3960: Loss=2.59 Acc@1=35.83 Acc@5=62.92\n",
            "Training 3990: Loss=2.66 Acc@1=33.75 Acc@5=62.5\n",
            "Training 4020: Loss=2.52 Acc@1=37.08 Acc@5=67.08\n",
            "Training 4050: Loss=2.58 Acc@1=34.17 Acc@5=68.75\n",
            "Training 4080: Loss=2.41 Acc@1=36.67 Acc@5=68.33\n",
            "Training 4110: Loss=2.37 Acc@1=39.17 Acc@5=69.58\n",
            "Training 4140: Loss=2.58 Acc@1=35.83 Acc@5=64.58\n",
            "Training 4170: Loss=2.49 Acc@1=32.92 Acc@5=68.33\n",
            "Training 4200: Loss=2.55 Acc@1=33.75 Acc@5=64.17\n",
            "Training 4230: Loss=2.45 Acc@1=38.75 Acc@5=69.17\n",
            "Training 4260: Loss=2.39 Acc@1=35.83 Acc@5=70.83\n",
            "Training 4290: Loss=2.45 Acc@1=35.83 Acc@5=67.92\n",
            "Training 4320: Loss=2.36 Acc@1=38.33 Acc@5=67.08\n",
            "Training 4350: Loss=2.65 Acc@1=30.83 Acc@5=62.92\n",
            "Training 4380: Loss=2.46 Acc@1=38.75 Acc@5=66.67\n",
            "Training 4410: Loss=2.67 Acc@1=33.75 Acc@5=63.75\n",
            "Training 4440: Loss=2.53 Acc@1=35.0 Acc@5=67.08\n",
            "Training 4470: Loss=2.74 Acc@1=30.0 Acc@5=63.33\n",
            "Training 4500: Loss=2.4 Acc@1=39.58 Acc@5=69.17\n",
            "Training 4530: Loss=2.46 Acc@1=34.58 Acc@5=66.67\n",
            "Training 4560: Loss=2.42 Acc@1=36.25 Acc@5=70.0\n",
            "Training 4590: Loss=2.59 Acc@1=35.42 Acc@5=65.83\n",
            "Training 4620: Loss=2.33 Acc@1=37.08 Acc@5=71.25\n",
            "Training 4650: Loss=2.37 Acc@1=39.58 Acc@5=69.17\n",
            "Training 4680: Loss=2.66 Acc@1=35.42 Acc@5=65.42\n",
            "Training 4710: Loss=2.71 Acc@1=30.42 Acc@5=60.83\n",
            "Training 4740: Loss=2.66 Acc@1=32.5 Acc@5=64.17\n",
            "Training 4770: Loss=2.77 Acc@1=34.58 Acc@5=61.67\n",
            "Training 4800: Loss=2.31 Acc@1=39.17 Acc@5=73.75\n",
            "Training 4830: Loss=2.28 Acc@1=42.5 Acc@5=71.25\n",
            "Training 4860: Loss=2.38 Acc@1=36.25 Acc@5=66.25\n",
            "Training 4890: Loss=2.59 Acc@1=35.42 Acc@5=65.0\n",
            "Training 4920: Loss=2.49 Acc@1=34.17 Acc@5=63.75\n",
            "Training 4950: Loss=2.42 Acc@1=35.42 Acc@5=66.67\n",
            "Training 4980: Loss=2.48 Acc@1=37.5 Acc@5=66.67\n",
            "Training 5010: Loss=2.5 Acc@1=37.5 Acc@5=68.33\n",
            "Training 5040: Loss=2.61 Acc@1=30.83 Acc@5=67.5\n",
            "Training 5070: Loss=2.69 Acc@1=29.58 Acc@5=60.83\n",
            "Training 5100: Loss=2.7 Acc@1=34.58 Acc@5=63.33\n",
            "Training 5130: Loss=2.74 Acc@1=32.92 Acc@5=60.42\n",
            "Training 5160: Loss=2.45 Acc@1=36.67 Acc@5=66.25\n",
            "Training 5190: Loss=2.61 Acc@1=32.08 Acc@5=65.42\n",
            "Training 5220: Loss=2.45 Acc@1=36.67 Acc@5=67.08\n",
            "Training 5250: Loss=2.51 Acc@1=33.75 Acc@5=68.33\n",
            "Training 5280: Loss=2.49 Acc@1=37.5 Acc@5=66.67\n",
            "Training 5310: Loss=2.54 Acc@1=31.25 Acc@5=67.08\n",
            "Training 5340: Loss=2.58 Acc@1=34.17 Acc@5=61.67\n",
            "Training 5370: Loss=2.71 Acc@1=35.0 Acc@5=60.0\n",
            "Training 5400: Loss=2.54 Acc@1=36.25 Acc@5=63.75\n",
            "Training 5430: Loss=2.4 Acc@1=36.67 Acc@5=65.83\n",
            "Training 5460: Loss=2.44 Acc@1=36.25 Acc@5=67.5\n",
            "Training 5490: Loss=2.45 Acc@1=36.67 Acc@5=66.67\n",
            "Training 5520: Loss=2.55 Acc@1=35.42 Acc@5=64.17\n",
            "Training 5550: Loss=2.56 Acc@1=36.25 Acc@5=61.67\n",
            "Training 5580: Loss=2.47 Acc@1=35.42 Acc@5=66.67\n",
            "Training 5610: Loss=2.23 Acc@1=40.42 Acc@5=77.08\n",
            "Training 5640: Loss=2.47 Acc@1=38.33 Acc@5=70.0\n",
            "Training 5670: Loss=2.52 Acc@1=35.0 Acc@5=68.33\n",
            "Training 5700: Loss=2.66 Acc@1=32.5 Acc@5=63.75\n",
            "Training 5730: Loss=2.69 Acc@1=33.33 Acc@5=63.33\n",
            "Training 5760: Loss=2.61 Acc@1=30.83 Acc@5=66.25\n",
            "Training 5790: Loss=2.49 Acc@1=36.67 Acc@5=69.58\n",
            "Training 5820: Loss=2.38 Acc@1=39.17 Acc@5=70.0\n",
            "Training 5850: Loss=2.38 Acc@1=32.08 Acc@5=72.92\n",
            "Training 5880: Loss=2.52 Acc@1=32.08 Acc@5=72.5\n",
            "Training 5910: Loss=2.45 Acc@1=39.17 Acc@5=67.5\n",
            "Training 5940: Loss=2.39 Acc@1=34.17 Acc@5=69.58\n",
            "Training 5970: Loss=2.5 Acc@1=36.25 Acc@5=68.75\n",
            "Training 6000: Loss=2.47 Acc@1=35.83 Acc@5=66.67\n",
            "Training 6030: Loss=2.37 Acc@1=40.42 Acc@5=68.33\n",
            "Training 6060: Loss=2.54 Acc@1=35.0 Acc@5=64.58\n",
            "Training 6090: Loss=2.68 Acc@1=33.33 Acc@5=62.08\n",
            "Training 6120: Loss=2.57 Acc@1=35.83 Acc@5=65.42\n",
            "Training 6150: Loss=2.47 Acc@1=30.42 Acc@5=66.67\n",
            "Training 6180: Loss=2.44 Acc@1=35.0 Acc@5=65.83\n",
            "Training 6210: Loss=2.52 Acc@1=35.42 Acc@5=66.25\n",
            "Training 6240: Loss=2.4 Acc@1=36.67 Acc@5=67.92\n",
            "Full imagenet train set: Acc@1=43.75 Acc@5=82.5\n",
            "Epoch: 6 ######################################################\n",
            "Training 30: Loss=2.44 Acc@1=43.33 Acc@5=67.5\n",
            "Training 60: Loss=2.19 Acc@1=40.83 Acc@5=72.92\n",
            "Training 90: Loss=2.2 Acc@1=40.0 Acc@5=73.33\n",
            "Training 120: Loss=2.55 Acc@1=34.17 Acc@5=65.42\n",
            "Training 150: Loss=2.54 Acc@1=37.92 Acc@5=64.58\n",
            "Training 180: Loss=2.35 Acc@1=37.08 Acc@5=68.33\n",
            "Training 210: Loss=2.36 Acc@1=38.33 Acc@5=72.08\n",
            "Training 240: Loss=2.38 Acc@1=36.25 Acc@5=68.33\n",
            "Training 270: Loss=2.28 Acc@1=39.58 Acc@5=71.67\n",
            "Training 300: Loss=2.37 Acc@1=37.08 Acc@5=70.0\n",
            "Training 330: Loss=2.44 Acc@1=36.67 Acc@5=69.58\n",
            "Training 360: Loss=2.28 Acc@1=38.33 Acc@5=72.08\n",
            "Training 390: Loss=2.26 Acc@1=42.08 Acc@5=71.67\n",
            "Training 420: Loss=2.51 Acc@1=38.33 Acc@5=65.0\n",
            "Training 450: Loss=2.43 Acc@1=35.42 Acc@5=69.17\n",
            "Training 480: Loss=2.4 Acc@1=37.92 Acc@5=70.83\n",
            "Training 510: Loss=2.48 Acc@1=37.92 Acc@5=67.92\n",
            "Training 540: Loss=2.46 Acc@1=38.75 Acc@5=64.58\n",
            "Training 570: Loss=2.37 Acc@1=38.33 Acc@5=70.42\n",
            "Training 600: Loss=2.37 Acc@1=40.0 Acc@5=68.33\n",
            "Training 630: Loss=2.38 Acc@1=42.92 Acc@5=68.75\n",
            "Training 660: Loss=2.39 Acc@1=42.08 Acc@5=66.67\n",
            "Training 690: Loss=2.42 Acc@1=36.25 Acc@5=67.92\n",
            "Training 720: Loss=2.45 Acc@1=37.92 Acc@5=65.83\n",
            "Training 750: Loss=2.27 Acc@1=43.75 Acc@5=71.25\n",
            "Training 780: Loss=2.51 Acc@1=37.08 Acc@5=66.67\n",
            "Training 810: Loss=2.41 Acc@1=33.75 Acc@5=70.83\n",
            "Training 840: Loss=2.21 Acc@1=42.5 Acc@5=73.33\n",
            "Training 870: Loss=2.26 Acc@1=38.75 Acc@5=72.08\n",
            "Training 900: Loss=2.36 Acc@1=36.67 Acc@5=70.42\n",
            "Training 930: Loss=2.36 Acc@1=38.33 Acc@5=69.58\n",
            "Training 960: Loss=2.38 Acc@1=38.33 Acc@5=69.17\n",
            "Training 990: Loss=2.5 Acc@1=34.17 Acc@5=69.58\n",
            "Training 1020: Loss=2.37 Acc@1=39.17 Acc@5=70.83\n",
            "Training 1050: Loss=2.38 Acc@1=37.5 Acc@5=67.5\n",
            "Training 1080: Loss=2.56 Acc@1=32.92 Acc@5=65.83\n",
            "Training 1110: Loss=2.38 Acc@1=41.67 Acc@5=68.33\n",
            "Training 1140: Loss=2.56 Acc@1=35.0 Acc@5=65.42\n",
            "Training 1170: Loss=2.21 Acc@1=40.0 Acc@5=73.75\n",
            "Training 1200: Loss=2.6 Acc@1=33.33 Acc@5=62.08\n",
            "Training 1230: Loss=2.39 Acc@1=35.42 Acc@5=69.17\n",
            "Training 1260: Loss=2.24 Acc@1=45.0 Acc@5=72.5\n",
            "Training 1290: Loss=2.22 Acc@1=42.5 Acc@5=69.58\n",
            "Training 1320: Loss=2.43 Acc@1=33.33 Acc@5=70.0\n",
            "Training 1350: Loss=2.61 Acc@1=32.5 Acc@5=61.67\n",
            "Training 1380: Loss=2.46 Acc@1=36.25 Acc@5=67.5\n",
            "Training 1410: Loss=2.45 Acc@1=34.17 Acc@5=66.67\n",
            "Training 1440: Loss=2.4 Acc@1=36.25 Acc@5=70.42\n",
            "Training 1470: Loss=2.46 Acc@1=35.0 Acc@5=68.33\n",
            "Training 1500: Loss=2.48 Acc@1=35.42 Acc@5=69.17\n",
            "Training 1530: Loss=2.37 Acc@1=41.25 Acc@5=69.58\n",
            "Training 1560: Loss=2.48 Acc@1=37.08 Acc@5=67.5\n",
            "Training 1590: Loss=2.44 Acc@1=38.33 Acc@5=66.25\n",
            "Training 1620: Loss=2.34 Acc@1=39.58 Acc@5=70.42\n",
            "Training 1650: Loss=2.21 Acc@1=36.67 Acc@5=72.5\n",
            "Training 1680: Loss=2.48 Acc@1=37.08 Acc@5=67.5\n",
            "Training 1710: Loss=2.29 Acc@1=37.08 Acc@5=75.0\n",
            "Training 1740: Loss=2.54 Acc@1=37.5 Acc@5=67.5\n",
            "Training 1770: Loss=2.44 Acc@1=33.75 Acc@5=67.08\n",
            "Training 1800: Loss=2.35 Acc@1=40.0 Acc@5=70.0\n",
            "Training 1830: Loss=2.37 Acc@1=41.67 Acc@5=67.92\n",
            "Training 1860: Loss=2.34 Acc@1=40.42 Acc@5=72.92\n",
            "Training 1890: Loss=2.24 Acc@1=41.25 Acc@5=71.67\n",
            "Training 1920: Loss=2.37 Acc@1=36.67 Acc@5=69.58\n",
            "Training 1950: Loss=2.26 Acc@1=42.5 Acc@5=71.25\n",
            "Training 1980: Loss=2.21 Acc@1=44.17 Acc@5=74.58\n",
            "Training 2010: Loss=2.44 Acc@1=38.33 Acc@5=69.58\n",
            "Training 2040: Loss=2.58 Acc@1=31.25 Acc@5=65.83\n",
            "Training 2070: Loss=2.2 Acc@1=42.5 Acc@5=71.67\n",
            "Training 2100: Loss=2.31 Acc@1=42.92 Acc@5=66.25\n",
            "Training 2130: Loss=2.48 Acc@1=33.75 Acc@5=67.5\n",
            "Training 2160: Loss=2.43 Acc@1=37.92 Acc@5=67.92\n",
            "Training 2190: Loss=2.45 Acc@1=35.42 Acc@5=70.0\n",
            "Training 2220: Loss=2.56 Acc@1=35.83 Acc@5=62.92\n",
            "Training 2250: Loss=2.43 Acc@1=37.5 Acc@5=67.5\n",
            "Training 2280: Loss=2.48 Acc@1=33.75 Acc@5=67.92\n",
            "Training 2310: Loss=2.37 Acc@1=35.0 Acc@5=66.25\n",
            "Training 2340: Loss=2.29 Acc@1=40.0 Acc@5=70.83\n",
            "Training 2370: Loss=2.29 Acc@1=36.67 Acc@5=73.75\n",
            "Training 2400: Loss=2.29 Acc@1=42.5 Acc@5=70.0\n",
            "Training 2430: Loss=2.44 Acc@1=36.25 Acc@5=69.17\n",
            "Training 2460: Loss=2.46 Acc@1=38.33 Acc@5=66.25\n",
            "Training 2490: Loss=2.31 Acc@1=39.58 Acc@5=72.08\n",
            "Training 2520: Loss=2.29 Acc@1=43.75 Acc@5=67.92\n",
            "Training 2550: Loss=2.42 Acc@1=38.33 Acc@5=65.83\n",
            "Training 2580: Loss=2.49 Acc@1=39.58 Acc@5=67.92\n",
            "Training 2610: Loss=2.21 Acc@1=43.33 Acc@5=73.75\n",
            "Training 2640: Loss=2.45 Acc@1=37.92 Acc@5=67.08\n",
            "Training 2670: Loss=2.27 Acc@1=37.08 Acc@5=70.42\n",
            "Training 2700: Loss=2.4 Acc@1=39.17 Acc@5=69.17\n",
            "Training 2730: Loss=2.37 Acc@1=40.42 Acc@5=69.58\n",
            "Training 2760: Loss=2.56 Acc@1=35.42 Acc@5=67.5\n",
            "Training 2790: Loss=2.23 Acc@1=40.42 Acc@5=70.42\n",
            "Training 2820: Loss=2.35 Acc@1=37.08 Acc@5=71.67\n",
            "Training 2850: Loss=2.38 Acc@1=39.58 Acc@5=69.58\n",
            "Training 2880: Loss=2.54 Acc@1=32.92 Acc@5=65.83\n",
            "Training 2910: Loss=2.25 Acc@1=43.75 Acc@5=71.25\n",
            "Training 2940: Loss=2.31 Acc@1=39.58 Acc@5=71.67\n",
            "Training 2970: Loss=2.23 Acc@1=40.0 Acc@5=76.67\n",
            "Training 3000: Loss=2.5 Acc@1=35.83 Acc@5=66.25\n",
            "Training 3030: Loss=2.34 Acc@1=36.25 Acc@5=70.83\n",
            "Training 3060: Loss=2.38 Acc@1=33.33 Acc@5=70.42\n",
            "Training 3090: Loss=2.45 Acc@1=37.5 Acc@5=68.75\n",
            "Training 3120: Loss=2.37 Acc@1=40.42 Acc@5=70.0\n",
            "Training 3150: Loss=2.36 Acc@1=42.5 Acc@5=72.5\n",
            "Training 3180: Loss=2.35 Acc@1=38.33 Acc@5=70.0\n",
            "Training 3210: Loss=2.32 Acc@1=41.25 Acc@5=71.25\n",
            "Training 3240: Loss=2.34 Acc@1=42.5 Acc@5=71.25\n",
            "Training 3270: Loss=2.19 Acc@1=40.42 Acc@5=72.92\n",
            "Training 3300: Loss=2.35 Acc@1=41.25 Acc@5=72.92\n",
            "Training 3330: Loss=2.3 Acc@1=42.08 Acc@5=73.33\n",
            "Training 3360: Loss=2.23 Acc@1=39.17 Acc@5=70.0\n",
            "Training 3390: Loss=2.43 Acc@1=38.33 Acc@5=67.5\n",
            "Training 3420: Loss=2.41 Acc@1=36.25 Acc@5=70.83\n",
            "Training 3450: Loss=2.38 Acc@1=41.67 Acc@5=69.58\n",
            "Training 3480: Loss=2.25 Acc@1=42.92 Acc@5=71.25\n",
            "Training 3510: Loss=2.41 Acc@1=39.58 Acc@5=67.08\n",
            "Training 3540: Loss=2.35 Acc@1=37.08 Acc@5=66.67\n",
            "Training 3570: Loss=2.66 Acc@1=34.17 Acc@5=60.0\n",
            "Training 3600: Loss=2.53 Acc@1=35.83 Acc@5=65.0\n",
            "Training 3630: Loss=2.54 Acc@1=35.83 Acc@5=64.58\n",
            "Training 3660: Loss=2.14 Acc@1=43.75 Acc@5=72.92\n",
            "Training 3690: Loss=2.39 Acc@1=37.92 Acc@5=72.5\n",
            "Training 3720: Loss=2.37 Acc@1=39.58 Acc@5=69.17\n",
            "Training 3750: Loss=2.32 Acc@1=39.17 Acc@5=70.0\n",
            "Training 3780: Loss=2.42 Acc@1=37.08 Acc@5=72.08\n",
            "Training 3810: Loss=2.33 Acc@1=42.08 Acc@5=66.67\n",
            "Training 3840: Loss=2.33 Acc@1=37.5 Acc@5=72.92\n",
            "Training 3870: Loss=2.51 Acc@1=36.25 Acc@5=63.33\n",
            "Training 3900: Loss=2.3 Acc@1=40.83 Acc@5=70.42\n",
            "Training 3930: Loss=2.6 Acc@1=36.25 Acc@5=62.08\n",
            "Training 3960: Loss=2.34 Acc@1=40.0 Acc@5=71.25\n",
            "Training 3990: Loss=2.35 Acc@1=39.17 Acc@5=68.75\n",
            "Training 4020: Loss=2.44 Acc@1=37.08 Acc@5=65.42\n",
            "Training 4050: Loss=2.43 Acc@1=41.67 Acc@5=67.92\n",
            "Training 4080: Loss=2.44 Acc@1=35.42 Acc@5=71.25\n",
            "Training 4110: Loss=2.47 Acc@1=39.17 Acc@5=67.08\n",
            "Training 4140: Loss=2.28 Acc@1=42.5 Acc@5=69.58\n",
            "Training 4170: Loss=2.36 Acc@1=39.17 Acc@5=69.17\n",
            "Training 4200: Loss=2.4 Acc@1=35.0 Acc@5=68.33\n",
            "Training 4230: Loss=2.36 Acc@1=35.42 Acc@5=68.33\n",
            "Training 4260: Loss=2.46 Acc@1=36.25 Acc@5=70.0\n",
            "Training 4290: Loss=2.61 Acc@1=34.58 Acc@5=63.33\n",
            "Training 4320: Loss=2.49 Acc@1=35.0 Acc@5=70.42\n",
            "Training 4350: Loss=2.43 Acc@1=39.17 Acc@5=70.83\n",
            "Training 4380: Loss=2.46 Acc@1=37.92 Acc@5=69.17\n",
            "Training 4410: Loss=2.41 Acc@1=37.08 Acc@5=69.17\n",
            "Training 4440: Loss=2.36 Acc@1=35.83 Acc@5=72.08\n",
            "Training 4470: Loss=2.12 Acc@1=44.58 Acc@5=75.83\n",
            "Training 4500: Loss=2.33 Acc@1=39.17 Acc@5=71.67\n",
            "Training 4530: Loss=2.65 Acc@1=27.5 Acc@5=65.83\n",
            "Training 4560: Loss=2.58 Acc@1=35.83 Acc@5=65.83\n",
            "Training 4590: Loss=2.24 Acc@1=40.83 Acc@5=73.33\n",
            "Training 4620: Loss=2.45 Acc@1=37.92 Acc@5=68.75\n",
            "Training 4650: Loss=2.37 Acc@1=39.17 Acc@5=72.92\n",
            "Training 4680: Loss=2.38 Acc@1=39.58 Acc@5=69.58\n",
            "Training 4710: Loss=2.46 Acc@1=40.0 Acc@5=68.75\n",
            "Training 4740: Loss=2.45 Acc@1=39.17 Acc@5=66.67\n",
            "Training 4770: Loss=2.62 Acc@1=38.75 Acc@5=62.08\n",
            "Training 4800: Loss=2.25 Acc@1=43.75 Acc@5=72.08\n",
            "Training 4830: Loss=2.64 Acc@1=35.0 Acc@5=62.08\n",
            "Training 4860: Loss=2.45 Acc@1=35.42 Acc@5=66.67\n",
            "Training 4890: Loss=2.47 Acc@1=36.67 Acc@5=68.75\n",
            "Training 4920: Loss=2.35 Acc@1=42.08 Acc@5=69.17\n",
            "Training 4950: Loss=2.59 Acc@1=36.25 Acc@5=68.75\n",
            "Training 4980: Loss=2.55 Acc@1=32.08 Acc@5=66.25\n",
            "Training 5010: Loss=2.24 Acc@1=42.92 Acc@5=74.17\n",
            "Training 5040: Loss=2.41 Acc@1=35.42 Acc@5=70.83\n",
            "Training 5070: Loss=2.33 Acc@1=39.58 Acc@5=70.42\n",
            "Training 5100: Loss=2.74 Acc@1=35.42 Acc@5=62.5\n",
            "Training 5130: Loss=2.46 Acc@1=34.58 Acc@5=68.33\n",
            "Training 5160: Loss=2.43 Acc@1=35.83 Acc@5=68.75\n",
            "Training 5190: Loss=2.47 Acc@1=36.25 Acc@5=66.67\n",
            "Training 5220: Loss=2.55 Acc@1=33.33 Acc@5=64.17\n",
            "Training 5250: Loss=2.4 Acc@1=40.42 Acc@5=67.92\n",
            "Training 5280: Loss=2.44 Acc@1=37.08 Acc@5=67.92\n",
            "Training 5310: Loss=2.44 Acc@1=38.75 Acc@5=67.5\n",
            "Training 5340: Loss=2.53 Acc@1=35.83 Acc@5=69.58\n",
            "Training 5370: Loss=2.47 Acc@1=36.25 Acc@5=68.33\n",
            "Training 5400: Loss=2.33 Acc@1=40.42 Acc@5=70.42\n",
            "Training 5430: Loss=2.57 Acc@1=31.67 Acc@5=67.08\n",
            "Training 5460: Loss=2.44 Acc@1=37.92 Acc@5=68.33\n",
            "Training 5490: Loss=2.51 Acc@1=38.33 Acc@5=65.0\n",
            "Training 5520: Loss=2.3 Acc@1=40.42 Acc@5=72.92\n",
            "Training 5550: Loss=2.45 Acc@1=37.5 Acc@5=65.42\n",
            "Training 5580: Loss=2.55 Acc@1=36.67 Acc@5=67.92\n",
            "Training 5610: Loss=2.34 Acc@1=42.5 Acc@5=66.25\n",
            "Training 5640: Loss=2.45 Acc@1=35.83 Acc@5=68.33\n",
            "Training 5670: Loss=2.32 Acc@1=39.17 Acc@5=67.92\n",
            "Training 5700: Loss=2.37 Acc@1=37.5 Acc@5=72.08\n",
            "Training 5730: Loss=2.31 Acc@1=37.08 Acc@5=72.92\n",
            "Training 5760: Loss=2.49 Acc@1=31.67 Acc@5=65.0\n",
            "Training 5790: Loss=2.44 Acc@1=37.5 Acc@5=69.17\n",
            "Training 5820: Loss=2.3 Acc@1=42.08 Acc@5=76.25\n",
            "Training 5850: Loss=2.55 Acc@1=37.08 Acc@5=64.17\n",
            "Training 5880: Loss=2.47 Acc@1=36.25 Acc@5=67.92\n",
            "Training 5910: Loss=2.42 Acc@1=38.75 Acc@5=64.58\n",
            "Training 5940: Loss=2.43 Acc@1=35.0 Acc@5=71.25\n",
            "Training 5970: Loss=2.42 Acc@1=35.83 Acc@5=68.33\n",
            "Training 6000: Loss=2.34 Acc@1=40.83 Acc@5=70.0\n",
            "Training 6030: Loss=2.34 Acc@1=40.42 Acc@5=71.25\n",
            "Training 6060: Loss=2.57 Acc@1=34.17 Acc@5=67.08\n",
            "Training 6090: Loss=2.34 Acc@1=40.0 Acc@5=70.0\n",
            "Training 6120: Loss=2.44 Acc@1=36.67 Acc@5=66.67\n",
            "Training 6150: Loss=2.56 Acc@1=36.25 Acc@5=65.0\n",
            "Training 6180: Loss=2.37 Acc@1=42.08 Acc@5=70.0\n",
            "Training 6210: Loss=2.38 Acc@1=41.25 Acc@5=67.5\n",
            "Training 6240: Loss=2.31 Acc@1=39.17 Acc@5=71.25\n",
            "Full imagenet train set: Acc@1=48.75 Acc@5=83.75\n",
            "Epoch: 7 ######################################################\n",
            "Training 30: Loss=2.41 Acc@1=38.33 Acc@5=70.42\n",
            "Training 60: Loss=2.23 Acc@1=42.92 Acc@5=72.5\n",
            "Training 90: Loss=2.36 Acc@1=40.42 Acc@5=70.42\n",
            "Training 120: Loss=2.38 Acc@1=39.17 Acc@5=69.17\n",
            "Training 150: Loss=2.28 Acc@1=38.75 Acc@5=74.17\n",
            "Training 180: Loss=2.2 Acc@1=44.17 Acc@5=72.92\n",
            "Training 210: Loss=2.25 Acc@1=39.17 Acc@5=75.0\n",
            "Training 240: Loss=2.21 Acc@1=41.25 Acc@5=72.92\n",
            "Training 270: Loss=2.13 Acc@1=40.83 Acc@5=78.75\n",
            "Training 300: Loss=2.55 Acc@1=35.0 Acc@5=65.83\n",
            "Training 330: Loss=2.21 Acc@1=40.0 Acc@5=73.33\n",
            "Training 360: Loss=2.5 Acc@1=37.08 Acc@5=67.5\n",
            "Training 390: Loss=2.22 Acc@1=42.92 Acc@5=72.92\n",
            "Training 420: Loss=2.29 Acc@1=39.58 Acc@5=71.67\n",
            "Training 450: Loss=2.26 Acc@1=37.92 Acc@5=72.92\n",
            "Training 480: Loss=2.27 Acc@1=40.83 Acc@5=70.0\n",
            "Training 510: Loss=2.24 Acc@1=45.0 Acc@5=72.08\n",
            "Training 540: Loss=2.3 Acc@1=38.33 Acc@5=69.17\n",
            "Training 570: Loss=2.36 Acc@1=37.5 Acc@5=70.42\n",
            "Training 600: Loss=2.29 Acc@1=39.17 Acc@5=72.5\n",
            "Training 630: Loss=2.3 Acc@1=42.5 Acc@5=70.42\n",
            "Training 660: Loss=2.23 Acc@1=42.92 Acc@5=74.17\n",
            "Training 690: Loss=2.23 Acc@1=37.92 Acc@5=72.5\n",
            "Training 720: Loss=2.3 Acc@1=41.67 Acc@5=74.58\n",
            "Training 750: Loss=2.38 Acc@1=36.67 Acc@5=72.08\n",
            "Training 780: Loss=2.06 Acc@1=43.33 Acc@5=78.33\n",
            "Training 810: Loss=2.2 Acc@1=40.83 Acc@5=71.25\n",
            "Training 840: Loss=2.21 Acc@1=40.42 Acc@5=71.25\n",
            "Training 870: Loss=2.23 Acc@1=42.92 Acc@5=73.75\n",
            "Training 900: Loss=2.24 Acc@1=40.0 Acc@5=72.92\n",
            "Training 930: Loss=2.37 Acc@1=37.5 Acc@5=70.83\n",
            "Training 960: Loss=2.09 Acc@1=45.42 Acc@5=75.42\n",
            "Training 990: Loss=2.44 Acc@1=39.17 Acc@5=67.08\n",
            "Training 1020: Loss=2.26 Acc@1=43.33 Acc@5=70.0\n",
            "Training 1050: Loss=2.22 Acc@1=43.33 Acc@5=71.67\n",
            "Training 1080: Loss=2.09 Acc@1=43.75 Acc@5=72.08\n",
            "Training 1110: Loss=2.2 Acc@1=40.83 Acc@5=74.17\n",
            "Training 1140: Loss=2.43 Acc@1=40.0 Acc@5=66.25\n",
            "Training 1170: Loss=2.2 Acc@1=38.75 Acc@5=74.58\n",
            "Training 1200: Loss=2.25 Acc@1=39.17 Acc@5=70.42\n",
            "Training 1230: Loss=2.39 Acc@1=37.92 Acc@5=65.42\n",
            "Training 1260: Loss=2.37 Acc@1=40.0 Acc@5=68.33\n",
            "Training 1290: Loss=2.33 Acc@1=37.08 Acc@5=70.42\n",
            "Training 1320: Loss=2.3 Acc@1=36.67 Acc@5=74.17\n",
            "Training 1350: Loss=2.23 Acc@1=40.83 Acc@5=71.25\n",
            "Training 1380: Loss=2.31 Acc@1=37.92 Acc@5=70.42\n",
            "Training 1410: Loss=2.18 Acc@1=42.92 Acc@5=73.33\n",
            "Training 1440: Loss=2.2 Acc@1=43.33 Acc@5=73.75\n",
            "Training 1470: Loss=2.18 Acc@1=40.42 Acc@5=74.17\n",
            "Training 1500: Loss=2.47 Acc@1=32.08 Acc@5=67.08\n",
            "Training 1530: Loss=1.97 Acc@1=43.75 Acc@5=73.75\n",
            "Training 1560: Loss=2.27 Acc@1=43.33 Acc@5=72.08\n",
            "Training 1590: Loss=2.27 Acc@1=43.33 Acc@5=67.92\n",
            "Training 1620: Loss=2.27 Acc@1=39.58 Acc@5=72.5\n",
            "Training 1650: Loss=2.49 Acc@1=37.08 Acc@5=67.5\n",
            "Training 1680: Loss=2.33 Acc@1=37.08 Acc@5=69.58\n",
            "Training 1710: Loss=2.2 Acc@1=39.58 Acc@5=75.42\n",
            "Training 1740: Loss=2.31 Acc@1=39.17 Acc@5=72.5\n",
            "Training 1770: Loss=2.26 Acc@1=39.58 Acc@5=70.42\n",
            "Training 1800: Loss=2.3 Acc@1=35.0 Acc@5=74.17\n",
            "Training 1830: Loss=2.39 Acc@1=41.25 Acc@5=67.08\n",
            "Training 1860: Loss=2.09 Acc@1=42.5 Acc@5=77.5\n",
            "Training 1890: Loss=2.28 Acc@1=38.33 Acc@5=68.75\n",
            "Training 1920: Loss=2.3 Acc@1=41.67 Acc@5=71.25\n",
            "Training 1950: Loss=2.31 Acc@1=41.25 Acc@5=71.25\n",
            "Training 1980: Loss=2.3 Acc@1=40.0 Acc@5=69.58\n",
            "Training 2010: Loss=2.36 Acc@1=40.0 Acc@5=71.25\n",
            "Training 2040: Loss=2.36 Acc@1=39.17 Acc@5=73.33\n",
            "Training 2070: Loss=2.28 Acc@1=40.83 Acc@5=70.42\n",
            "Training 2100: Loss=2.27 Acc@1=40.42 Acc@5=69.58\n",
            "Training 2130: Loss=2.33 Acc@1=38.75 Acc@5=71.25\n",
            "Training 2160: Loss=2.44 Acc@1=36.67 Acc@5=66.25\n",
            "Training 2190: Loss=2.19 Acc@1=42.5 Acc@5=73.75\n",
            "Training 2220: Loss=2.44 Acc@1=35.42 Acc@5=67.92\n",
            "Training 2250: Loss=2.18 Acc@1=44.58 Acc@5=72.5\n",
            "Training 2280: Loss=2.42 Acc@1=40.42 Acc@5=69.17\n",
            "Training 2310: Loss=2.48 Acc@1=34.58 Acc@5=65.0\n",
            "Training 2340: Loss=2.24 Acc@1=42.08 Acc@5=70.42\n",
            "Training 2370: Loss=2.36 Acc@1=35.83 Acc@5=71.67\n",
            "Training 2400: Loss=2.28 Acc@1=43.33 Acc@5=71.67\n",
            "Training 2430: Loss=2.16 Acc@1=43.33 Acc@5=75.0\n",
            "Training 2460: Loss=2.36 Acc@1=38.75 Acc@5=70.42\n",
            "Training 2490: Loss=2.34 Acc@1=37.92 Acc@5=70.0\n",
            "Training 2520: Loss=2.4 Acc@1=36.25 Acc@5=68.75\n",
            "Training 2550: Loss=2.43 Acc@1=36.67 Acc@5=66.25\n",
            "Training 2580: Loss=2.16 Acc@1=42.92 Acc@5=75.42\n",
            "Training 2610: Loss=2.27 Acc@1=42.5 Acc@5=72.5\n",
            "Training 2640: Loss=2.27 Acc@1=41.67 Acc@5=70.83\n",
            "Training 2670: Loss=2.17 Acc@1=41.67 Acc@5=76.25\n",
            "Training 2700: Loss=2.15 Acc@1=44.17 Acc@5=74.17\n",
            "Training 2730: Loss=2.21 Acc@1=41.25 Acc@5=75.0\n",
            "Training 2760: Loss=2.34 Acc@1=43.33 Acc@5=67.08\n",
            "Training 2790: Loss=2.32 Acc@1=42.08 Acc@5=70.42\n",
            "Training 2820: Loss=2.34 Acc@1=43.33 Acc@5=66.67\n",
            "Training 2850: Loss=2.5 Acc@1=37.5 Acc@5=65.0\n",
            "Training 2880: Loss=2.25 Acc@1=42.08 Acc@5=72.5\n",
            "Training 2910: Loss=2.3 Acc@1=37.08 Acc@5=71.25\n",
            "Training 2940: Loss=2.39 Acc@1=40.42 Acc@5=68.33\n",
            "Training 2970: Loss=2.4 Acc@1=36.25 Acc@5=67.5\n",
            "Training 3000: Loss=2.43 Acc@1=36.25 Acc@5=70.42\n",
            "Training 3030: Loss=2.4 Acc@1=42.5 Acc@5=69.58\n",
            "Training 3060: Loss=2.29 Acc@1=43.75 Acc@5=72.5\n",
            "Training 3090: Loss=2.06 Acc@1=47.92 Acc@5=77.92\n",
            "Training 3120: Loss=2.35 Acc@1=35.83 Acc@5=71.25\n",
            "Training 3150: Loss=2.53 Acc@1=36.25 Acc@5=65.42\n",
            "Training 3180: Loss=2.1 Acc@1=44.58 Acc@5=73.33\n",
            "Training 3210: Loss=2.33 Acc@1=35.83 Acc@5=67.5\n",
            "Training 3240: Loss=2.29 Acc@1=37.5 Acc@5=74.58\n",
            "Training 3270: Loss=2.19 Acc@1=42.92 Acc@5=72.92\n",
            "Training 3300: Loss=2.52 Acc@1=37.92 Acc@5=68.33\n",
            "Training 3330: Loss=2.59 Acc@1=33.33 Acc@5=65.42\n",
            "Training 3360: Loss=2.24 Acc@1=44.58 Acc@5=69.58\n",
            "Training 3390: Loss=2.25 Acc@1=41.25 Acc@5=72.5\n",
            "Training 3420: Loss=2.28 Acc@1=38.75 Acc@5=72.92\n",
            "Training 3450: Loss=2.43 Acc@1=36.67 Acc@5=69.17\n",
            "Training 3480: Loss=2.4 Acc@1=38.33 Acc@5=69.58\n",
            "Training 3510: Loss=2.2 Acc@1=38.33 Acc@5=73.75\n",
            "Training 3540: Loss=2.28 Acc@1=37.5 Acc@5=72.5\n",
            "Training 3570: Loss=2.35 Acc@1=40.0 Acc@5=69.58\n",
            "Training 3600: Loss=2.24 Acc@1=39.58 Acc@5=73.75\n",
            "Training 3630: Loss=2.25 Acc@1=42.5 Acc@5=73.33\n",
            "Training 3660: Loss=2.34 Acc@1=41.67 Acc@5=71.25\n",
            "Training 3690: Loss=2.2 Acc@1=38.75 Acc@5=72.92\n",
            "Training 3720: Loss=2.32 Acc@1=41.67 Acc@5=72.5\n",
            "Training 3750: Loss=2.41 Acc@1=36.25 Acc@5=65.83\n",
            "Training 3780: Loss=2.36 Acc@1=35.0 Acc@5=69.17\n",
            "Training 3810: Loss=2.24 Acc@1=45.42 Acc@5=70.83\n",
            "Training 3840: Loss=2.32 Acc@1=39.58 Acc@5=69.17\n",
            "Training 3870: Loss=2.6 Acc@1=32.5 Acc@5=65.83\n",
            "Training 3900: Loss=2.02 Acc@1=45.42 Acc@5=75.42\n",
            "Training 3930: Loss=2.16 Acc@1=42.08 Acc@5=70.42\n",
            "Training 3960: Loss=2.21 Acc@1=45.42 Acc@5=72.92\n",
            "Training 3990: Loss=2.36 Acc@1=39.58 Acc@5=69.58\n",
            "Training 4020: Loss=2.45 Acc@1=38.33 Acc@5=69.58\n",
            "Training 4050: Loss=2.44 Acc@1=42.08 Acc@5=66.25\n",
            "Training 4080: Loss=2.21 Acc@1=42.08 Acc@5=72.92\n",
            "Training 4110: Loss=2.53 Acc@1=38.33 Acc@5=64.58\n",
            "Training 4140: Loss=2.25 Acc@1=42.08 Acc@5=75.0\n",
            "Training 4170: Loss=2.3 Acc@1=41.25 Acc@5=70.83\n",
            "Training 4200: Loss=2.31 Acc@1=41.25 Acc@5=66.67\n",
            "Training 4230: Loss=2.43 Acc@1=37.08 Acc@5=67.92\n",
            "Training 4260: Loss=2.29 Acc@1=38.33 Acc@5=70.42\n",
            "Training 4290: Loss=2.3 Acc@1=37.5 Acc@5=71.67\n",
            "Training 4320: Loss=2.23 Acc@1=40.42 Acc@5=73.75\n",
            "Training 4350: Loss=2.21 Acc@1=38.33 Acc@5=72.08\n",
            "Training 4380: Loss=2.24 Acc@1=40.42 Acc@5=70.83\n",
            "Training 4410: Loss=2.31 Acc@1=39.17 Acc@5=67.5\n",
            "Training 4440: Loss=2.15 Acc@1=46.25 Acc@5=71.67\n",
            "Training 4470: Loss=2.4 Acc@1=37.92 Acc@5=68.75\n",
            "Training 4500: Loss=2.39 Acc@1=33.75 Acc@5=72.5\n",
            "Training 4530: Loss=2.23 Acc@1=41.25 Acc@5=70.42\n",
            "Training 4560: Loss=2.23 Acc@1=42.08 Acc@5=73.33\n",
            "Training 4590: Loss=2.3 Acc@1=40.83 Acc@5=72.08\n",
            "Training 4620: Loss=2.38 Acc@1=36.67 Acc@5=70.83\n",
            "Training 4650: Loss=2.01 Acc@1=47.5 Acc@5=77.92\n",
            "Training 4680: Loss=2.26 Acc@1=37.08 Acc@5=72.08\n",
            "Training 4710: Loss=2.24 Acc@1=43.75 Acc@5=72.5\n",
            "Training 4740: Loss=2.08 Acc@1=44.58 Acc@5=75.83\n",
            "Training 4770: Loss=2.39 Acc@1=36.25 Acc@5=70.42\n",
            "Training 4800: Loss=2.39 Acc@1=39.58 Acc@5=69.58\n",
            "Training 4830: Loss=2.29 Acc@1=39.58 Acc@5=72.92\n",
            "Training 4860: Loss=2.36 Acc@1=41.67 Acc@5=70.42\n",
            "Training 4890: Loss=2.27 Acc@1=43.75 Acc@5=71.25\n",
            "Training 4920: Loss=2.34 Acc@1=40.42 Acc@5=64.17\n",
            "Training 4950: Loss=2.49 Acc@1=36.25 Acc@5=68.75\n",
            "Training 4980: Loss=2.28 Acc@1=42.5 Acc@5=73.33\n",
            "Training 5010: Loss=2.38 Acc@1=38.75 Acc@5=72.08\n",
            "Training 5040: Loss=2.38 Acc@1=39.17 Acc@5=72.92\n",
            "Training 5070: Loss=2.32 Acc@1=44.17 Acc@5=67.5\n",
            "Training 5100: Loss=2.37 Acc@1=37.5 Acc@5=70.83\n",
            "Training 5130: Loss=2.26 Acc@1=40.83 Acc@5=70.83\n",
            "Training 5160: Loss=2.19 Acc@1=44.58 Acc@5=72.08\n",
            "Training 5190: Loss=2.15 Acc@1=41.67 Acc@5=74.17\n",
            "Training 5220: Loss=2.13 Acc@1=43.75 Acc@5=75.0\n",
            "Training 5250: Loss=2.37 Acc@1=38.75 Acc@5=71.25\n",
            "Training 5280: Loss=2.21 Acc@1=40.0 Acc@5=74.17\n",
            "Training 5310: Loss=2.1 Acc@1=43.75 Acc@5=72.5\n",
            "Training 5340: Loss=2.34 Acc@1=37.08 Acc@5=69.58\n",
            "Training 5370: Loss=2.35 Acc@1=43.33 Acc@5=68.33\n",
            "Training 5400: Loss=2.22 Acc@1=41.67 Acc@5=71.25\n",
            "Training 5430: Loss=2.32 Acc@1=40.0 Acc@5=74.58\n",
            "Training 5460: Loss=2.27 Acc@1=38.75 Acc@5=72.5\n",
            "Training 5490: Loss=2.33 Acc@1=38.75 Acc@5=71.25\n",
            "Training 5520: Loss=2.45 Acc@1=37.5 Acc@5=69.17\n",
            "Training 5550: Loss=2.54 Acc@1=35.83 Acc@5=68.75\n",
            "Training 5580: Loss=2.32 Acc@1=40.0 Acc@5=71.25\n",
            "Training 5610: Loss=2.36 Acc@1=38.33 Acc@5=69.17\n",
            "Training 5640: Loss=2.25 Acc@1=41.25 Acc@5=73.75\n",
            "Training 5670: Loss=2.55 Acc@1=33.75 Acc@5=67.5\n",
            "Training 5700: Loss=2.24 Acc@1=42.5 Acc@5=72.92\n",
            "Training 5730: Loss=2.49 Acc@1=37.5 Acc@5=69.17\n",
            "Training 5760: Loss=2.31 Acc@1=42.5 Acc@5=72.08\n",
            "Training 5790: Loss=2.2 Acc@1=39.17 Acc@5=71.67\n",
            "Training 5820: Loss=2.24 Acc@1=42.92 Acc@5=70.0\n",
            "Training 5850: Loss=2.36 Acc@1=37.92 Acc@5=69.58\n",
            "Training 5880: Loss=2.25 Acc@1=42.08 Acc@5=71.25\n",
            "Training 5910: Loss=2.41 Acc@1=37.92 Acc@5=70.42\n",
            "Training 5940: Loss=2.32 Acc@1=42.08 Acc@5=69.17\n",
            "Training 5970: Loss=2.27 Acc@1=40.83 Acc@5=70.83\n",
            "Training 6000: Loss=2.22 Acc@1=43.33 Acc@5=71.67\n",
            "Training 6030: Loss=2.18 Acc@1=40.42 Acc@5=73.75\n",
            "Training 6060: Loss=2.19 Acc@1=44.17 Acc@5=72.08\n",
            "Training 6090: Loss=2.27 Acc@1=38.75 Acc@5=70.42\n",
            "Training 6120: Loss=2.15 Acc@1=39.17 Acc@5=71.67\n",
            "Training 6150: Loss=2.29 Acc@1=40.83 Acc@5=68.75\n",
            "Training 6180: Loss=2.22 Acc@1=40.42 Acc@5=70.42\n",
            "Training 6210: Loss=2.39 Acc@1=40.83 Acc@5=71.25\n",
            "Training 6240: Loss=2.23 Acc@1=40.83 Acc@5=73.33\n",
            "Full imagenet train set: Acc@1=56.25 Acc@5=77.5\n",
            "Epoch: 8 ######################################################\n",
            "Training 30: Loss=2.02 Acc@1=43.75 Acc@5=77.08\n",
            "Training 60: Loss=2.06 Acc@1=47.08 Acc@5=74.17\n",
            "Training 90: Loss=1.98 Acc@1=47.92 Acc@5=77.5\n",
            "Training 120: Loss=2.23 Acc@1=42.08 Acc@5=71.25\n",
            "Training 150: Loss=2.19 Acc@1=44.58 Acc@5=72.92\n",
            "Training 180: Loss=2.06 Acc@1=45.0 Acc@5=74.17\n",
            "Training 210: Loss=2.18 Acc@1=44.58 Acc@5=75.0\n",
            "Training 240: Loss=2.16 Acc@1=40.83 Acc@5=75.42\n",
            "Training 270: Loss=2.04 Acc@1=44.58 Acc@5=76.67\n",
            "Training 300: Loss=2.32 Acc@1=38.33 Acc@5=73.33\n",
            "Training 330: Loss=2.16 Acc@1=44.17 Acc@5=71.25\n",
            "Training 360: Loss=2.12 Acc@1=42.08 Acc@5=73.33\n",
            "Training 390: Loss=2.17 Acc@1=38.75 Acc@5=77.92\n",
            "Training 420: Loss=2.02 Acc@1=47.92 Acc@5=79.58\n",
            "Training 450: Loss=2.21 Acc@1=42.92 Acc@5=72.92\n",
            "Training 480: Loss=2.25 Acc@1=39.17 Acc@5=75.0\n",
            "Training 510: Loss=2.17 Acc@1=44.58 Acc@5=71.25\n",
            "Training 540: Loss=2.35 Acc@1=38.75 Acc@5=70.0\n",
            "Training 570: Loss=2.13 Acc@1=36.67 Acc@5=75.0\n",
            "Training 600: Loss=2.34 Acc@1=41.25 Acc@5=70.0\n",
            "Training 630: Loss=2.19 Acc@1=47.08 Acc@5=73.33\n",
            "Training 660: Loss=2.26 Acc@1=41.25 Acc@5=71.25\n",
            "Training 690: Loss=2.48 Acc@1=37.5 Acc@5=70.0\n",
            "Training 720: Loss=2.35 Acc@1=42.08 Acc@5=71.67\n",
            "Training 750: Loss=2.12 Acc@1=43.75 Acc@5=74.17\n",
            "Training 780: Loss=2.28 Acc@1=43.33 Acc@5=73.75\n",
            "Training 810: Loss=2.34 Acc@1=42.5 Acc@5=68.33\n",
            "Training 840: Loss=2.23 Acc@1=40.83 Acc@5=72.5\n",
            "Training 870: Loss=2.25 Acc@1=42.5 Acc@5=72.5\n",
            "Training 900: Loss=2.18 Acc@1=45.83 Acc@5=74.17\n",
            "Training 930: Loss=2.13 Acc@1=43.75 Acc@5=76.67\n",
            "Training 960: Loss=2.17 Acc@1=42.92 Acc@5=76.25\n",
            "Training 990: Loss=2.23 Acc@1=40.42 Acc@5=72.5\n",
            "Training 1020: Loss=1.98 Acc@1=48.33 Acc@5=75.42\n",
            "Training 1050: Loss=2.1 Acc@1=43.33 Acc@5=79.17\n",
            "Training 1080: Loss=2.12 Acc@1=42.92 Acc@5=75.83\n",
            "Training 1110: Loss=2.38 Acc@1=37.92 Acc@5=66.25\n",
            "Training 1140: Loss=2.19 Acc@1=40.0 Acc@5=70.83\n",
            "Training 1170: Loss=2.24 Acc@1=43.33 Acc@5=72.5\n",
            "Training 1200: Loss=2.13 Acc@1=45.83 Acc@5=76.67\n",
            "Training 1230: Loss=2.2 Acc@1=39.17 Acc@5=75.83\n",
            "Training 1260: Loss=2.22 Acc@1=40.83 Acc@5=75.0\n",
            "Training 1290: Loss=2.35 Acc@1=37.08 Acc@5=70.83\n",
            "Training 1320: Loss=2.16 Acc@1=37.92 Acc@5=73.33\n",
            "Training 1350: Loss=2.14 Acc@1=45.42 Acc@5=73.75\n",
            "Training 1380: Loss=2.24 Acc@1=40.0 Acc@5=70.0\n",
            "Training 1410: Loss=2.02 Acc@1=46.25 Acc@5=79.58\n",
            "Training 1440: Loss=2.31 Acc@1=40.0 Acc@5=69.58\n",
            "Training 1470: Loss=2.05 Acc@1=42.5 Acc@5=78.33\n",
            "Training 1500: Loss=1.95 Acc@1=48.75 Acc@5=77.08\n",
            "Training 1530: Loss=2.07 Acc@1=44.58 Acc@5=74.17\n",
            "Training 1560: Loss=2.07 Acc@1=46.25 Acc@5=74.58\n",
            "Training 1590: Loss=2.15 Acc@1=42.5 Acc@5=73.33\n",
            "Training 1620: Loss=2.11 Acc@1=45.0 Acc@5=73.33\n",
            "Training 1650: Loss=2.16 Acc@1=46.67 Acc@5=72.92\n",
            "Training 1680: Loss=2.17 Acc@1=42.08 Acc@5=75.0\n",
            "Training 1710: Loss=2.08 Acc@1=45.83 Acc@5=75.83\n",
            "Training 1740: Loss=2.16 Acc@1=44.17 Acc@5=71.25\n",
            "Training 1770: Loss=2.23 Acc@1=42.5 Acc@5=71.25\n",
            "Training 1800: Loss=2.2 Acc@1=42.5 Acc@5=71.25\n",
            "Training 1830: Loss=2.06 Acc@1=46.25 Acc@5=76.25\n",
            "Training 1860: Loss=2.1 Acc@1=39.58 Acc@5=72.92\n",
            "Training 1890: Loss=2.43 Acc@1=35.83 Acc@5=66.67\n",
            "Training 1920: Loss=2.11 Acc@1=44.17 Acc@5=75.0\n",
            "Training 1950: Loss=2.01 Acc@1=46.25 Acc@5=75.42\n",
            "Training 1980: Loss=2.24 Acc@1=41.67 Acc@5=70.0\n",
            "Training 2010: Loss=2.25 Acc@1=39.58 Acc@5=73.33\n",
            "Training 2040: Loss=2.43 Acc@1=36.25 Acc@5=67.92\n",
            "Training 2070: Loss=2.19 Acc@1=45.42 Acc@5=74.58\n",
            "Training 2100: Loss=2.24 Acc@1=42.08 Acc@5=70.42\n",
            "Training 2130: Loss=2.34 Acc@1=37.5 Acc@5=68.33\n",
            "Training 2160: Loss=2.25 Acc@1=43.33 Acc@5=70.83\n",
            "Training 2190: Loss=2.26 Acc@1=38.33 Acc@5=74.58\n",
            "Training 2220: Loss=2.13 Acc@1=42.5 Acc@5=74.17\n",
            "Training 2250: Loss=2.1 Acc@1=47.5 Acc@5=72.08\n",
            "Training 2280: Loss=2.21 Acc@1=45.0 Acc@5=74.58\n",
            "Training 2310: Loss=2.3 Acc@1=40.42 Acc@5=72.08\n",
            "Training 2340: Loss=2.31 Acc@1=39.58 Acc@5=71.25\n",
            "Training 2370: Loss=2.13 Acc@1=44.17 Acc@5=73.75\n",
            "Training 2400: Loss=2.26 Acc@1=36.67 Acc@5=73.33\n",
            "Training 2430: Loss=2.21 Acc@1=42.92 Acc@5=75.0\n",
            "Training 2460: Loss=2.14 Acc@1=43.33 Acc@5=74.17\n",
            "Training 2490: Loss=2.2 Acc@1=42.92 Acc@5=75.0\n",
            "Training 2520: Loss=2.32 Acc@1=37.5 Acc@5=72.08\n",
            "Training 2550: Loss=2.17 Acc@1=43.33 Acc@5=72.5\n",
            "Training 2580: Loss=2.28 Acc@1=42.92 Acc@5=70.0\n",
            "Training 2610: Loss=2.2 Acc@1=39.17 Acc@5=72.5\n",
            "Training 2640: Loss=2.36 Acc@1=37.5 Acc@5=69.17\n",
            "Training 2670: Loss=2.2 Acc@1=37.08 Acc@5=75.0\n",
            "Training 2700: Loss=2.08 Acc@1=41.67 Acc@5=77.08\n",
            "Training 2730: Loss=2.07 Acc@1=45.42 Acc@5=77.5\n",
            "Training 2760: Loss=2.02 Acc@1=46.67 Acc@5=75.0\n",
            "Training 2790: Loss=2.14 Acc@1=45.0 Acc@5=72.5\n",
            "Training 2820: Loss=2.23 Acc@1=38.75 Acc@5=75.42\n",
            "Training 2850: Loss=2.18 Acc@1=44.17 Acc@5=74.17\n",
            "Training 2880: Loss=2.09 Acc@1=44.17 Acc@5=76.25\n",
            "Training 2910: Loss=2.11 Acc@1=42.5 Acc@5=72.08\n",
            "Training 2940: Loss=2.29 Acc@1=40.42 Acc@5=67.92\n",
            "Training 2970: Loss=2.38 Acc@1=39.58 Acc@5=65.0\n",
            "Training 3000: Loss=2.33 Acc@1=39.58 Acc@5=67.08\n",
            "Training 3030: Loss=2.4 Acc@1=35.83 Acc@5=67.5\n",
            "Training 3060: Loss=2.18 Acc@1=42.92 Acc@5=75.0\n",
            "Training 3090: Loss=2.14 Acc@1=44.58 Acc@5=76.67\n",
            "Training 3120: Loss=2.2 Acc@1=44.58 Acc@5=74.17\n",
            "Training 3150: Loss=2.3 Acc@1=36.67 Acc@5=70.0\n",
            "Training 3180: Loss=2.28 Acc@1=39.17 Acc@5=70.42\n",
            "Training 3210: Loss=2.04 Acc@1=46.25 Acc@5=74.17\n",
            "Training 3240: Loss=2.39 Acc@1=37.5 Acc@5=65.0\n",
            "Training 3270: Loss=2.23 Acc@1=43.33 Acc@5=77.08\n",
            "Training 3300: Loss=2.27 Acc@1=39.17 Acc@5=72.08\n",
            "Training 3330: Loss=2.18 Acc@1=40.83 Acc@5=71.67\n",
            "Training 3360: Loss=2.16 Acc@1=45.83 Acc@5=72.92\n",
            "Training 3390: Loss=2.2 Acc@1=43.75 Acc@5=72.5\n",
            "Training 3420: Loss=2.24 Acc@1=39.58 Acc@5=74.17\n",
            "Training 3450: Loss=1.83 Acc@1=52.5 Acc@5=79.17\n",
            "Training 3480: Loss=2.17 Acc@1=38.33 Acc@5=73.33\n",
            "Training 3510: Loss=2.57 Acc@1=34.58 Acc@5=65.42\n",
            "Training 3540: Loss=2.15 Acc@1=42.92 Acc@5=72.92\n",
            "Training 3570: Loss=2.18 Acc@1=38.33 Acc@5=73.33\n",
            "Training 3600: Loss=2.36 Acc@1=38.75 Acc@5=70.0\n",
            "Training 3630: Loss=2.31 Acc@1=39.58 Acc@5=72.92\n",
            "Training 3660: Loss=2.18 Acc@1=41.67 Acc@5=72.08\n",
            "Training 3690: Loss=2.08 Acc@1=45.0 Acc@5=73.75\n",
            "Training 3720: Loss=2.33 Acc@1=42.08 Acc@5=69.58\n",
            "Training 3750: Loss=2.17 Acc@1=44.17 Acc@5=74.58\n",
            "Training 3780: Loss=2.1 Acc@1=44.58 Acc@5=74.17\n",
            "Training 3810: Loss=2.1 Acc@1=47.08 Acc@5=74.58\n",
            "Training 3840: Loss=2.28 Acc@1=42.5 Acc@5=67.5\n",
            "Training 3870: Loss=2.38 Acc@1=37.5 Acc@5=70.42\n",
            "Training 3900: Loss=2.32 Acc@1=37.92 Acc@5=73.33\n",
            "Training 3930: Loss=2.29 Acc@1=41.67 Acc@5=70.0\n",
            "Training 3960: Loss=2.13 Acc@1=43.75 Acc@5=76.67\n",
            "Training 3990: Loss=2.17 Acc@1=42.5 Acc@5=73.33\n",
            "Training 4020: Loss=2.23 Acc@1=42.5 Acc@5=70.83\n",
            "Training 4050: Loss=2.2 Acc@1=45.42 Acc@5=70.83\n",
            "Training 4080: Loss=2.29 Acc@1=38.75 Acc@5=72.08\n",
            "Training 4110: Loss=2.15 Acc@1=47.92 Acc@5=72.08\n",
            "Training 4140: Loss=2.13 Acc@1=42.08 Acc@5=74.17\n",
            "Training 4170: Loss=2.27 Acc@1=38.75 Acc@5=69.58\n",
            "Training 4200: Loss=2.37 Acc@1=40.42 Acc@5=68.75\n",
            "Training 4230: Loss=2.43 Acc@1=38.75 Acc@5=68.33\n",
            "Training 4260: Loss=2.34 Acc@1=37.08 Acc@5=73.75\n",
            "Training 4290: Loss=2.23 Acc@1=40.83 Acc@5=74.17\n",
            "Training 4320: Loss=2.19 Acc@1=38.75 Acc@5=75.0\n",
            "Training 4350: Loss=2.21 Acc@1=42.08 Acc@5=72.5\n",
            "Training 4380: Loss=2.17 Acc@1=43.33 Acc@5=73.33\n",
            "Training 4410: Loss=2.23 Acc@1=40.0 Acc@5=71.67\n",
            "Training 4440: Loss=2.09 Acc@1=42.08 Acc@5=75.0\n",
            "Training 4470: Loss=2.17 Acc@1=42.08 Acc@5=75.83\n",
            "Training 4500: Loss=2.04 Acc@1=48.33 Acc@5=76.25\n",
            "Training 4530: Loss=2.04 Acc@1=45.83 Acc@5=75.42\n",
            "Training 4560: Loss=2.27 Acc@1=40.0 Acc@5=66.67\n",
            "Training 4590: Loss=2.19 Acc@1=38.75 Acc@5=74.17\n",
            "Training 4620: Loss=2.37 Acc@1=41.25 Acc@5=71.67\n",
            "Training 4650: Loss=2.29 Acc@1=41.25 Acc@5=72.5\n",
            "Training 4680: Loss=2.18 Acc@1=42.08 Acc@5=72.92\n",
            "Training 4710: Loss=2.21 Acc@1=41.25 Acc@5=72.08\n",
            "Training 4740: Loss=2.3 Acc@1=42.92 Acc@5=73.33\n",
            "Training 4770: Loss=2.17 Acc@1=39.17 Acc@5=72.08\n",
            "Training 4800: Loss=2.24 Acc@1=40.42 Acc@5=73.75\n",
            "Training 4830: Loss=2.25 Acc@1=41.67 Acc@5=71.67\n",
            "Training 4860: Loss=2.37 Acc@1=42.08 Acc@5=73.33\n",
            "Training 4890: Loss=2.19 Acc@1=44.58 Acc@5=72.92\n",
            "Training 4920: Loss=2.13 Acc@1=47.92 Acc@5=74.17\n",
            "Training 4950: Loss=2.34 Acc@1=36.67 Acc@5=71.67\n",
            "Training 4980: Loss=2.21 Acc@1=44.17 Acc@5=73.33\n",
            "Training 5010: Loss=2.27 Acc@1=42.92 Acc@5=70.83\n",
            "Training 5040: Loss=2.28 Acc@1=38.75 Acc@5=72.08\n",
            "Training 5070: Loss=2.07 Acc@1=43.75 Acc@5=76.67\n",
            "Training 5100: Loss=2.25 Acc@1=36.67 Acc@5=72.92\n",
            "Training 5130: Loss=2.15 Acc@1=44.17 Acc@5=72.92\n",
            "Training 5160: Loss=2.37 Acc@1=36.25 Acc@5=75.83\n",
            "Training 5190: Loss=2.27 Acc@1=46.25 Acc@5=67.92\n",
            "Training 5220: Loss=2.16 Acc@1=41.25 Acc@5=71.25\n",
            "Training 5250: Loss=2.21 Acc@1=42.08 Acc@5=72.08\n",
            "Training 5280: Loss=2.17 Acc@1=40.42 Acc@5=74.17\n",
            "Training 5310: Loss=2.23 Acc@1=39.17 Acc@5=75.42\n",
            "Training 5340: Loss=2.32 Acc@1=40.83 Acc@5=69.17\n",
            "Training 5370: Loss=2.19 Acc@1=40.42 Acc@5=74.17\n",
            "Training 5400: Loss=2.12 Acc@1=45.0 Acc@5=72.92\n",
            "Training 5430: Loss=2.25 Acc@1=39.58 Acc@5=73.75\n",
            "Training 5460: Loss=2.21 Acc@1=44.58 Acc@5=73.75\n",
            "Training 5490: Loss=2.24 Acc@1=32.5 Acc@5=74.17\n",
            "Training 5520: Loss=2.24 Acc@1=42.08 Acc@5=74.17\n",
            "Training 5550: Loss=2.27 Acc@1=41.25 Acc@5=68.75\n",
            "Training 5580: Loss=2.12 Acc@1=47.92 Acc@5=72.08\n",
            "Training 5610: Loss=2.07 Acc@1=43.33 Acc@5=74.58\n",
            "Training 5640: Loss=2.03 Acc@1=45.42 Acc@5=79.17\n",
            "Training 5670: Loss=2.21 Acc@1=44.17 Acc@5=72.08\n",
            "Training 5700: Loss=2.21 Acc@1=41.67 Acc@5=72.08\n",
            "Training 5730: Loss=2.12 Acc@1=45.42 Acc@5=75.42\n",
            "Training 5760: Loss=2.13 Acc@1=45.42 Acc@5=73.33\n",
            "Training 5790: Loss=2.35 Acc@1=42.5 Acc@5=70.42\n",
            "Training 5820: Loss=2.18 Acc@1=40.0 Acc@5=74.58\n",
            "Training 5850: Loss=2.14 Acc@1=42.08 Acc@5=75.0\n",
            "Training 5880: Loss=2.02 Acc@1=42.5 Acc@5=76.25\n",
            "Training 5910: Loss=2.32 Acc@1=35.83 Acc@5=71.67\n",
            "Training 5940: Loss=2.05 Acc@1=45.0 Acc@5=74.17\n",
            "Training 5970: Loss=2.24 Acc@1=39.17 Acc@5=72.08\n",
            "Training 6000: Loss=2.43 Acc@1=37.5 Acc@5=67.92\n",
            "Training 6030: Loss=2.17 Acc@1=47.08 Acc@5=71.25\n",
            "Training 6060: Loss=2.38 Acc@1=38.75 Acc@5=71.25\n",
            "Training 6090: Loss=2.34 Acc@1=41.67 Acc@5=68.33\n",
            "Training 6120: Loss=2.12 Acc@1=42.92 Acc@5=73.33\n",
            "Training 6150: Loss=1.94 Acc@1=47.08 Acc@5=80.0\n",
            "Training 6180: Loss=1.99 Acc@1=47.08 Acc@5=75.42\n",
            "Training 6210: Loss=2.09 Acc@1=45.42 Acc@5=74.58\n",
            "Training 6240: Loss=2.4 Acc@1=37.5 Acc@5=71.25\n",
            "Full imagenet train set: Acc@1=52.5 Acc@5=82.5\n",
            "Epoch: 9 ######################################################\n",
            "Training 30: Loss=2.04 Acc@1=45.42 Acc@5=77.08\n",
            "Training 60: Loss=2.02 Acc@1=47.08 Acc@5=77.5\n",
            "Training 90: Loss=2.19 Acc@1=42.08 Acc@5=72.92\n",
            "Training 120: Loss=1.99 Acc@1=48.33 Acc@5=78.75\n",
            "Training 150: Loss=2.14 Acc@1=42.92 Acc@5=70.83\n",
            "Training 180: Loss=1.94 Acc@1=47.92 Acc@5=76.25\n",
            "Training 210: Loss=1.93 Acc@1=45.42 Acc@5=81.67\n",
            "Training 240: Loss=2.03 Acc@1=42.92 Acc@5=77.5\n",
            "Training 270: Loss=2.09 Acc@1=44.17 Acc@5=76.25\n",
            "Training 300: Loss=1.84 Acc@1=49.58 Acc@5=80.42\n",
            "Training 330: Loss=2.02 Acc@1=46.25 Acc@5=77.5\n",
            "Training 360: Loss=2.07 Acc@1=44.58 Acc@5=76.67\n",
            "Training 390: Loss=2.09 Acc@1=46.25 Acc@5=75.83\n",
            "Training 420: Loss=1.95 Acc@1=48.75 Acc@5=76.67\n",
            "Training 450: Loss=1.98 Acc@1=44.58 Acc@5=77.92\n",
            "Training 480: Loss=2.18 Acc@1=42.5 Acc@5=75.0\n",
            "Training 510: Loss=2.12 Acc@1=42.5 Acc@5=75.83\n",
            "Training 540: Loss=2.28 Acc@1=42.5 Acc@5=72.5\n",
            "Training 570: Loss=1.97 Acc@1=45.83 Acc@5=77.92\n",
            "Training 600: Loss=2.07 Acc@1=42.08 Acc@5=77.08\n",
            "Training 630: Loss=2.15 Acc@1=40.83 Acc@5=75.0\n",
            "Training 660: Loss=2.16 Acc@1=41.67 Acc@5=71.25\n",
            "Training 690: Loss=2.11 Acc@1=42.92 Acc@5=75.42\n",
            "Training 720: Loss=2.29 Acc@1=41.67 Acc@5=71.25\n",
            "Training 750: Loss=2.02 Acc@1=48.33 Acc@5=78.75\n",
            "Training 780: Loss=2.01 Acc@1=45.42 Acc@5=77.08\n",
            "Training 810: Loss=2.04 Acc@1=42.5 Acc@5=76.67\n",
            "Training 840: Loss=1.91 Acc@1=51.25 Acc@5=79.17\n",
            "Training 870: Loss=2.06 Acc@1=44.17 Acc@5=74.17\n",
            "Training 900: Loss=2.16 Acc@1=48.75 Acc@5=76.67\n",
            "Training 930: Loss=2.18 Acc@1=42.5 Acc@5=71.25\n",
            "Training 960: Loss=1.88 Acc@1=45.0 Acc@5=80.42\n",
            "Training 990: Loss=1.97 Acc@1=45.42 Acc@5=79.58\n",
            "Training 1020: Loss=2.03 Acc@1=43.33 Acc@5=75.42\n",
            "Training 1050: Loss=2.04 Acc@1=42.5 Acc@5=75.83\n",
            "Training 1080: Loss=2.22 Acc@1=38.75 Acc@5=71.25\n",
            "Training 1110: Loss=2.11 Acc@1=49.17 Acc@5=74.58\n",
            "Training 1140: Loss=2.04 Acc@1=47.08 Acc@5=76.67\n",
            "Training 1170: Loss=2.1 Acc@1=41.25 Acc@5=74.17\n",
            "Training 1200: Loss=2.22 Acc@1=42.5 Acc@5=69.58\n",
            "Training 1230: Loss=2.18 Acc@1=41.25 Acc@5=76.25\n",
            "Training 1260: Loss=2.2 Acc@1=39.17 Acc@5=75.83\n",
            "Training 1290: Loss=2.18 Acc@1=43.75 Acc@5=71.67\n",
            "Training 1320: Loss=2.01 Acc@1=48.33 Acc@5=74.17\n",
            "Training 1350: Loss=2.07 Acc@1=45.0 Acc@5=75.83\n",
            "Training 1380: Loss=2.16 Acc@1=44.17 Acc@5=76.67\n",
            "Training 1410: Loss=2.33 Acc@1=41.67 Acc@5=72.5\n",
            "Training 1440: Loss=2.12 Acc@1=45.83 Acc@5=73.75\n",
            "Training 1470: Loss=2.29 Acc@1=39.17 Acc@5=73.33\n",
            "Training 1500: Loss=2.23 Acc@1=42.08 Acc@5=73.75\n",
            "Training 1530: Loss=2.25 Acc@1=40.0 Acc@5=72.92\n",
            "Training 1560: Loss=2.13 Acc@1=44.58 Acc@5=72.5\n",
            "Training 1590: Loss=2.1 Acc@1=41.25 Acc@5=75.83\n",
            "Training 1620: Loss=1.92 Acc@1=47.5 Acc@5=80.0\n",
            "Training 1650: Loss=1.98 Acc@1=47.92 Acc@5=75.42\n",
            "Training 1680: Loss=2.27 Acc@1=38.33 Acc@5=71.67\n",
            "Training 1710: Loss=2.13 Acc@1=47.92 Acc@5=75.83\n",
            "Training 1740: Loss=1.95 Acc@1=49.17 Acc@5=77.08\n",
            "Training 1770: Loss=1.99 Acc@1=44.58 Acc@5=82.08\n",
            "Training 1800: Loss=1.99 Acc@1=47.5 Acc@5=79.17\n",
            "Training 1830: Loss=1.94 Acc@1=48.33 Acc@5=77.92\n",
            "Training 1860: Loss=2.16 Acc@1=41.25 Acc@5=76.25\n",
            "Training 1890: Loss=2.04 Acc@1=45.0 Acc@5=79.17\n",
            "Training 1920: Loss=2.01 Acc@1=46.67 Acc@5=73.75\n",
            "Training 1950: Loss=2.21 Acc@1=41.67 Acc@5=72.08\n",
            "Training 1980: Loss=2.0 Acc@1=43.33 Acc@5=77.08\n",
            "Training 2010: Loss=1.97 Acc@1=47.92 Acc@5=77.5\n",
            "Training 2040: Loss=2.1 Acc@1=46.25 Acc@5=76.25\n",
            "Training 2070: Loss=2.24 Acc@1=42.92 Acc@5=70.83\n",
            "Training 2100: Loss=2.21 Acc@1=38.33 Acc@5=76.25\n",
            "Training 2130: Loss=1.84 Acc@1=51.67 Acc@5=79.58\n",
            "Training 2160: Loss=2.18 Acc@1=40.42 Acc@5=69.58\n",
            "Training 2190: Loss=2.12 Acc@1=43.75 Acc@5=74.17\n",
            "Training 2220: Loss=2.15 Acc@1=40.83 Acc@5=73.33\n",
            "Training 2250: Loss=2.25 Acc@1=42.5 Acc@5=72.5\n",
            "Training 2280: Loss=2.0 Acc@1=47.08 Acc@5=78.33\n",
            "Training 2310: Loss=1.91 Acc@1=47.92 Acc@5=78.33\n",
            "Training 2340: Loss=2.01 Acc@1=46.67 Acc@5=76.25\n",
            "Training 2370: Loss=2.03 Acc@1=43.33 Acc@5=76.25\n",
            "Training 2400: Loss=2.04 Acc@1=48.75 Acc@5=76.25\n",
            "Training 2430: Loss=2.24 Acc@1=41.25 Acc@5=76.67\n",
            "Training 2460: Loss=2.16 Acc@1=42.92 Acc@5=75.42\n",
            "Training 2490: Loss=1.93 Acc@1=47.5 Acc@5=80.0\n",
            "Training 2520: Loss=2.24 Acc@1=42.92 Acc@5=72.5\n",
            "Training 2550: Loss=2.11 Acc@1=43.75 Acc@5=74.58\n",
            "Training 2580: Loss=2.22 Acc@1=46.25 Acc@5=74.17\n",
            "Training 2610: Loss=2.06 Acc@1=44.58 Acc@5=77.5\n",
            "Training 2640: Loss=2.06 Acc@1=46.25 Acc@5=76.25\n",
            "Training 2670: Loss=2.1 Acc@1=47.08 Acc@5=76.67\n",
            "Training 2700: Loss=2.17 Acc@1=43.75 Acc@5=73.33\n",
            "Training 2730: Loss=2.18 Acc@1=44.17 Acc@5=75.42\n",
            "Training 2760: Loss=2.04 Acc@1=47.5 Acc@5=75.42\n",
            "Training 2790: Loss=2.04 Acc@1=50.0 Acc@5=76.67\n",
            "Training 2820: Loss=2.09 Acc@1=41.67 Acc@5=75.42\n",
            "Training 2850: Loss=2.22 Acc@1=41.67 Acc@5=70.83\n",
            "Training 2880: Loss=2.06 Acc@1=42.08 Acc@5=75.83\n",
            "Training 2910: Loss=2.18 Acc@1=44.17 Acc@5=72.5\n",
            "Training 2940: Loss=1.99 Acc@1=47.08 Acc@5=79.58\n",
            "Training 2970: Loss=2.25 Acc@1=47.08 Acc@5=72.5\n",
            "Training 3000: Loss=1.98 Acc@1=50.0 Acc@5=78.75\n",
            "Training 3030: Loss=1.9 Acc@1=48.75 Acc@5=79.58\n",
            "Training 3060: Loss=1.95 Acc@1=46.67 Acc@5=77.5\n",
            "Training 3090: Loss=2.36 Acc@1=41.67 Acc@5=67.5\n",
            "Training 3120: Loss=2.11 Acc@1=44.17 Acc@5=77.5\n",
            "Training 3150: Loss=2.06 Acc@1=45.0 Acc@5=76.25\n",
            "Training 3180: Loss=1.9 Acc@1=45.0 Acc@5=81.25\n",
            "Training 3210: Loss=2.42 Acc@1=35.0 Acc@5=67.92\n",
            "Training 3240: Loss=1.85 Acc@1=50.0 Acc@5=79.58\n",
            "Training 3270: Loss=2.14 Acc@1=42.5 Acc@5=72.5\n",
            "Training 3300: Loss=2.25 Acc@1=42.5 Acc@5=70.42\n",
            "Training 3330: Loss=1.98 Acc@1=47.08 Acc@5=78.33\n",
            "Training 3360: Loss=2.12 Acc@1=42.5 Acc@5=75.0\n",
            "Training 3390: Loss=2.2 Acc@1=45.42 Acc@5=73.33\n",
            "Training 3420: Loss=2.16 Acc@1=47.08 Acc@5=72.92\n",
            "Training 3450: Loss=2.22 Acc@1=40.42 Acc@5=72.08\n",
            "Training 3480: Loss=2.13 Acc@1=45.0 Acc@5=73.75\n",
            "Training 3510: Loss=2.34 Acc@1=34.17 Acc@5=72.5\n",
            "Training 3540: Loss=2.06 Acc@1=48.75 Acc@5=78.33\n",
            "Training 3570: Loss=2.5 Acc@1=34.17 Acc@5=65.42\n",
            "Training 3600: Loss=2.33 Acc@1=42.5 Acc@5=70.42\n",
            "Training 3630: Loss=2.14 Acc@1=42.5 Acc@5=73.33\n",
            "Training 3660: Loss=1.96 Acc@1=48.33 Acc@5=76.25\n",
            "Training 3690: Loss=2.27 Acc@1=45.0 Acc@5=72.08\n",
            "Training 3720: Loss=2.2 Acc@1=43.75 Acc@5=71.67\n",
            "Training 3750: Loss=2.27 Acc@1=40.83 Acc@5=72.5\n",
            "Training 3780: Loss=2.18 Acc@1=42.5 Acc@5=71.67\n",
            "Training 3810: Loss=2.05 Acc@1=46.67 Acc@5=75.42\n",
            "Training 3840: Loss=2.08 Acc@1=47.5 Acc@5=76.25\n",
            "Training 3870: Loss=2.26 Acc@1=45.83 Acc@5=70.83\n",
            "Training 3900: Loss=2.14 Acc@1=41.25 Acc@5=75.83\n",
            "Training 3930: Loss=2.09 Acc@1=45.0 Acc@5=76.67\n",
            "Training 3960: Loss=2.27 Acc@1=40.42 Acc@5=75.0\n",
            "Training 3990: Loss=2.04 Acc@1=48.33 Acc@5=74.58\n",
            "Training 4020: Loss=2.11 Acc@1=43.33 Acc@5=72.92\n",
            "Training 4050: Loss=2.1 Acc@1=43.75 Acc@5=76.25\n",
            "Training 4080: Loss=2.24 Acc@1=40.0 Acc@5=76.25\n",
            "Training 4110: Loss=2.14 Acc@1=40.42 Acc@5=72.5\n",
            "Training 4140: Loss=2.12 Acc@1=43.33 Acc@5=75.83\n",
            "Training 4170: Loss=2.14 Acc@1=44.58 Acc@5=72.92\n",
            "Training 4200: Loss=2.22 Acc@1=46.25 Acc@5=72.08\n",
            "Training 4230: Loss=2.26 Acc@1=41.67 Acc@5=73.75\n",
            "Training 4260: Loss=2.15 Acc@1=43.75 Acc@5=71.25\n",
            "Training 4290: Loss=2.28 Acc@1=42.92 Acc@5=70.42\n",
            "Training 4320: Loss=1.96 Acc@1=46.25 Acc@5=76.67\n",
            "Training 4350: Loss=2.3 Acc@1=41.25 Acc@5=68.33\n",
            "Training 4380: Loss=2.03 Acc@1=45.83 Acc@5=75.83\n",
            "Training 4410: Loss=2.21 Acc@1=42.08 Acc@5=75.0\n",
            "Training 4440: Loss=2.13 Acc@1=45.42 Acc@5=73.75\n",
            "Training 4470: Loss=2.3 Acc@1=38.75 Acc@5=72.92\n",
            "Training 4500: Loss=2.27 Acc@1=42.92 Acc@5=72.08\n",
            "Training 4530: Loss=2.11 Acc@1=43.75 Acc@5=77.92\n",
            "Training 4560: Loss=2.01 Acc@1=45.0 Acc@5=76.67\n",
            "Training 4590: Loss=2.05 Acc@1=45.83 Acc@5=74.17\n",
            "Training 4620: Loss=2.13 Acc@1=42.92 Acc@5=74.17\n",
            "Training 4650: Loss=1.77 Acc@1=53.75 Acc@5=82.92\n",
            "Training 4680: Loss=2.0 Acc@1=44.58 Acc@5=76.67\n",
            "Training 4710: Loss=2.27 Acc@1=40.83 Acc@5=69.17\n",
            "Training 4740: Loss=2.03 Acc@1=45.83 Acc@5=78.33\n",
            "Training 4770: Loss=2.35 Acc@1=40.42 Acc@5=70.42\n",
            "Training 4800: Loss=2.0 Acc@1=46.67 Acc@5=75.83\n",
            "Training 4830: Loss=2.01 Acc@1=43.75 Acc@5=76.25\n",
            "Training 4860: Loss=2.11 Acc@1=41.25 Acc@5=73.75\n",
            "Training 4890: Loss=1.98 Acc@1=45.42 Acc@5=76.25\n",
            "Training 4920: Loss=1.96 Acc@1=47.92 Acc@5=78.75\n",
            "Training 4950: Loss=2.05 Acc@1=47.92 Acc@5=72.92\n",
            "Training 4980: Loss=2.05 Acc@1=44.17 Acc@5=77.92\n",
            "Training 5010: Loss=2.02 Acc@1=43.75 Acc@5=76.67\n",
            "Training 5040: Loss=2.15 Acc@1=47.08 Acc@5=72.08\n",
            "Training 5070: Loss=2.22 Acc@1=38.33 Acc@5=71.67\n",
            "Training 5100: Loss=2.07 Acc@1=47.5 Acc@5=75.42\n",
            "Training 5130: Loss=2.24 Acc@1=38.75 Acc@5=69.17\n",
            "Training 5160: Loss=2.08 Acc@1=46.25 Acc@5=72.92\n",
            "Training 5190: Loss=2.14 Acc@1=41.25 Acc@5=74.58\n",
            "Training 5220: Loss=1.98 Acc@1=47.5 Acc@5=78.75\n",
            "Training 5250: Loss=2.07 Acc@1=44.17 Acc@5=76.25\n",
            "Training 5280: Loss=2.22 Acc@1=42.5 Acc@5=72.08\n",
            "Training 5310: Loss=2.09 Acc@1=42.5 Acc@5=77.5\n",
            "Training 5340: Loss=2.42 Acc@1=34.58 Acc@5=70.83\n",
            "Training 5370: Loss=2.02 Acc@1=46.25 Acc@5=77.5\n",
            "Training 5400: Loss=2.29 Acc@1=37.08 Acc@5=70.83\n",
            "Training 5430: Loss=2.02 Acc@1=44.17 Acc@5=76.25\n",
            "Training 5460: Loss=2.09 Acc@1=46.67 Acc@5=75.42\n",
            "Training 5490: Loss=1.8 Acc@1=53.75 Acc@5=82.08\n",
            "Training 5520: Loss=2.03 Acc@1=48.75 Acc@5=75.0\n",
            "Training 5550: Loss=2.02 Acc@1=47.92 Acc@5=75.42\n",
            "Training 5580: Loss=2.07 Acc@1=44.58 Acc@5=77.5\n",
            "Training 5610: Loss=2.06 Acc@1=45.42 Acc@5=73.33\n",
            "Training 5640: Loss=2.22 Acc@1=42.08 Acc@5=71.25\n",
            "Training 5670: Loss=2.35 Acc@1=37.5 Acc@5=69.58\n",
            "Training 5700: Loss=2.04 Acc@1=47.5 Acc@5=77.08\n",
            "Training 5730: Loss=2.32 Acc@1=42.5 Acc@5=71.25\n",
            "Training 5760: Loss=2.0 Acc@1=46.67 Acc@5=78.33\n",
            "Training 5790: Loss=2.13 Acc@1=47.92 Acc@5=72.92\n",
            "Training 5820: Loss=2.07 Acc@1=46.25 Acc@5=75.42\n",
            "Training 5850: Loss=2.21 Acc@1=44.17 Acc@5=72.08\n",
            "Training 5880: Loss=2.19 Acc@1=46.67 Acc@5=72.92\n",
            "Training 5910: Loss=2.27 Acc@1=37.08 Acc@5=72.5\n",
            "Training 5940: Loss=1.94 Acc@1=46.67 Acc@5=80.0\n",
            "Training 5970: Loss=2.32 Acc@1=44.58 Acc@5=72.08\n",
            "Training 6000: Loss=2.09 Acc@1=46.25 Acc@5=75.83\n",
            "Training 6030: Loss=2.01 Acc@1=45.83 Acc@5=75.42\n",
            "Training 6060: Loss=2.13 Acc@1=45.42 Acc@5=72.92\n",
            "Training 6090: Loss=2.24 Acc@1=40.83 Acc@5=73.33\n",
            "Training 6120: Loss=2.15 Acc@1=37.92 Acc@5=76.25\n",
            "Training 6150: Loss=2.26 Acc@1=45.83 Acc@5=71.67\n",
            "Training 6180: Loss=2.03 Acc@1=46.67 Acc@5=75.0\n",
            "Training 6210: Loss=1.95 Acc@1=49.58 Acc@5=75.0\n",
            "Training 6240: Loss=2.14 Acc@1=41.25 Acc@5=75.0\n",
            "Full imagenet train set: Acc@1=48.75 Acc@5=87.5\n",
            "Epoch: 10 ######################################################\n",
            "Training 30: Loss=1.96 Acc@1=45.83 Acc@5=80.83\n",
            "Training 60: Loss=1.82 Acc@1=53.75 Acc@5=81.67\n",
            "Training 90: Loss=2.06 Acc@1=46.67 Acc@5=75.0\n",
            "Training 120: Loss=1.97 Acc@1=49.17 Acc@5=77.08\n",
            "Training 150: Loss=1.82 Acc@1=53.33 Acc@5=80.0\n",
            "Training 180: Loss=1.99 Acc@1=48.33 Acc@5=76.25\n",
            "Training 210: Loss=2.16 Acc@1=41.25 Acc@5=73.33\n",
            "Training 240: Loss=1.91 Acc@1=50.0 Acc@5=78.75\n",
            "Training 270: Loss=2.14 Acc@1=42.92 Acc@5=76.25\n",
            "Training 300: Loss=1.9 Acc@1=46.67 Acc@5=79.58\n",
            "Training 330: Loss=1.92 Acc@1=49.58 Acc@5=78.33\n",
            "Training 360: Loss=1.94 Acc@1=47.92 Acc@5=75.0\n",
            "Training 390: Loss=1.92 Acc@1=51.25 Acc@5=80.0\n",
            "Training 420: Loss=1.96 Acc@1=49.17 Acc@5=77.92\n",
            "Training 450: Loss=2.14 Acc@1=45.0 Acc@5=77.08\n",
            "Training 480: Loss=1.9 Acc@1=50.0 Acc@5=77.92\n",
            "Training 510: Loss=2.08 Acc@1=47.5 Acc@5=70.42\n",
            "Training 540: Loss=2.12 Acc@1=45.0 Acc@5=74.58\n",
            "Training 570: Loss=1.76 Acc@1=55.0 Acc@5=82.92\n",
            "Training 600: Loss=2.04 Acc@1=44.17 Acc@5=77.08\n",
            "Training 630: Loss=1.89 Acc@1=51.25 Acc@5=78.75\n",
            "Training 660: Loss=1.98 Acc@1=47.08 Acc@5=75.83\n",
            "Training 690: Loss=1.99 Acc@1=47.08 Acc@5=76.67\n",
            "Training 720: Loss=2.09 Acc@1=45.83 Acc@5=74.58\n",
            "Training 750: Loss=1.98 Acc@1=44.58 Acc@5=78.33\n",
            "Training 780: Loss=2.22 Acc@1=42.92 Acc@5=71.67\n",
            "Training 810: Loss=2.18 Acc@1=40.42 Acc@5=77.5\n",
            "Training 840: Loss=2.04 Acc@1=48.75 Acc@5=75.0\n",
            "Training 870: Loss=1.94 Acc@1=45.83 Acc@5=75.83\n",
            "Training 900: Loss=1.83 Acc@1=45.83 Acc@5=80.0\n",
            "Training 930: Loss=1.95 Acc@1=51.25 Acc@5=76.25\n",
            "Training 960: Loss=1.89 Acc@1=46.25 Acc@5=76.67\n",
            "Training 990: Loss=2.0 Acc@1=47.5 Acc@5=77.5\n",
            "Training 1020: Loss=2.03 Acc@1=47.92 Acc@5=79.17\n",
            "Training 1050: Loss=1.92 Acc@1=50.0 Acc@5=78.75\n",
            "Training 1080: Loss=2.01 Acc@1=43.33 Acc@5=75.83\n",
            "Training 1110: Loss=1.94 Acc@1=49.58 Acc@5=76.67\n",
            "Training 1140: Loss=1.99 Acc@1=45.83 Acc@5=76.25\n",
            "Training 1170: Loss=2.02 Acc@1=47.92 Acc@5=77.92\n",
            "Training 1200: Loss=2.24 Acc@1=43.33 Acc@5=71.25\n",
            "Training 1230: Loss=2.01 Acc@1=45.83 Acc@5=78.75\n",
            "Training 1260: Loss=1.9 Acc@1=46.25 Acc@5=76.25\n",
            "Training 1290: Loss=2.12 Acc@1=42.92 Acc@5=75.0\n",
            "Training 1320: Loss=2.12 Acc@1=46.25 Acc@5=75.42\n",
            "Training 1350: Loss=2.02 Acc@1=46.67 Acc@5=78.33\n",
            "Training 1380: Loss=1.62 Acc@1=53.33 Acc@5=86.25\n",
            "Training 1410: Loss=2.04 Acc@1=47.08 Acc@5=76.25\n",
            "Training 1440: Loss=2.02 Acc@1=47.92 Acc@5=73.75\n",
            "Training 1470: Loss=2.06 Acc@1=43.33 Acc@5=75.42\n",
            "Training 1500: Loss=2.21 Acc@1=42.92 Acc@5=70.42\n",
            "Training 1530: Loss=1.92 Acc@1=48.33 Acc@5=79.58\n",
            "Training 1560: Loss=1.9 Acc@1=51.25 Acc@5=76.67\n",
            "Training 1590: Loss=1.85 Acc@1=50.0 Acc@5=78.75\n",
            "Training 1620: Loss=2.05 Acc@1=45.42 Acc@5=75.0\n",
            "Training 1650: Loss=2.08 Acc@1=45.83 Acc@5=72.08\n",
            "Training 1680: Loss=1.99 Acc@1=46.25 Acc@5=76.25\n",
            "Training 1710: Loss=2.02 Acc@1=42.92 Acc@5=77.92\n",
            "Training 1740: Loss=2.03 Acc@1=42.92 Acc@5=76.25\n",
            "Training 1770: Loss=1.92 Acc@1=49.58 Acc@5=78.75\n",
            "Training 1800: Loss=1.89 Acc@1=54.17 Acc@5=79.17\n",
            "Training 1830: Loss=2.11 Acc@1=45.83 Acc@5=75.83\n",
            "Training 1860: Loss=2.16 Acc@1=37.92 Acc@5=76.67\n",
            "Training 1890: Loss=2.11 Acc@1=44.17 Acc@5=74.58\n",
            "Training 1920: Loss=1.98 Acc@1=44.58 Acc@5=78.33\n",
            "Training 1950: Loss=1.7 Acc@1=52.08 Acc@5=84.17\n",
            "Training 1980: Loss=1.97 Acc@1=47.5 Acc@5=75.42\n",
            "Training 2010: Loss=2.11 Acc@1=44.58 Acc@5=75.42\n",
            "Training 2040: Loss=2.01 Acc@1=48.33 Acc@5=77.08\n",
            "Training 2070: Loss=2.12 Acc@1=40.83 Acc@5=75.0\n",
            "Training 2100: Loss=1.93 Acc@1=46.25 Acc@5=80.0\n",
            "Training 2130: Loss=2.07 Acc@1=43.33 Acc@5=77.5\n",
            "Training 2160: Loss=1.91 Acc@1=47.5 Acc@5=79.17\n",
            "Training 2190: Loss=1.93 Acc@1=47.5 Acc@5=83.33\n",
            "Training 2220: Loss=2.18 Acc@1=42.92 Acc@5=74.58\n",
            "Training 2250: Loss=2.1 Acc@1=44.17 Acc@5=71.67\n",
            "Training 2280: Loss=1.97 Acc@1=44.17 Acc@5=78.33\n",
            "Training 2310: Loss=1.81 Acc@1=53.33 Acc@5=81.25\n",
            "Training 2340: Loss=1.83 Acc@1=53.33 Acc@5=78.75\n",
            "Training 2370: Loss=2.22 Acc@1=43.75 Acc@5=72.5\n",
            "Training 2400: Loss=2.05 Acc@1=47.08 Acc@5=77.5\n",
            "Training 2430: Loss=1.97 Acc@1=46.67 Acc@5=77.08\n",
            "Training 2460: Loss=2.04 Acc@1=47.08 Acc@5=74.17\n",
            "Training 2490: Loss=1.95 Acc@1=47.08 Acc@5=79.17\n",
            "Training 2520: Loss=2.1 Acc@1=45.42 Acc@5=76.25\n",
            "Training 2550: Loss=2.11 Acc@1=42.5 Acc@5=79.58\n",
            "Training 2580: Loss=1.98 Acc@1=45.83 Acc@5=77.5\n",
            "Training 2610: Loss=2.06 Acc@1=45.0 Acc@5=75.0\n",
            "Training 2640: Loss=1.89 Acc@1=50.83 Acc@5=79.58\n",
            "Training 2670: Loss=2.06 Acc@1=42.92 Acc@5=74.58\n",
            "Training 2700: Loss=2.13 Acc@1=45.0 Acc@5=77.08\n",
            "Training 2730: Loss=2.22 Acc@1=41.67 Acc@5=73.75\n",
            "Training 2760: Loss=2.14 Acc@1=45.0 Acc@5=76.25\n",
            "Training 2790: Loss=2.03 Acc@1=44.58 Acc@5=76.67\n",
            "Training 2820: Loss=1.95 Acc@1=45.0 Acc@5=79.58\n",
            "Training 2850: Loss=1.91 Acc@1=45.83 Acc@5=79.58\n",
            "Training 2880: Loss=2.1 Acc@1=41.67 Acc@5=75.42\n",
            "Training 2910: Loss=1.9 Acc@1=46.67 Acc@5=77.92\n",
            "Training 2940: Loss=2.1 Acc@1=42.5 Acc@5=76.67\n",
            "Training 2970: Loss=1.97 Acc@1=50.83 Acc@5=75.0\n",
            "Training 3000: Loss=1.97 Acc@1=49.17 Acc@5=77.5\n",
            "Training 3030: Loss=2.14 Acc@1=41.67 Acc@5=75.42\n",
            "Training 3060: Loss=2.24 Acc@1=41.67 Acc@5=70.83\n",
            "Training 3090: Loss=1.95 Acc@1=50.0 Acc@5=78.75\n",
            "Training 3120: Loss=2.09 Acc@1=42.5 Acc@5=77.92\n",
            "Training 3150: Loss=2.14 Acc@1=47.5 Acc@5=73.33\n",
            "Training 3180: Loss=2.14 Acc@1=42.92 Acc@5=77.08\n",
            "Training 3210: Loss=1.88 Acc@1=49.58 Acc@5=77.92\n",
            "Training 3240: Loss=1.98 Acc@1=48.75 Acc@5=78.33\n",
            "Training 3270: Loss=2.22 Acc@1=44.17 Acc@5=71.67\n",
            "Training 3300: Loss=2.04 Acc@1=46.25 Acc@5=75.42\n",
            "Training 3330: Loss=2.07 Acc@1=46.25 Acc@5=77.5\n",
            "Training 3360: Loss=2.15 Acc@1=46.67 Acc@5=73.33\n",
            "Training 3390: Loss=2.19 Acc@1=44.17 Acc@5=72.92\n",
            "Training 3420: Loss=1.88 Acc@1=49.58 Acc@5=80.0\n",
            "Training 3450: Loss=2.09 Acc@1=46.67 Acc@5=74.58\n",
            "Training 3480: Loss=1.98 Acc@1=46.67 Acc@5=76.25\n",
            "Training 3510: Loss=1.87 Acc@1=48.75 Acc@5=80.0\n",
            "Training 3540: Loss=1.97 Acc@1=43.75 Acc@5=78.33\n",
            "Training 3570: Loss=1.99 Acc@1=44.58 Acc@5=77.08\n",
            "Training 3600: Loss=2.08 Acc@1=44.58 Acc@5=76.67\n",
            "Training 3630: Loss=1.95 Acc@1=46.67 Acc@5=80.0\n",
            "Training 3660: Loss=2.17 Acc@1=43.75 Acc@5=76.25\n",
            "Training 3690: Loss=2.04 Acc@1=44.17 Acc@5=78.75\n",
            "Training 3720: Loss=2.1 Acc@1=42.08 Acc@5=77.92\n",
            "Training 3750: Loss=1.92 Acc@1=45.83 Acc@5=78.33\n",
            "Training 3780: Loss=2.06 Acc@1=45.42 Acc@5=77.08\n",
            "Training 3810: Loss=2.01 Acc@1=46.67 Acc@5=76.25\n",
            "Training 3840: Loss=2.26 Acc@1=42.5 Acc@5=72.92\n",
            "Training 3870: Loss=2.17 Acc@1=41.67 Acc@5=72.08\n",
            "Training 3900: Loss=2.11 Acc@1=44.17 Acc@5=75.0\n",
            "Training 3930: Loss=2.14 Acc@1=47.92 Acc@5=71.67\n",
            "Training 3960: Loss=2.32 Acc@1=38.75 Acc@5=72.92\n",
            "Training 3990: Loss=2.24 Acc@1=41.67 Acc@5=71.67\n",
            "Training 4020: Loss=2.09 Acc@1=47.92 Acc@5=75.0\n",
            "Training 4050: Loss=2.03 Acc@1=44.17 Acc@5=78.33\n",
            "Training 4080: Loss=2.03 Acc@1=47.08 Acc@5=73.33\n",
            "Training 4110: Loss=2.35 Acc@1=37.5 Acc@5=70.42\n",
            "Training 4140: Loss=2.2 Acc@1=40.0 Acc@5=75.83\n",
            "Training 4170: Loss=1.9 Acc@1=46.67 Acc@5=78.33\n",
            "Training 4200: Loss=1.93 Acc@1=46.25 Acc@5=77.92\n",
            "Training 4230: Loss=2.11 Acc@1=45.0 Acc@5=76.25\n",
            "Training 4260: Loss=2.17 Acc@1=48.33 Acc@5=73.33\n",
            "Training 4290: Loss=2.17 Acc@1=39.58 Acc@5=75.0\n",
            "Training 4320: Loss=1.94 Acc@1=46.25 Acc@5=79.17\n",
            "Training 4350: Loss=2.27 Acc@1=40.42 Acc@5=74.58\n",
            "Training 4380: Loss=2.33 Acc@1=42.92 Acc@5=72.08\n",
            "Training 4410: Loss=2.2 Acc@1=41.67 Acc@5=74.17\n",
            "Training 4440: Loss=2.07 Acc@1=43.33 Acc@5=75.42\n",
            "Training 4470: Loss=2.19 Acc@1=43.75 Acc@5=76.67\n",
            "Training 4500: Loss=1.94 Acc@1=45.42 Acc@5=79.17\n",
            "Training 4530: Loss=1.97 Acc@1=45.83 Acc@5=77.08\n",
            "Training 4560: Loss=1.97 Acc@1=47.08 Acc@5=78.75\n",
            "Training 4590: Loss=1.98 Acc@1=44.17 Acc@5=79.58\n",
            "Training 4620: Loss=1.85 Acc@1=46.67 Acc@5=81.25\n",
            "Training 4650: Loss=2.1 Acc@1=41.25 Acc@5=76.25\n",
            "Training 4680: Loss=2.01 Acc@1=46.67 Acc@5=76.67\n",
            "Training 4710: Loss=1.97 Acc@1=48.33 Acc@5=75.42\n",
            "Training 4740: Loss=1.99 Acc@1=45.83 Acc@5=78.33\n",
            "Training 4770: Loss=2.05 Acc@1=45.83 Acc@5=75.42\n",
            "Training 4800: Loss=1.97 Acc@1=48.75 Acc@5=79.17\n",
            "Training 4830: Loss=2.03 Acc@1=46.67 Acc@5=77.92\n",
            "Training 4860: Loss=2.15 Acc@1=44.58 Acc@5=72.08\n",
            "Training 4890: Loss=1.91 Acc@1=51.25 Acc@5=77.92\n",
            "Training 4920: Loss=1.83 Acc@1=49.17 Acc@5=81.67\n",
            "Training 4950: Loss=2.2 Acc@1=40.42 Acc@5=75.0\n",
            "Training 4980: Loss=2.07 Acc@1=46.25 Acc@5=76.67\n",
            "Training 5010: Loss=2.02 Acc@1=48.33 Acc@5=73.33\n",
            "Training 5040: Loss=2.23 Acc@1=45.0 Acc@5=74.17\n",
            "Training 5070: Loss=1.87 Acc@1=48.33 Acc@5=81.25\n",
            "Training 5100: Loss=1.99 Acc@1=50.0 Acc@5=75.0\n",
            "Training 5130: Loss=1.86 Acc@1=52.08 Acc@5=78.33\n",
            "Training 5160: Loss=2.17 Acc@1=44.17 Acc@5=74.17\n",
            "Training 5190: Loss=2.03 Acc@1=46.25 Acc@5=77.92\n",
            "Training 5220: Loss=2.09 Acc@1=45.83 Acc@5=74.17\n",
            "Training 5250: Loss=1.97 Acc@1=50.0 Acc@5=77.92\n",
            "Training 5280: Loss=1.94 Acc@1=46.67 Acc@5=80.83\n",
            "Training 5310: Loss=2.0 Acc@1=48.33 Acc@5=75.42\n",
            "Training 5340: Loss=2.03 Acc@1=44.17 Acc@5=76.67\n",
            "Training 5370: Loss=1.88 Acc@1=49.58 Acc@5=78.75\n",
            "Training 5400: Loss=2.04 Acc@1=43.75 Acc@5=73.33\n",
            "Training 5430: Loss=1.96 Acc@1=48.75 Acc@5=75.42\n",
            "Training 5460: Loss=2.0 Acc@1=47.08 Acc@5=79.17\n",
            "Training 5490: Loss=1.96 Acc@1=44.17 Acc@5=77.5\n",
            "Training 5520: Loss=2.16 Acc@1=41.25 Acc@5=77.92\n",
            "Training 5550: Loss=2.01 Acc@1=50.42 Acc@5=76.25\n",
            "Training 5580: Loss=2.09 Acc@1=46.67 Acc@5=76.25\n",
            "Training 5610: Loss=2.05 Acc@1=47.08 Acc@5=78.75\n",
            "Training 5640: Loss=2.13 Acc@1=43.33 Acc@5=73.75\n",
            "Training 5670: Loss=2.2 Acc@1=40.42 Acc@5=73.75\n",
            "Training 5700: Loss=2.18 Acc@1=42.08 Acc@5=72.5\n",
            "Training 5730: Loss=2.12 Acc@1=42.92 Acc@5=74.17\n",
            "Training 5760: Loss=2.06 Acc@1=45.42 Acc@5=76.25\n",
            "Training 5790: Loss=2.09 Acc@1=46.25 Acc@5=75.0\n",
            "Training 5820: Loss=1.93 Acc@1=47.92 Acc@5=78.75\n",
            "Training 5850: Loss=1.95 Acc@1=47.92 Acc@5=80.0\n",
            "Training 5880: Loss=2.32 Acc@1=43.33 Acc@5=69.58\n",
            "Training 5910: Loss=2.1 Acc@1=44.58 Acc@5=75.83\n",
            "Training 5940: Loss=2.25 Acc@1=39.17 Acc@5=77.5\n",
            "Training 5970: Loss=2.0 Acc@1=48.75 Acc@5=75.0\n",
            "Training 6000: Loss=2.08 Acc@1=47.08 Acc@5=79.58\n",
            "Training 6030: Loss=1.93 Acc@1=47.5 Acc@5=77.08\n",
            "Training 6060: Loss=2.1 Acc@1=42.5 Acc@5=75.0\n",
            "Training 6090: Loss=1.94 Acc@1=46.25 Acc@5=79.17\n",
            "Training 6120: Loss=2.11 Acc@1=44.17 Acc@5=77.08\n",
            "Training 6150: Loss=1.96 Acc@1=45.42 Acc@5=77.92\n",
            "Training 6180: Loss=1.99 Acc@1=44.58 Acc@5=77.92\n",
            "Training 6210: Loss=2.04 Acc@1=44.58 Acc@5=73.75\n",
            "Training 6240: Loss=1.92 Acc@1=45.42 Acc@5=79.58\n",
            "Full imagenet train set: Acc@1=65.0 Acc@5=83.75\n",
            "Epoch: 11 ######################################################\n",
            "Training 30: Loss=1.92 Acc@1=50.42 Acc@5=78.75\n",
            "Training 60: Loss=1.84 Acc@1=49.58 Acc@5=81.25\n",
            "Training 90: Loss=1.95 Acc@1=50.0 Acc@5=76.25\n",
            "Training 120: Loss=1.9 Acc@1=46.67 Acc@5=76.25\n",
            "Training 150: Loss=2.07 Acc@1=42.08 Acc@5=74.58\n",
            "Training 180: Loss=1.94 Acc@1=47.08 Acc@5=76.25\n",
            "Training 210: Loss=1.98 Acc@1=45.83 Acc@5=78.75\n",
            "Training 240: Loss=1.98 Acc@1=48.75 Acc@5=77.5\n",
            "Training 270: Loss=1.9 Acc@1=46.67 Acc@5=80.0\n",
            "Training 300: Loss=1.93 Acc@1=47.08 Acc@5=80.42\n",
            "Training 330: Loss=1.84 Acc@1=52.5 Acc@5=79.17\n",
            "Training 360: Loss=1.85 Acc@1=53.75 Acc@5=78.75\n",
            "Training 390: Loss=1.94 Acc@1=48.33 Acc@5=79.58\n",
            "Training 420: Loss=1.85 Acc@1=48.33 Acc@5=83.33\n",
            "Training 450: Loss=1.86 Acc@1=47.08 Acc@5=76.67\n",
            "Training 480: Loss=1.89 Acc@1=47.08 Acc@5=80.0\n",
            "Training 510: Loss=1.96 Acc@1=49.17 Acc@5=78.33\n",
            "Training 540: Loss=1.84 Acc@1=46.67 Acc@5=79.58\n",
            "Training 570: Loss=2.01 Acc@1=49.58 Acc@5=75.0\n",
            "Training 600: Loss=1.72 Acc@1=50.42 Acc@5=82.5\n",
            "Training 630: Loss=1.77 Acc@1=55.83 Acc@5=80.0\n",
            "Training 660: Loss=1.75 Acc@1=56.25 Acc@5=81.25\n",
            "Training 690: Loss=1.98 Acc@1=47.5 Acc@5=77.92\n",
            "Training 720: Loss=1.76 Acc@1=52.08 Acc@5=82.5\n",
            "Training 750: Loss=2.04 Acc@1=45.42 Acc@5=77.92\n",
            "Training 780: Loss=2.05 Acc@1=44.58 Acc@5=74.58\n",
            "Training 810: Loss=1.9 Acc@1=46.25 Acc@5=78.33\n",
            "Training 840: Loss=1.97 Acc@1=49.17 Acc@5=77.08\n",
            "Training 870: Loss=1.98 Acc@1=45.0 Acc@5=75.0\n",
            "Training 900: Loss=2.03 Acc@1=42.5 Acc@5=78.33\n",
            "Training 930: Loss=1.92 Acc@1=47.08 Acc@5=77.08\n",
            "Training 960: Loss=1.63 Acc@1=55.42 Acc@5=81.25\n",
            "Training 990: Loss=2.03 Acc@1=45.42 Acc@5=80.0\n",
            "Training 1020: Loss=1.91 Acc@1=47.92 Acc@5=78.33\n",
            "Training 1050: Loss=2.09 Acc@1=46.67 Acc@5=75.42\n",
            "Training 1080: Loss=1.87 Acc@1=47.5 Acc@5=80.42\n",
            "Training 1110: Loss=1.98 Acc@1=48.33 Acc@5=75.83\n",
            "Training 1140: Loss=1.94 Acc@1=47.5 Acc@5=78.75\n",
            "Training 1170: Loss=1.88 Acc@1=48.33 Acc@5=77.08\n",
            "Training 1200: Loss=1.95 Acc@1=45.83 Acc@5=80.83\n",
            "Training 1230: Loss=1.66 Acc@1=56.67 Acc@5=84.58\n",
            "Training 1260: Loss=1.91 Acc@1=49.58 Acc@5=78.33\n",
            "Training 1290: Loss=1.84 Acc@1=51.25 Acc@5=77.92\n",
            "Training 1320: Loss=1.88 Acc@1=47.92 Acc@5=78.33\n",
            "Training 1350: Loss=2.1 Acc@1=43.33 Acc@5=75.42\n",
            "Training 1380: Loss=1.91 Acc@1=48.75 Acc@5=78.33\n",
            "Training 1410: Loss=2.02 Acc@1=46.67 Acc@5=77.92\n",
            "Training 1440: Loss=1.88 Acc@1=50.83 Acc@5=80.0\n",
            "Training 1470: Loss=1.78 Acc@1=51.25 Acc@5=81.25\n",
            "Training 1500: Loss=2.02 Acc@1=46.25 Acc@5=75.0\n",
            "Training 1530: Loss=1.92 Acc@1=47.92 Acc@5=79.17\n",
            "Training 1560: Loss=1.97 Acc@1=48.75 Acc@5=72.5\n",
            "Training 1590: Loss=2.16 Acc@1=43.33 Acc@5=73.33\n",
            "Training 1620: Loss=1.9 Acc@1=50.0 Acc@5=79.17\n",
            "Training 1650: Loss=1.99 Acc@1=45.42 Acc@5=79.58\n",
            "Training 1680: Loss=2.0 Acc@1=44.58 Acc@5=77.5\n",
            "Training 1710: Loss=1.91 Acc@1=47.5 Acc@5=79.58\n",
            "Training 1740: Loss=1.92 Acc@1=47.08 Acc@5=80.0\n",
            "Training 1770: Loss=1.86 Acc@1=50.42 Acc@5=82.08\n",
            "Training 1800: Loss=1.97 Acc@1=47.92 Acc@5=78.33\n",
            "Training 1830: Loss=1.84 Acc@1=49.17 Acc@5=79.58\n",
            "Training 1860: Loss=1.94 Acc@1=47.92 Acc@5=78.33\n",
            "Training 1890: Loss=1.87 Acc@1=49.17 Acc@5=77.08\n",
            "Training 1920: Loss=1.99 Acc@1=49.58 Acc@5=75.0\n",
            "Training 1950: Loss=1.98 Acc@1=48.75 Acc@5=76.67\n",
            "Training 1980: Loss=1.99 Acc@1=42.92 Acc@5=78.33\n",
            "Training 2010: Loss=1.74 Acc@1=52.5 Acc@5=85.0\n",
            "Training 2040: Loss=1.85 Acc@1=52.5 Acc@5=81.25\n",
            "Training 2070: Loss=1.77 Acc@1=58.75 Acc@5=81.67\n",
            "Training 2100: Loss=1.95 Acc@1=45.83 Acc@5=76.25\n",
            "Training 2130: Loss=1.93 Acc@1=48.33 Acc@5=77.5\n",
            "Training 2160: Loss=1.91 Acc@1=51.25 Acc@5=77.5\n",
            "Training 2190: Loss=1.83 Acc@1=47.08 Acc@5=81.25\n",
            "Training 2220: Loss=2.14 Acc@1=41.67 Acc@5=75.42\n",
            "Training 2250: Loss=1.84 Acc@1=49.17 Acc@5=84.17\n",
            "Training 2280: Loss=1.92 Acc@1=48.33 Acc@5=78.33\n",
            "Training 2310: Loss=2.04 Acc@1=43.75 Acc@5=77.08\n",
            "Training 2340: Loss=2.02 Acc@1=47.92 Acc@5=77.08\n",
            "Training 2370: Loss=1.94 Acc@1=46.67 Acc@5=77.92\n",
            "Training 2400: Loss=1.98 Acc@1=45.83 Acc@5=80.42\n",
            "Training 2430: Loss=1.77 Acc@1=51.25 Acc@5=80.42\n",
            "Training 2460: Loss=1.86 Acc@1=50.0 Acc@5=80.42\n",
            "Training 2490: Loss=2.04 Acc@1=45.83 Acc@5=78.33\n",
            "Training 2520: Loss=1.84 Acc@1=50.83 Acc@5=78.75\n",
            "Training 2550: Loss=1.92 Acc@1=47.5 Acc@5=79.58\n",
            "Training 2580: Loss=1.96 Acc@1=49.17 Acc@5=76.25\n",
            "Training 2610: Loss=1.8 Acc@1=53.75 Acc@5=82.92\n",
            "Training 2640: Loss=2.0 Acc@1=45.0 Acc@5=80.42\n",
            "Training 2670: Loss=1.94 Acc@1=47.5 Acc@5=75.83\n",
            "Training 2700: Loss=1.74 Acc@1=52.5 Acc@5=81.67\n",
            "Training 2730: Loss=1.9 Acc@1=48.75 Acc@5=77.5\n",
            "Training 2760: Loss=2.03 Acc@1=49.58 Acc@5=74.58\n",
            "Training 2790: Loss=2.07 Acc@1=45.0 Acc@5=74.17\n",
            "Training 2820: Loss=1.98 Acc@1=47.92 Acc@5=78.75\n",
            "Training 2850: Loss=1.95 Acc@1=46.67 Acc@5=80.83\n",
            "Training 2880: Loss=1.86 Acc@1=46.67 Acc@5=80.0\n",
            "Training 2910: Loss=1.88 Acc@1=48.75 Acc@5=77.92\n",
            "Training 2940: Loss=1.89 Acc@1=49.58 Acc@5=77.92\n",
            "Training 2970: Loss=2.25 Acc@1=39.58 Acc@5=70.42\n",
            "Training 3000: Loss=2.0 Acc@1=42.92 Acc@5=80.0\n",
            "Training 3030: Loss=1.96 Acc@1=45.0 Acc@5=75.42\n",
            "Training 3060: Loss=1.96 Acc@1=49.58 Acc@5=79.58\n",
            "Training 3090: Loss=1.88 Acc@1=50.0 Acc@5=78.33\n",
            "Training 3120: Loss=2.21 Acc@1=42.5 Acc@5=75.0\n",
            "Training 3150: Loss=1.9 Acc@1=50.42 Acc@5=77.08\n",
            "Training 3180: Loss=1.88 Acc@1=50.83 Acc@5=76.25\n",
            "Training 3210: Loss=1.95 Acc@1=45.42 Acc@5=77.5\n",
            "Training 3240: Loss=2.07 Acc@1=45.83 Acc@5=76.67\n",
            "Training 3270: Loss=1.69 Acc@1=53.75 Acc@5=83.75\n",
            "Training 3300: Loss=2.17 Acc@1=40.42 Acc@5=73.75\n",
            "Training 3330: Loss=1.91 Acc@1=46.67 Acc@5=77.92\n",
            "Training 3360: Loss=2.06 Acc@1=45.83 Acc@5=75.42\n",
            "Training 3390: Loss=1.88 Acc@1=48.75 Acc@5=82.08\n",
            "Training 3420: Loss=1.98 Acc@1=46.67 Acc@5=77.5\n",
            "Training 3450: Loss=1.85 Acc@1=46.25 Acc@5=80.0\n",
            "Training 3480: Loss=1.96 Acc@1=42.92 Acc@5=78.75\n",
            "Training 3510: Loss=2.15 Acc@1=44.58 Acc@5=76.25\n",
            "Training 3540: Loss=1.81 Acc@1=50.0 Acc@5=81.67\n",
            "Training 3570: Loss=1.7 Acc@1=54.17 Acc@5=82.92\n",
            "Training 3600: Loss=2.07 Acc@1=48.33 Acc@5=77.5\n",
            "Training 3630: Loss=1.84 Acc@1=47.5 Acc@5=81.25\n",
            "Training 3660: Loss=1.92 Acc@1=50.83 Acc@5=77.08\n",
            "Training 3690: Loss=1.85 Acc@1=47.08 Acc@5=82.08\n",
            "Training 3720: Loss=1.7 Acc@1=49.58 Acc@5=85.0\n",
            "Training 3750: Loss=2.05 Acc@1=45.0 Acc@5=76.67\n",
            "Training 3780: Loss=1.99 Acc@1=46.25 Acc@5=79.58\n",
            "Training 3810: Loss=1.93 Acc@1=48.33 Acc@5=77.08\n",
            "Training 3840: Loss=2.16 Acc@1=43.75 Acc@5=77.08\n",
            "Training 3870: Loss=1.84 Acc@1=47.5 Acc@5=77.5\n",
            "Training 3900: Loss=1.95 Acc@1=47.08 Acc@5=77.92\n",
            "Training 3930: Loss=1.78 Acc@1=50.0 Acc@5=83.75\n",
            "Training 3960: Loss=1.92 Acc@1=50.0 Acc@5=76.67\n",
            "Training 3990: Loss=2.03 Acc@1=46.67 Acc@5=75.42\n",
            "Training 4020: Loss=2.07 Acc@1=42.92 Acc@5=76.25\n",
            "Training 4050: Loss=1.84 Acc@1=49.58 Acc@5=78.75\n",
            "Training 4080: Loss=2.1 Acc@1=42.92 Acc@5=75.42\n",
            "Training 4110: Loss=2.21 Acc@1=49.58 Acc@5=72.92\n",
            "Training 4140: Loss=2.0 Acc@1=46.67 Acc@5=75.83\n",
            "Training 4170: Loss=2.02 Acc@1=46.67 Acc@5=76.25\n",
            "Training 4200: Loss=1.79 Acc@1=55.0 Acc@5=81.67\n",
            "Training 4230: Loss=1.97 Acc@1=45.42 Acc@5=79.58\n",
            "Training 4260: Loss=2.06 Acc@1=43.75 Acc@5=75.83\n",
            "Training 4290: Loss=1.9 Acc@1=49.17 Acc@5=77.08\n",
            "Training 4320: Loss=1.99 Acc@1=45.83 Acc@5=78.33\n",
            "Training 4350: Loss=2.02 Acc@1=42.92 Acc@5=77.08\n",
            "Training 4380: Loss=1.89 Acc@1=49.17 Acc@5=77.08\n",
            "Training 4410: Loss=2.01 Acc@1=45.0 Acc@5=77.92\n",
            "Training 4440: Loss=1.94 Acc@1=50.0 Acc@5=78.33\n",
            "Training 4470: Loss=1.87 Acc@1=50.0 Acc@5=77.5\n",
            "Training 4500: Loss=1.95 Acc@1=47.08 Acc@5=78.33\n",
            "Training 4530: Loss=1.94 Acc@1=47.92 Acc@5=75.0\n",
            "Training 4560: Loss=2.03 Acc@1=46.25 Acc@5=78.33\n",
            "Training 4590: Loss=1.96 Acc@1=48.33 Acc@5=76.67\n",
            "Training 4620: Loss=2.09 Acc@1=45.42 Acc@5=75.0\n",
            "Training 4650: Loss=2.09 Acc@1=39.17 Acc@5=75.42\n",
            "Training 4680: Loss=1.89 Acc@1=49.58 Acc@5=78.75\n",
            "Training 4710: Loss=1.95 Acc@1=47.92 Acc@5=79.17\n",
            "Training 4740: Loss=2.02 Acc@1=49.17 Acc@5=75.0\n",
            "Training 4770: Loss=1.82 Acc@1=48.75 Acc@5=81.25\n",
            "Training 4800: Loss=1.67 Acc@1=51.67 Acc@5=81.25\n",
            "Training 4830: Loss=2.05 Acc@1=43.33 Acc@5=74.58\n",
            "Training 4860: Loss=2.05 Acc@1=41.67 Acc@5=77.92\n",
            "Training 4890: Loss=2.3 Acc@1=40.0 Acc@5=72.5\n",
            "Training 4920: Loss=2.01 Acc@1=45.42 Acc@5=75.0\n",
            "Training 4950: Loss=1.92 Acc@1=50.83 Acc@5=78.75\n",
            "Training 4980: Loss=2.12 Acc@1=45.83 Acc@5=75.0\n",
            "Training 5010: Loss=2.11 Acc@1=45.42 Acc@5=75.83\n",
            "Training 5040: Loss=2.04 Acc@1=43.33 Acc@5=78.75\n",
            "Training 5070: Loss=1.93 Acc@1=50.42 Acc@5=77.5\n",
            "Training 5100: Loss=2.06 Acc@1=45.0 Acc@5=76.25\n",
            "Training 5130: Loss=2.04 Acc@1=45.83 Acc@5=75.42\n",
            "Training 5160: Loss=1.84 Acc@1=50.0 Acc@5=82.5\n",
            "Training 5190: Loss=1.92 Acc@1=50.0 Acc@5=79.58\n",
            "Training 5220: Loss=1.87 Acc@1=47.92 Acc@5=81.25\n",
            "Training 5250: Loss=1.86 Acc@1=51.25 Acc@5=79.58\n",
            "Training 5280: Loss=2.25 Acc@1=42.08 Acc@5=71.25\n",
            "Training 5310: Loss=2.16 Acc@1=43.33 Acc@5=72.5\n",
            "Training 5340: Loss=1.98 Acc@1=50.83 Acc@5=77.5\n",
            "Training 5370: Loss=2.2 Acc@1=40.42 Acc@5=70.83\n",
            "Training 5400: Loss=2.12 Acc@1=44.58 Acc@5=75.42\n",
            "Training 5430: Loss=2.0 Acc@1=45.42 Acc@5=79.58\n",
            "Training 5460: Loss=2.11 Acc@1=43.33 Acc@5=74.58\n",
            "Training 5490: Loss=1.82 Acc@1=48.33 Acc@5=81.67\n",
            "Training 5520: Loss=1.98 Acc@1=44.17 Acc@5=77.08\n",
            "Training 5550: Loss=1.94 Acc@1=47.92 Acc@5=79.17\n",
            "Training 5580: Loss=1.78 Acc@1=53.33 Acc@5=80.0\n",
            "Training 5610: Loss=2.09 Acc@1=44.17 Acc@5=73.33\n",
            "Training 5640: Loss=1.78 Acc@1=52.08 Acc@5=82.5\n",
            "Training 5670: Loss=2.17 Acc@1=46.67 Acc@5=73.33\n",
            "Training 5700: Loss=1.96 Acc@1=50.42 Acc@5=77.92\n",
            "Training 5730: Loss=2.11 Acc@1=44.58 Acc@5=74.58\n",
            "Training 5760: Loss=1.87 Acc@1=51.67 Acc@5=81.67\n",
            "Training 5790: Loss=2.27 Acc@1=40.42 Acc@5=73.75\n",
            "Training 5820: Loss=2.01 Acc@1=43.75 Acc@5=77.08\n",
            "Training 5850: Loss=2.2 Acc@1=43.33 Acc@5=75.42\n",
            "Training 5880: Loss=2.05 Acc@1=43.75 Acc@5=73.75\n",
            "Training 5910: Loss=1.94 Acc@1=47.92 Acc@5=80.0\n",
            "Training 5940: Loss=1.92 Acc@1=46.67 Acc@5=79.17\n",
            "Training 5970: Loss=2.14 Acc@1=44.58 Acc@5=75.42\n",
            "Training 6000: Loss=2.21 Acc@1=38.75 Acc@5=73.33\n",
            "Training 6030: Loss=2.09 Acc@1=47.5 Acc@5=75.42\n",
            "Training 6060: Loss=1.87 Acc@1=48.33 Acc@5=80.0\n",
            "Training 6090: Loss=2.07 Acc@1=41.25 Acc@5=76.67\n",
            "Training 6120: Loss=2.08 Acc@1=41.67 Acc@5=72.92\n",
            "Training 6150: Loss=1.96 Acc@1=45.0 Acc@5=77.5\n",
            "Training 6180: Loss=1.93 Acc@1=49.17 Acc@5=78.33\n",
            "Training 6210: Loss=1.96 Acc@1=48.33 Acc@5=79.58\n",
            "Training 6240: Loss=2.08 Acc@1=42.08 Acc@5=76.25\n",
            "Full imagenet train set: Acc@1=61.25 Acc@5=81.25\n",
            "Epoch: 12 ######################################################\n",
            "Training 30: Loss=1.84 Acc@1=49.17 Acc@5=81.25\n",
            "Training 60: Loss=1.83 Acc@1=51.67 Acc@5=80.83\n",
            "Training 90: Loss=1.94 Acc@1=43.75 Acc@5=78.33\n",
            "Training 120: Loss=1.82 Acc@1=53.33 Acc@5=79.17\n",
            "Training 150: Loss=1.82 Acc@1=55.83 Acc@5=78.75\n",
            "Training 180: Loss=1.74 Acc@1=54.58 Acc@5=82.08\n",
            "Training 210: Loss=1.97 Acc@1=46.67 Acc@5=75.83\n",
            "Training 240: Loss=1.67 Acc@1=55.42 Acc@5=81.67\n",
            "Training 270: Loss=1.73 Acc@1=51.25 Acc@5=84.58\n",
            "Training 300: Loss=2.07 Acc@1=43.33 Acc@5=76.67\n",
            "Training 330: Loss=1.77 Acc@1=53.75 Acc@5=80.83\n",
            "Training 360: Loss=1.65 Acc@1=58.75 Acc@5=82.92\n",
            "Training 390: Loss=1.87 Acc@1=48.75 Acc@5=79.17\n",
            "Training 420: Loss=1.98 Acc@1=44.58 Acc@5=77.5\n",
            "Training 450: Loss=1.73 Acc@1=55.0 Acc@5=83.33\n",
            "Training 480: Loss=1.86 Acc@1=47.92 Acc@5=80.83\n",
            "Training 510: Loss=2.03 Acc@1=47.08 Acc@5=75.42\n",
            "Training 540: Loss=1.73 Acc@1=54.17 Acc@5=80.83\n",
            "Training 570: Loss=1.59 Acc@1=55.42 Acc@5=85.0\n",
            "Training 600: Loss=1.89 Acc@1=49.58 Acc@5=76.25\n",
            "Training 630: Loss=1.93 Acc@1=49.58 Acc@5=77.08\n",
            "Training 660: Loss=1.74 Acc@1=52.08 Acc@5=82.08\n",
            "Training 690: Loss=1.64 Acc@1=52.5 Acc@5=80.42\n",
            "Training 720: Loss=1.91 Acc@1=47.08 Acc@5=78.75\n",
            "Training 750: Loss=2.05 Acc@1=46.67 Acc@5=75.42\n",
            "Training 780: Loss=1.97 Acc@1=48.33 Acc@5=78.75\n",
            "Training 810: Loss=1.72 Acc@1=53.33 Acc@5=80.83\n",
            "Training 840: Loss=1.86 Acc@1=48.75 Acc@5=78.75\n",
            "Training 870: Loss=1.91 Acc@1=51.67 Acc@5=82.08\n",
            "Training 900: Loss=1.92 Acc@1=46.25 Acc@5=79.17\n",
            "Training 930: Loss=1.9 Acc@1=48.75 Acc@5=77.92\n",
            "Training 960: Loss=1.76 Acc@1=49.17 Acc@5=82.92\n",
            "Training 990: Loss=1.88 Acc@1=51.67 Acc@5=77.92\n",
            "Training 1020: Loss=2.0 Acc@1=46.67 Acc@5=76.67\n",
            "Training 1050: Loss=2.0 Acc@1=44.17 Acc@5=75.42\n",
            "Training 1080: Loss=1.84 Acc@1=48.33 Acc@5=80.42\n",
            "Training 1110: Loss=1.92 Acc@1=49.58 Acc@5=78.75\n",
            "Training 1140: Loss=1.93 Acc@1=47.92 Acc@5=78.75\n",
            "Training 1170: Loss=1.75 Acc@1=52.92 Acc@5=80.83\n",
            "Training 1200: Loss=1.76 Acc@1=50.83 Acc@5=78.75\n",
            "Training 1230: Loss=1.79 Acc@1=47.5 Acc@5=80.83\n",
            "Training 1260: Loss=1.83 Acc@1=50.42 Acc@5=80.42\n",
            "Training 1290: Loss=2.06 Acc@1=43.75 Acc@5=77.5\n",
            "Training 1320: Loss=1.87 Acc@1=47.08 Acc@5=81.25\n",
            "Training 1350: Loss=1.87 Acc@1=52.5 Acc@5=80.42\n",
            "Training 1380: Loss=1.79 Acc@1=51.67 Acc@5=84.17\n",
            "Training 1410: Loss=1.76 Acc@1=52.5 Acc@5=81.25\n",
            "Training 1440: Loss=1.67 Acc@1=57.08 Acc@5=80.83\n",
            "Training 1470: Loss=1.81 Acc@1=52.08 Acc@5=77.5\n",
            "Training 1500: Loss=1.92 Acc@1=48.75 Acc@5=77.92\n",
            "Training 1530: Loss=1.88 Acc@1=52.92 Acc@5=79.17\n",
            "Training 1560: Loss=1.83 Acc@1=50.83 Acc@5=79.58\n",
            "Training 1590: Loss=2.0 Acc@1=42.92 Acc@5=77.5\n",
            "Training 1620: Loss=1.81 Acc@1=52.08 Acc@5=81.25\n",
            "Training 1650: Loss=1.76 Acc@1=54.17 Acc@5=77.92\n",
            "Training 1680: Loss=1.94 Acc@1=47.92 Acc@5=77.92\n",
            "Training 1710: Loss=1.79 Acc@1=51.25 Acc@5=81.67\n",
            "Training 1740: Loss=1.95 Acc@1=47.5 Acc@5=77.92\n",
            "Training 1770: Loss=1.91 Acc@1=43.75 Acc@5=80.83\n",
            "Training 1800: Loss=1.94 Acc@1=50.0 Acc@5=79.17\n",
            "Training 1830: Loss=1.84 Acc@1=50.42 Acc@5=82.92\n",
            "Training 1860: Loss=1.88 Acc@1=50.42 Acc@5=80.42\n",
            "Training 1890: Loss=1.71 Acc@1=51.25 Acc@5=81.67\n",
            "Training 1920: Loss=2.01 Acc@1=44.58 Acc@5=78.33\n",
            "Training 1950: Loss=1.69 Acc@1=53.33 Acc@5=82.92\n",
            "Training 1980: Loss=1.97 Acc@1=47.5 Acc@5=76.67\n",
            "Training 2010: Loss=1.73 Acc@1=51.67 Acc@5=85.83\n",
            "Training 2040: Loss=1.89 Acc@1=48.33 Acc@5=80.0\n",
            "Training 2070: Loss=1.8 Acc@1=50.83 Acc@5=82.08\n",
            "Training 2100: Loss=2.02 Acc@1=44.17 Acc@5=76.25\n",
            "Training 2130: Loss=1.85 Acc@1=51.25 Acc@5=78.75\n",
            "Training 2160: Loss=1.7 Acc@1=52.92 Acc@5=83.33\n",
            "Training 2190: Loss=1.88 Acc@1=46.67 Acc@5=82.92\n",
            "Training 2220: Loss=1.89 Acc@1=43.75 Acc@5=81.25\n",
            "Training 2250: Loss=1.74 Acc@1=50.83 Acc@5=83.75\n",
            "Training 2280: Loss=1.93 Acc@1=45.42 Acc@5=77.5\n",
            "Training 2310: Loss=1.65 Acc@1=49.58 Acc@5=84.17\n",
            "Training 2340: Loss=1.82 Acc@1=51.25 Acc@5=80.42\n",
            "Training 2370: Loss=1.87 Acc@1=50.42 Acc@5=75.83\n",
            "Training 2400: Loss=1.93 Acc@1=47.5 Acc@5=80.0\n",
            "Training 2430: Loss=1.8 Acc@1=50.0 Acc@5=80.83\n",
            "Training 2460: Loss=1.87 Acc@1=47.08 Acc@5=82.5\n",
            "Training 2490: Loss=1.95 Acc@1=50.83 Acc@5=76.67\n",
            "Training 2520: Loss=1.81 Acc@1=50.0 Acc@5=82.08\n",
            "Training 2550: Loss=1.77 Acc@1=52.5 Acc@5=81.67\n",
            "Training 2580: Loss=1.99 Acc@1=46.25 Acc@5=78.75\n",
            "Training 2610: Loss=1.7 Acc@1=51.67 Acc@5=85.42\n",
            "Training 2640: Loss=1.93 Acc@1=47.08 Acc@5=77.92\n",
            "Training 2670: Loss=1.93 Acc@1=46.67 Acc@5=78.75\n",
            "Training 2700: Loss=1.98 Acc@1=47.08 Acc@5=80.0\n",
            "Training 2730: Loss=2.16 Acc@1=42.92 Acc@5=75.83\n",
            "Training 2760: Loss=1.82 Acc@1=50.0 Acc@5=80.83\n",
            "Training 2790: Loss=1.97 Acc@1=47.5 Acc@5=76.67\n",
            "Training 2820: Loss=1.78 Acc@1=52.08 Acc@5=80.83\n",
            "Training 2850: Loss=1.82 Acc@1=52.5 Acc@5=78.33\n",
            "Training 2880: Loss=1.96 Acc@1=50.42 Acc@5=77.08\n",
            "Training 2910: Loss=1.8 Acc@1=51.25 Acc@5=77.08\n",
            "Training 2940: Loss=1.82 Acc@1=55.0 Acc@5=82.08\n",
            "Training 2970: Loss=1.75 Acc@1=53.75 Acc@5=83.33\n",
            "Training 3000: Loss=2.02 Acc@1=45.0 Acc@5=77.5\n",
            "Training 3030: Loss=2.01 Acc@1=45.42 Acc@5=78.75\n",
            "Training 3060: Loss=1.89 Acc@1=48.33 Acc@5=79.17\n",
            "Training 3090: Loss=1.99 Acc@1=49.17 Acc@5=77.5\n",
            "Training 3120: Loss=2.07 Acc@1=44.17 Acc@5=78.75\n",
            "Training 3150: Loss=1.96 Acc@1=47.5 Acc@5=76.67\n",
            "Training 3180: Loss=1.9 Acc@1=49.58 Acc@5=81.67\n",
            "Training 3210: Loss=1.84 Acc@1=51.25 Acc@5=80.83\n",
            "Training 3240: Loss=2.02 Acc@1=45.0 Acc@5=77.08\n",
            "Training 3270: Loss=1.92 Acc@1=49.17 Acc@5=77.92\n",
            "Training 3300: Loss=1.73 Acc@1=53.33 Acc@5=83.33\n",
            "Training 3330: Loss=1.89 Acc@1=50.0 Acc@5=81.25\n",
            "Training 3360: Loss=1.83 Acc@1=51.25 Acc@5=80.83\n",
            "Training 3390: Loss=1.79 Acc@1=50.42 Acc@5=80.42\n",
            "Training 3420: Loss=1.84 Acc@1=51.25 Acc@5=78.75\n",
            "Training 3450: Loss=1.95 Acc@1=47.92 Acc@5=76.25\n",
            "Training 3480: Loss=1.9 Acc@1=45.83 Acc@5=78.33\n",
            "Training 3510: Loss=1.87 Acc@1=51.25 Acc@5=78.33\n",
            "Training 3540: Loss=2.12 Acc@1=47.5 Acc@5=72.92\n",
            "Training 3570: Loss=1.89 Acc@1=52.92 Acc@5=76.67\n",
            "Training 3600: Loss=2.02 Acc@1=48.33 Acc@5=77.08\n",
            "Training 3630: Loss=2.15 Acc@1=46.67 Acc@5=75.83\n",
            "Training 3660: Loss=1.76 Acc@1=51.67 Acc@5=81.25\n",
            "Training 3690: Loss=1.96 Acc@1=52.5 Acc@5=77.08\n",
            "Training 3720: Loss=1.88 Acc@1=51.25 Acc@5=78.33\n",
            "Training 3750: Loss=1.83 Acc@1=51.67 Acc@5=78.33\n",
            "Training 3780: Loss=1.71 Acc@1=55.0 Acc@5=80.42\n",
            "Training 3810: Loss=1.94 Acc@1=44.58 Acc@5=79.17\n",
            "Training 3840: Loss=1.91 Acc@1=50.0 Acc@5=77.5\n",
            "Training 3870: Loss=2.08 Acc@1=45.0 Acc@5=75.0\n",
            "Training 3900: Loss=2.11 Acc@1=44.58 Acc@5=75.42\n",
            "Training 3930: Loss=1.82 Acc@1=48.33 Acc@5=80.0\n",
            "Training 3960: Loss=2.21 Acc@1=41.25 Acc@5=73.33\n",
            "Training 3990: Loss=1.99 Acc@1=45.42 Acc@5=79.17\n",
            "Training 4020: Loss=1.77 Acc@1=52.92 Acc@5=82.5\n",
            "Training 4050: Loss=1.77 Acc@1=50.0 Acc@5=77.92\n",
            "Training 4080: Loss=1.84 Acc@1=49.17 Acc@5=80.83\n",
            "Training 4110: Loss=2.11 Acc@1=44.58 Acc@5=76.67\n",
            "Training 4140: Loss=1.82 Acc@1=50.0 Acc@5=80.0\n",
            "Training 4170: Loss=2.05 Acc@1=45.83 Acc@5=77.08\n",
            "Training 4200: Loss=1.95 Acc@1=46.67 Acc@5=75.83\n",
            "Training 4230: Loss=1.97 Acc@1=48.75 Acc@5=77.92\n",
            "Training 4260: Loss=1.84 Acc@1=51.25 Acc@5=82.92\n",
            "Training 4290: Loss=1.83 Acc@1=50.42 Acc@5=80.83\n",
            "Training 4320: Loss=2.1 Acc@1=43.33 Acc@5=74.17\n",
            "Training 4350: Loss=1.76 Acc@1=51.25 Acc@5=78.75\n",
            "Training 4380: Loss=1.97 Acc@1=49.58 Acc@5=78.75\n",
            "Training 4410: Loss=1.9 Acc@1=50.42 Acc@5=79.58\n",
            "Training 4440: Loss=2.05 Acc@1=45.42 Acc@5=75.42\n",
            "Training 4470: Loss=1.9 Acc@1=45.83 Acc@5=77.92\n",
            "Training 4500: Loss=1.68 Acc@1=56.25 Acc@5=80.42\n",
            "Training 4530: Loss=1.85 Acc@1=50.0 Acc@5=80.42\n",
            "Training 4560: Loss=1.86 Acc@1=50.42 Acc@5=79.58\n",
            "Training 4590: Loss=1.99 Acc@1=47.92 Acc@5=76.25\n",
            "Training 4620: Loss=2.05 Acc@1=45.42 Acc@5=75.0\n",
            "Training 4650: Loss=2.03 Acc@1=47.08 Acc@5=75.42\n",
            "Training 4680: Loss=1.79 Acc@1=53.33 Acc@5=79.58\n",
            "Training 4710: Loss=1.67 Acc@1=53.75 Acc@5=84.58\n",
            "Training 4740: Loss=1.71 Acc@1=52.5 Acc@5=82.08\n",
            "Training 4770: Loss=1.98 Acc@1=47.08 Acc@5=77.5\n",
            "Training 4800: Loss=2.13 Acc@1=47.92 Acc@5=71.67\n",
            "Training 4830: Loss=1.84 Acc@1=45.0 Acc@5=85.42\n",
            "Training 4860: Loss=1.79 Acc@1=50.83 Acc@5=80.42\n",
            "Training 4890: Loss=1.77 Acc@1=53.75 Acc@5=80.0\n",
            "Training 4920: Loss=2.05 Acc@1=46.25 Acc@5=74.17\n",
            "Training 4950: Loss=1.93 Acc@1=47.92 Acc@5=81.25\n",
            "Training 4980: Loss=1.92 Acc@1=51.67 Acc@5=78.33\n",
            "Training 5010: Loss=1.91 Acc@1=47.5 Acc@5=79.17\n",
            "Training 5040: Loss=1.95 Acc@1=45.83 Acc@5=76.67\n",
            "Training 5070: Loss=2.01 Acc@1=46.67 Acc@5=74.58\n",
            "Training 5100: Loss=2.01 Acc@1=45.0 Acc@5=75.42\n",
            "Training 5130: Loss=1.89 Acc@1=50.42 Acc@5=78.33\n",
            "Training 5160: Loss=2.03 Acc@1=47.08 Acc@5=77.08\n",
            "Training 5190: Loss=1.89 Acc@1=48.33 Acc@5=79.17\n",
            "Training 5220: Loss=1.78 Acc@1=51.25 Acc@5=80.0\n",
            "Training 5250: Loss=1.92 Acc@1=48.33 Acc@5=82.08\n",
            "Training 5280: Loss=1.96 Acc@1=46.25 Acc@5=78.75\n",
            "Training 5310: Loss=1.82 Acc@1=50.42 Acc@5=80.0\n",
            "Training 5340: Loss=1.81 Acc@1=49.58 Acc@5=82.08\n",
            "Training 5370: Loss=1.86 Acc@1=46.25 Acc@5=81.67\n",
            "Training 5400: Loss=1.83 Acc@1=52.5 Acc@5=80.42\n",
            "Training 5430: Loss=1.96 Acc@1=44.17 Acc@5=79.17\n",
            "Training 5460: Loss=1.63 Acc@1=52.5 Acc@5=82.5\n",
            "Training 5490: Loss=1.91 Acc@1=49.17 Acc@5=77.5\n",
            "Training 5520: Loss=1.88 Acc@1=46.67 Acc@5=77.08\n",
            "Training 5550: Loss=2.06 Acc@1=45.0 Acc@5=76.67\n",
            "Training 5580: Loss=1.97 Acc@1=44.58 Acc@5=73.33\n",
            "Training 5610: Loss=2.18 Acc@1=44.58 Acc@5=72.92\n",
            "Training 5640: Loss=1.88 Acc@1=51.67 Acc@5=77.92\n",
            "Training 5670: Loss=1.89 Acc@1=50.42 Acc@5=79.17\n",
            "Training 5700: Loss=1.96 Acc@1=46.67 Acc@5=79.17\n",
            "Training 5730: Loss=1.85 Acc@1=45.83 Acc@5=78.75\n",
            "Training 5760: Loss=1.82 Acc@1=52.5 Acc@5=80.42\n",
            "Training 5790: Loss=2.05 Acc@1=47.92 Acc@5=76.67\n",
            "Training 5820: Loss=2.0 Acc@1=46.25 Acc@5=74.17\n",
            "Training 5850: Loss=2.0 Acc@1=49.58 Acc@5=77.08\n",
            "Training 5880: Loss=1.85 Acc@1=49.58 Acc@5=80.83\n",
            "Training 5910: Loss=1.84 Acc@1=49.17 Acc@5=81.25\n",
            "Training 5940: Loss=1.85 Acc@1=50.83 Acc@5=80.0\n",
            "Training 5970: Loss=2.0 Acc@1=47.08 Acc@5=76.25\n",
            "Training 6000: Loss=2.03 Acc@1=45.42 Acc@5=76.67\n",
            "Training 6030: Loss=2.08 Acc@1=43.75 Acc@5=75.83\n",
            "Training 6060: Loss=1.88 Acc@1=47.5 Acc@5=78.33\n",
            "Training 6090: Loss=1.96 Acc@1=49.58 Acc@5=77.08\n",
            "Training 6120: Loss=1.89 Acc@1=48.75 Acc@5=80.83\n",
            "Training 6150: Loss=2.06 Acc@1=42.92 Acc@5=75.0\n",
            "Training 6180: Loss=1.91 Acc@1=46.67 Acc@5=77.5\n",
            "Training 6210: Loss=2.0 Acc@1=45.83 Acc@5=76.25\n",
            "Training 6240: Loss=1.94 Acc@1=49.17 Acc@5=75.0\n",
            "Full imagenet train set: Acc@1=67.5 Acc@5=88.75\n",
            "Epoch: 13 ######################################################\n",
            "Training 30: Loss=1.72 Acc@1=55.42 Acc@5=81.67\n",
            "Training 60: Loss=1.99 Acc@1=47.92 Acc@5=78.33\n",
            "Training 90: Loss=1.66 Acc@1=55.83 Acc@5=85.42\n",
            "Training 120: Loss=1.7 Acc@1=55.83 Acc@5=82.08\n",
            "Training 150: Loss=1.67 Acc@1=49.17 Acc@5=86.67\n",
            "Training 180: Loss=1.72 Acc@1=53.75 Acc@5=80.42\n",
            "Training 210: Loss=1.73 Acc@1=49.17 Acc@5=84.58\n",
            "Training 240: Loss=1.86 Acc@1=50.42 Acc@5=80.42\n",
            "Training 270: Loss=1.93 Acc@1=47.5 Acc@5=78.75\n",
            "Training 300: Loss=1.69 Acc@1=56.67 Acc@5=82.5\n",
            "Training 330: Loss=1.66 Acc@1=52.92 Acc@5=84.17\n",
            "Training 360: Loss=1.93 Acc@1=48.33 Acc@5=79.58\n",
            "Training 390: Loss=1.68 Acc@1=53.33 Acc@5=81.67\n",
            "Training 420: Loss=1.64 Acc@1=55.42 Acc@5=86.67\n",
            "Training 450: Loss=1.68 Acc@1=56.25 Acc@5=83.75\n",
            "Training 480: Loss=1.74 Acc@1=54.58 Acc@5=80.83\n",
            "Training 510: Loss=1.72 Acc@1=53.75 Acc@5=82.92\n",
            "Training 540: Loss=1.81 Acc@1=47.08 Acc@5=79.58\n",
            "Training 570: Loss=1.97 Acc@1=48.75 Acc@5=80.0\n",
            "Training 600: Loss=1.73 Acc@1=49.58 Acc@5=82.5\n",
            "Training 630: Loss=1.66 Acc@1=55.83 Acc@5=83.33\n",
            "Training 660: Loss=1.7 Acc@1=50.83 Acc@5=82.92\n",
            "Training 690: Loss=1.66 Acc@1=50.83 Acc@5=84.17\n",
            "Training 720: Loss=1.6 Acc@1=55.0 Acc@5=83.33\n",
            "Training 750: Loss=1.71 Acc@1=52.08 Acc@5=82.5\n",
            "Training 780: Loss=1.87 Acc@1=53.75 Acc@5=79.17\n",
            "Training 810: Loss=1.84 Acc@1=52.5 Acc@5=80.42\n",
            "Training 840: Loss=1.65 Acc@1=50.83 Acc@5=82.92\n",
            "Training 870: Loss=1.67 Acc@1=54.58 Acc@5=85.42\n",
            "Training 900: Loss=1.76 Acc@1=50.0 Acc@5=82.5\n",
            "Training 930: Loss=1.75 Acc@1=51.67 Acc@5=82.08\n",
            "Training 960: Loss=1.77 Acc@1=53.33 Acc@5=84.17\n",
            "Training 990: Loss=1.75 Acc@1=53.33 Acc@5=80.42\n",
            "Training 1020: Loss=1.71 Acc@1=52.5 Acc@5=81.67\n",
            "Training 1050: Loss=1.95 Acc@1=49.58 Acc@5=78.33\n",
            "Training 1080: Loss=1.79 Acc@1=50.0 Acc@5=81.25\n",
            "Training 1110: Loss=1.83 Acc@1=48.75 Acc@5=79.58\n",
            "Training 1140: Loss=1.77 Acc@1=53.33 Acc@5=77.08\n",
            "Training 1170: Loss=1.68 Acc@1=54.17 Acc@5=82.5\n",
            "Training 1200: Loss=1.73 Acc@1=50.0 Acc@5=81.67\n",
            "Training 1230: Loss=1.65 Acc@1=57.92 Acc@5=83.75\n",
            "Training 1260: Loss=1.74 Acc@1=53.33 Acc@5=81.25\n",
            "Training 1290: Loss=1.83 Acc@1=49.58 Acc@5=80.83\n",
            "Training 1320: Loss=1.65 Acc@1=56.67 Acc@5=79.17\n",
            "Training 1350: Loss=1.81 Acc@1=49.58 Acc@5=80.0\n",
            "Training 1380: Loss=1.72 Acc@1=50.0 Acc@5=84.58\n",
            "Training 1410: Loss=1.71 Acc@1=51.67 Acc@5=86.67\n",
            "Training 1440: Loss=2.04 Acc@1=44.17 Acc@5=76.67\n",
            "Training 1470: Loss=1.79 Acc@1=52.08 Acc@5=81.67\n",
            "Training 1500: Loss=1.78 Acc@1=54.58 Acc@5=77.92\n",
            "Training 1530: Loss=1.8 Acc@1=51.25 Acc@5=80.83\n",
            "Training 1560: Loss=1.75 Acc@1=49.58 Acc@5=80.0\n",
            "Training 1590: Loss=1.76 Acc@1=50.42 Acc@5=81.67\n",
            "Training 1620: Loss=1.94 Acc@1=50.42 Acc@5=77.08\n",
            "Training 1650: Loss=1.8 Acc@1=55.0 Acc@5=78.33\n",
            "Training 1680: Loss=1.85 Acc@1=52.92 Acc@5=78.75\n",
            "Training 1710: Loss=1.65 Acc@1=52.08 Acc@5=85.42\n",
            "Training 1740: Loss=1.98 Acc@1=44.17 Acc@5=75.0\n",
            "Training 1770: Loss=1.78 Acc@1=51.25 Acc@5=80.83\n",
            "Training 1800: Loss=1.76 Acc@1=48.75 Acc@5=81.67\n",
            "Training 1830: Loss=1.92 Acc@1=48.75 Acc@5=77.08\n",
            "Training 1860: Loss=1.79 Acc@1=55.0 Acc@5=80.42\n",
            "Training 1890: Loss=1.83 Acc@1=50.0 Acc@5=81.67\n",
            "Training 1920: Loss=1.76 Acc@1=50.0 Acc@5=82.08\n",
            "Training 1950: Loss=1.72 Acc@1=50.0 Acc@5=83.75\n",
            "Training 1980: Loss=1.77 Acc@1=56.25 Acc@5=82.5\n",
            "Training 2010: Loss=1.66 Acc@1=52.92 Acc@5=85.0\n",
            "Training 2040: Loss=1.81 Acc@1=48.33 Acc@5=82.08\n",
            "Training 2070: Loss=1.74 Acc@1=48.75 Acc@5=85.0\n",
            "Training 2100: Loss=1.89 Acc@1=50.42 Acc@5=77.5\n",
            "Training 2130: Loss=1.94 Acc@1=50.83 Acc@5=76.67\n",
            "Training 2160: Loss=1.84 Acc@1=47.08 Acc@5=80.0\n",
            "Training 2190: Loss=1.79 Acc@1=51.25 Acc@5=80.42\n",
            "Training 2220: Loss=1.58 Acc@1=56.67 Acc@5=85.83\n",
            "Training 2250: Loss=1.88 Acc@1=47.08 Acc@5=80.42\n",
            "Training 2280: Loss=1.76 Acc@1=50.0 Acc@5=80.42\n",
            "Training 2310: Loss=2.01 Acc@1=45.0 Acc@5=77.5\n",
            "Training 2340: Loss=1.85 Acc@1=50.0 Acc@5=78.75\n",
            "Training 2370: Loss=1.83 Acc@1=52.5 Acc@5=82.5\n",
            "Training 2400: Loss=1.76 Acc@1=55.83 Acc@5=81.67\n",
            "Training 2430: Loss=1.83 Acc@1=49.58 Acc@5=81.25\n",
            "Training 2460: Loss=1.79 Acc@1=49.58 Acc@5=79.17\n",
            "Training 2490: Loss=1.85 Acc@1=51.25 Acc@5=82.5\n",
            "Training 2520: Loss=1.86 Acc@1=51.67 Acc@5=77.5\n",
            "Training 2550: Loss=1.86 Acc@1=51.25 Acc@5=79.17\n",
            "Training 2580: Loss=1.98 Acc@1=48.33 Acc@5=74.58\n",
            "Training 2610: Loss=1.79 Acc@1=50.0 Acc@5=82.5\n",
            "Training 2640: Loss=1.8 Acc@1=47.5 Acc@5=80.42\n",
            "Training 2670: Loss=1.91 Acc@1=49.58 Acc@5=78.75\n",
            "Training 2700: Loss=1.67 Acc@1=55.0 Acc@5=82.08\n",
            "Training 2730: Loss=1.7 Acc@1=51.67 Acc@5=81.67\n",
            "Training 2760: Loss=1.68 Acc@1=53.75 Acc@5=80.83\n",
            "Training 2790: Loss=1.76 Acc@1=49.17 Acc@5=83.75\n",
            "Training 2820: Loss=1.61 Acc@1=53.33 Acc@5=87.5\n",
            "Training 2850: Loss=1.78 Acc@1=52.5 Acc@5=80.83\n",
            "Training 2880: Loss=1.8 Acc@1=48.75 Acc@5=83.33\n",
            "Training 2910: Loss=1.96 Acc@1=49.58 Acc@5=72.5\n",
            "Training 2940: Loss=1.78 Acc@1=51.25 Acc@5=82.92\n",
            "Training 2970: Loss=1.99 Acc@1=47.92 Acc@5=79.17\n",
            "Training 3000: Loss=1.9 Acc@1=50.42 Acc@5=81.67\n",
            "Training 3030: Loss=1.8 Acc@1=49.58 Acc@5=85.0\n",
            "Training 3060: Loss=1.89 Acc@1=47.92 Acc@5=81.25\n",
            "Training 3090: Loss=1.69 Acc@1=51.67 Acc@5=82.08\n",
            "Training 3120: Loss=1.69 Acc@1=53.33 Acc@5=82.08\n",
            "Training 3150: Loss=1.73 Acc@1=56.25 Acc@5=80.0\n",
            "Training 3180: Loss=1.7 Acc@1=52.08 Acc@5=83.75\n",
            "Training 3210: Loss=1.54 Acc@1=55.83 Acc@5=83.75\n",
            "Training 3240: Loss=1.87 Acc@1=47.92 Acc@5=80.0\n",
            "Training 3270: Loss=1.89 Acc@1=49.17 Acc@5=78.75\n",
            "Training 3300: Loss=1.87 Acc@1=51.25 Acc@5=78.75\n",
            "Training 3330: Loss=1.85 Acc@1=51.25 Acc@5=82.08\n",
            "Training 3360: Loss=1.74 Acc@1=52.92 Acc@5=82.5\n",
            "Training 3390: Loss=2.01 Acc@1=44.58 Acc@5=75.42\n",
            "Training 3420: Loss=1.72 Acc@1=54.17 Acc@5=79.17\n",
            "Training 3450: Loss=2.02 Acc@1=47.5 Acc@5=77.92\n",
            "Training 3480: Loss=1.83 Acc@1=49.17 Acc@5=81.25\n",
            "Training 3510: Loss=1.78 Acc@1=49.17 Acc@5=81.25\n",
            "Training 3540: Loss=1.78 Acc@1=46.25 Acc@5=81.67\n",
            "Training 3570: Loss=1.82 Acc@1=49.58 Acc@5=81.25\n",
            "Training 3600: Loss=1.74 Acc@1=52.08 Acc@5=80.83\n",
            "Training 3630: Loss=1.72 Acc@1=48.33 Acc@5=81.67\n",
            "Training 3660: Loss=1.89 Acc@1=48.75 Acc@5=79.58\n",
            "Training 3690: Loss=1.83 Acc@1=51.25 Acc@5=80.83\n",
            "Training 3720: Loss=1.71 Acc@1=52.08 Acc@5=84.58\n",
            "Training 3750: Loss=1.5 Acc@1=57.92 Acc@5=88.33\n",
            "Training 3780: Loss=1.72 Acc@1=56.67 Acc@5=80.0\n",
            "Training 3810: Loss=1.91 Acc@1=50.42 Acc@5=77.08\n",
            "Training 3840: Loss=1.97 Acc@1=45.42 Acc@5=78.75\n",
            "Training 3870: Loss=1.75 Acc@1=50.83 Acc@5=83.75\n",
            "Training 3900: Loss=1.76 Acc@1=47.5 Acc@5=82.92\n",
            "Training 3930: Loss=1.98 Acc@1=45.42 Acc@5=80.0\n",
            "Training 3960: Loss=1.86 Acc@1=49.58 Acc@5=78.33\n",
            "Training 3990: Loss=1.66 Acc@1=51.25 Acc@5=81.25\n",
            "Training 4020: Loss=1.79 Acc@1=52.08 Acc@5=82.92\n",
            "Training 4050: Loss=1.97 Acc@1=51.67 Acc@5=75.0\n",
            "Training 4080: Loss=2.02 Acc@1=48.33 Acc@5=75.83\n",
            "Training 4110: Loss=1.92 Acc@1=51.67 Acc@5=76.67\n",
            "Training 4140: Loss=1.59 Acc@1=55.0 Acc@5=84.58\n",
            "Training 4170: Loss=1.92 Acc@1=50.42 Acc@5=77.5\n",
            "Training 4200: Loss=1.63 Acc@1=53.75 Acc@5=82.5\n",
            "Training 4230: Loss=1.94 Acc@1=45.42 Acc@5=77.92\n",
            "Training 4260: Loss=1.67 Acc@1=57.08 Acc@5=84.58\n",
            "Training 4290: Loss=1.96 Acc@1=50.83 Acc@5=74.17\n",
            "Training 4320: Loss=1.7 Acc@1=53.33 Acc@5=82.5\n",
            "Training 4350: Loss=1.81 Acc@1=53.33 Acc@5=80.83\n",
            "Training 4380: Loss=2.0 Acc@1=46.25 Acc@5=75.83\n",
            "Training 4410: Loss=1.91 Acc@1=47.08 Acc@5=80.0\n",
            "Training 4440: Loss=2.02 Acc@1=50.0 Acc@5=80.0\n",
            "Training 4470: Loss=2.05 Acc@1=45.42 Acc@5=76.67\n",
            "Training 4500: Loss=1.92 Acc@1=47.08 Acc@5=77.08\n",
            "Training 4530: Loss=1.85 Acc@1=50.42 Acc@5=80.83\n",
            "Training 4560: Loss=1.79 Acc@1=49.58 Acc@5=80.42\n",
            "Training 4590: Loss=1.91 Acc@1=49.17 Acc@5=76.67\n",
            "Training 4620: Loss=1.88 Acc@1=48.33 Acc@5=80.0\n",
            "Training 4650: Loss=2.07 Acc@1=47.92 Acc@5=75.42\n",
            "Training 4680: Loss=1.75 Acc@1=52.08 Acc@5=80.42\n",
            "Training 4710: Loss=1.91 Acc@1=45.83 Acc@5=78.33\n",
            "Training 4740: Loss=1.64 Acc@1=49.58 Acc@5=87.08\n",
            "Training 4770: Loss=1.84 Acc@1=49.58 Acc@5=80.42\n",
            "Training 4800: Loss=1.66 Acc@1=53.75 Acc@5=82.08\n",
            "Training 4830: Loss=1.94 Acc@1=45.42 Acc@5=79.58\n",
            "Training 4860: Loss=2.09 Acc@1=45.0 Acc@5=75.0\n",
            "Training 4890: Loss=1.71 Acc@1=55.0 Acc@5=83.75\n",
            "Training 4920: Loss=1.93 Acc@1=49.58 Acc@5=78.75\n",
            "Training 4950: Loss=1.81 Acc@1=55.83 Acc@5=79.58\n",
            "Training 4980: Loss=1.9 Acc@1=50.83 Acc@5=77.92\n",
            "Training 5010: Loss=1.81 Acc@1=51.25 Acc@5=80.42\n",
            "Training 5040: Loss=1.93 Acc@1=50.0 Acc@5=77.92\n",
            "Training 5070: Loss=1.88 Acc@1=48.75 Acc@5=80.0\n",
            "Training 5100: Loss=1.87 Acc@1=47.92 Acc@5=82.08\n",
            "Training 5130: Loss=1.86 Acc@1=50.0 Acc@5=80.0\n",
            "Training 5160: Loss=1.84 Acc@1=50.42 Acc@5=80.0\n",
            "Training 5190: Loss=1.83 Acc@1=51.25 Acc@5=79.58\n",
            "Training 5220: Loss=1.84 Acc@1=48.75 Acc@5=80.0\n",
            "Training 5250: Loss=1.69 Acc@1=52.92 Acc@5=78.75\n",
            "Training 5280: Loss=1.91 Acc@1=47.92 Acc@5=77.5\n",
            "Training 5310: Loss=1.81 Acc@1=52.92 Acc@5=79.17\n",
            "Training 5340: Loss=1.64 Acc@1=55.0 Acc@5=85.42\n",
            "Training 5370: Loss=1.85 Acc@1=49.17 Acc@5=80.42\n",
            "Training 5400: Loss=1.7 Acc@1=55.42 Acc@5=82.5\n",
            "Training 5430: Loss=1.99 Acc@1=50.83 Acc@5=77.5\n",
            "Training 5460: Loss=1.98 Acc@1=52.08 Acc@5=75.42\n",
            "Training 5490: Loss=1.85 Acc@1=50.42 Acc@5=81.67\n",
            "Training 5520: Loss=2.05 Acc@1=47.5 Acc@5=74.58\n",
            "Training 5550: Loss=1.79 Acc@1=46.25 Acc@5=82.08\n",
            "Training 5580: Loss=2.0 Acc@1=46.67 Acc@5=74.17\n",
            "Training 5610: Loss=2.03 Acc@1=42.5 Acc@5=77.08\n",
            "Training 5640: Loss=1.99 Acc@1=48.75 Acc@5=76.67\n",
            "Training 5670: Loss=1.85 Acc@1=49.17 Acc@5=76.67\n",
            "Training 5700: Loss=1.76 Acc@1=45.83 Acc@5=81.25\n",
            "Training 5730: Loss=1.75 Acc@1=50.42 Acc@5=83.75\n",
            "Training 5760: Loss=1.76 Acc@1=50.83 Acc@5=81.67\n",
            "Training 5790: Loss=1.93 Acc@1=53.75 Acc@5=80.0\n",
            "Training 5820: Loss=1.89 Acc@1=50.83 Acc@5=78.33\n",
            "Training 5850: Loss=2.08 Acc@1=46.67 Acc@5=74.17\n",
            "Training 5880: Loss=1.89 Acc@1=50.42 Acc@5=78.33\n",
            "Training 5910: Loss=1.81 Acc@1=49.17 Acc@5=81.67\n",
            "Training 5940: Loss=1.93 Acc@1=45.83 Acc@5=76.67\n",
            "Training 5970: Loss=1.95 Acc@1=49.58 Acc@5=76.67\n",
            "Training 6000: Loss=2.04 Acc@1=47.5 Acc@5=75.42\n",
            "Training 6030: Loss=2.05 Acc@1=46.67 Acc@5=75.42\n",
            "Training 6060: Loss=1.86 Acc@1=49.58 Acc@5=81.67\n",
            "Training 6090: Loss=1.97 Acc@1=42.92 Acc@5=77.08\n",
            "Training 6120: Loss=1.77 Acc@1=54.17 Acc@5=80.42\n",
            "Training 6150: Loss=1.8 Acc@1=49.58 Acc@5=81.67\n",
            "Training 6180: Loss=2.07 Acc@1=45.83 Acc@5=73.33\n",
            "Training 6210: Loss=1.69 Acc@1=55.42 Acc@5=81.67\n",
            "Training 6240: Loss=1.92 Acc@1=45.83 Acc@5=77.5\n",
            "Full imagenet train set: Acc@1=55.0 Acc@5=85.0\n",
            "Epoch: 14 ######################################################\n",
            "Training 30: Loss=1.56 Acc@1=57.08 Acc@5=85.83\n",
            "Training 60: Loss=1.89 Acc@1=50.83 Acc@5=79.58\n",
            "Training 90: Loss=1.64 Acc@1=57.08 Acc@5=83.33\n",
            "Training 120: Loss=1.57 Acc@1=56.25 Acc@5=82.5\n",
            "Training 150: Loss=1.54 Acc@1=59.17 Acc@5=84.17\n",
            "Training 180: Loss=1.62 Acc@1=55.83 Acc@5=80.0\n",
            "Training 210: Loss=1.71 Acc@1=56.67 Acc@5=83.33\n",
            "Training 240: Loss=1.57 Acc@1=61.25 Acc@5=83.75\n",
            "Training 270: Loss=1.84 Acc@1=50.83 Acc@5=79.17\n",
            "Training 300: Loss=1.79 Acc@1=51.25 Acc@5=80.0\n",
            "Training 330: Loss=1.71 Acc@1=55.0 Acc@5=83.33\n",
            "Training 360: Loss=1.71 Acc@1=50.83 Acc@5=81.25\n",
            "Training 390: Loss=1.73 Acc@1=51.25 Acc@5=83.33\n",
            "Training 420: Loss=1.71 Acc@1=50.42 Acc@5=83.33\n",
            "Training 450: Loss=1.9 Acc@1=49.17 Acc@5=79.58\n",
            "Training 480: Loss=1.71 Acc@1=52.92 Acc@5=83.33\n",
            "Training 510: Loss=1.66 Acc@1=54.58 Acc@5=83.75\n",
            "Training 540: Loss=1.85 Acc@1=53.75 Acc@5=80.83\n",
            "Training 570: Loss=1.53 Acc@1=59.17 Acc@5=82.5\n",
            "Training 600: Loss=1.58 Acc@1=55.83 Acc@5=85.0\n",
            "Training 630: Loss=1.84 Acc@1=50.42 Acc@5=78.33\n",
            "Training 660: Loss=1.68 Acc@1=55.0 Acc@5=84.58\n",
            "Training 690: Loss=1.68 Acc@1=57.5 Acc@5=81.25\n",
            "Training 720: Loss=1.44 Acc@1=60.83 Acc@5=89.17\n",
            "Training 750: Loss=1.72 Acc@1=50.42 Acc@5=82.08\n",
            "Training 780: Loss=1.8 Acc@1=53.75 Acc@5=80.83\n",
            "Training 810: Loss=1.82 Acc@1=47.5 Acc@5=80.42\n",
            "Training 840: Loss=1.62 Acc@1=57.5 Acc@5=83.75\n",
            "Training 870: Loss=1.73 Acc@1=50.42 Acc@5=84.58\n",
            "Training 900: Loss=1.73 Acc@1=54.17 Acc@5=80.83\n",
            "Training 930: Loss=1.67 Acc@1=56.67 Acc@5=82.5\n",
            "Training 960: Loss=1.73 Acc@1=55.0 Acc@5=81.25\n",
            "Training 990: Loss=1.81 Acc@1=55.42 Acc@5=80.42\n",
            "Training 1020: Loss=1.92 Acc@1=48.75 Acc@5=77.92\n",
            "Training 1050: Loss=1.56 Acc@1=56.25 Acc@5=83.75\n",
            "Training 1080: Loss=1.98 Acc@1=48.75 Acc@5=78.33\n",
            "Training 1110: Loss=1.74 Acc@1=53.33 Acc@5=81.25\n",
            "Training 1140: Loss=1.55 Acc@1=58.33 Acc@5=85.0\n",
            "Training 1170: Loss=1.53 Acc@1=60.83 Acc@5=85.0\n",
            "Training 1200: Loss=1.77 Acc@1=50.83 Acc@5=80.83\n",
            "Training 1230: Loss=1.55 Acc@1=57.5 Acc@5=85.0\n",
            "Training 1260: Loss=1.71 Acc@1=54.17 Acc@5=81.25\n",
            "Training 1290: Loss=1.96 Acc@1=49.17 Acc@5=80.42\n",
            "Training 1320: Loss=1.84 Acc@1=46.25 Acc@5=81.67\n",
            "Training 1350: Loss=1.66 Acc@1=55.83 Acc@5=85.42\n",
            "Training 1380: Loss=1.69 Acc@1=51.67 Acc@5=81.25\n",
            "Training 1410: Loss=1.51 Acc@1=55.0 Acc@5=85.42\n",
            "Training 1440: Loss=1.82 Acc@1=47.92 Acc@5=79.17\n",
            "Training 1470: Loss=1.84 Acc@1=50.0 Acc@5=79.17\n",
            "Training 1500: Loss=1.71 Acc@1=52.5 Acc@5=83.33\n",
            "Training 1530: Loss=1.73 Acc@1=49.58 Acc@5=80.0\n",
            "Training 1560: Loss=1.69 Acc@1=53.75 Acc@5=82.08\n",
            "Training 1590: Loss=1.79 Acc@1=48.75 Acc@5=82.92\n",
            "Training 1620: Loss=1.42 Acc@1=59.58 Acc@5=87.5\n",
            "Training 1650: Loss=1.69 Acc@1=55.42 Acc@5=83.75\n",
            "Training 1680: Loss=1.7 Acc@1=50.83 Acc@5=82.5\n",
            "Training 1710: Loss=1.87 Acc@1=47.92 Acc@5=79.17\n",
            "Training 1740: Loss=1.56 Acc@1=58.75 Acc@5=84.58\n",
            "Training 1770: Loss=1.67 Acc@1=53.75 Acc@5=83.33\n",
            "Training 1800: Loss=1.7 Acc@1=50.0 Acc@5=82.92\n",
            "Training 1830: Loss=1.63 Acc@1=58.33 Acc@5=82.92\n",
            "Training 1860: Loss=1.7 Acc@1=56.67 Acc@5=82.08\n",
            "Training 1890: Loss=1.84 Acc@1=54.58 Acc@5=80.0\n",
            "Training 1920: Loss=1.88 Acc@1=49.58 Acc@5=79.17\n",
            "Training 1950: Loss=1.82 Acc@1=53.33 Acc@5=76.25\n",
            "Training 1980: Loss=1.72 Acc@1=53.75 Acc@5=83.75\n",
            "Training 2010: Loss=1.75 Acc@1=52.5 Acc@5=80.0\n",
            "Training 2040: Loss=1.64 Acc@1=55.83 Acc@5=82.5\n",
            "Training 2070: Loss=1.91 Acc@1=47.92 Acc@5=78.33\n",
            "Training 2100: Loss=1.8 Acc@1=50.42 Acc@5=81.25\n",
            "Training 2130: Loss=1.85 Acc@1=50.0 Acc@5=78.33\n",
            "Training 2160: Loss=1.53 Acc@1=57.08 Acc@5=83.75\n",
            "Training 2190: Loss=1.74 Acc@1=51.25 Acc@5=81.25\n",
            "Training 2220: Loss=1.83 Acc@1=52.5 Acc@5=78.75\n",
            "Training 2250: Loss=1.75 Acc@1=51.25 Acc@5=80.0\n",
            "Training 2280: Loss=1.76 Acc@1=53.33 Acc@5=82.5\n",
            "Training 2310: Loss=1.74 Acc@1=54.17 Acc@5=83.75\n",
            "Training 2340: Loss=1.83 Acc@1=54.17 Acc@5=77.5\n",
            "Training 2370: Loss=1.75 Acc@1=52.08 Acc@5=80.0\n",
            "Training 2400: Loss=1.68 Acc@1=53.33 Acc@5=84.58\n",
            "Training 2430: Loss=1.82 Acc@1=52.08 Acc@5=81.67\n",
            "Training 2460: Loss=1.72 Acc@1=54.58 Acc@5=82.5\n",
            "Training 2490: Loss=1.9 Acc@1=49.17 Acc@5=80.0\n",
            "Training 2520: Loss=1.58 Acc@1=58.75 Acc@5=83.75\n",
            "Training 2550: Loss=1.72 Acc@1=53.33 Acc@5=81.67\n",
            "Training 2580: Loss=1.82 Acc@1=48.33 Acc@5=80.42\n",
            "Training 2610: Loss=2.0 Acc@1=49.17 Acc@5=77.92\n",
            "Training 2640: Loss=1.73 Acc@1=52.08 Acc@5=82.5\n",
            "Training 2670: Loss=1.69 Acc@1=56.25 Acc@5=82.08\n",
            "Training 2700: Loss=1.94 Acc@1=50.0 Acc@5=78.75\n",
            "Training 2730: Loss=1.75 Acc@1=54.58 Acc@5=80.0\n",
            "Training 2760: Loss=1.67 Acc@1=55.83 Acc@5=81.67\n",
            "Training 2790: Loss=1.76 Acc@1=51.25 Acc@5=82.5\n",
            "Training 2820: Loss=1.93 Acc@1=52.08 Acc@5=78.33\n",
            "Training 2850: Loss=1.79 Acc@1=52.08 Acc@5=79.17\n",
            "Training 2880: Loss=1.65 Acc@1=52.5 Acc@5=82.92\n",
            "Training 2910: Loss=1.88 Acc@1=50.0 Acc@5=77.5\n",
            "Training 2940: Loss=1.87 Acc@1=49.58 Acc@5=79.17\n",
            "Training 2970: Loss=1.79 Acc@1=52.92 Acc@5=79.17\n",
            "Training 3000: Loss=1.65 Acc@1=54.58 Acc@5=85.0\n",
            "Training 3030: Loss=1.9 Acc@1=46.25 Acc@5=80.0\n",
            "Training 3060: Loss=1.82 Acc@1=50.0 Acc@5=80.83\n",
            "Training 3090: Loss=1.72 Acc@1=51.67 Acc@5=82.08\n",
            "Training 3120: Loss=1.83 Acc@1=51.67 Acc@5=79.58\n",
            "Training 3150: Loss=1.74 Acc@1=50.83 Acc@5=84.17\n",
            "Training 3180: Loss=1.7 Acc@1=52.08 Acc@5=82.5\n",
            "Training 3210: Loss=1.84 Acc@1=52.92 Acc@5=78.75\n",
            "Training 3240: Loss=1.79 Acc@1=48.75 Acc@5=80.42\n",
            "Training 3270: Loss=1.77 Acc@1=50.83 Acc@5=81.25\n",
            "Training 3300: Loss=1.74 Acc@1=55.83 Acc@5=80.42\n",
            "Training 3330: Loss=1.65 Acc@1=51.67 Acc@5=87.08\n",
            "Training 3360: Loss=1.8 Acc@1=48.75 Acc@5=80.0\n",
            "Training 3390: Loss=1.83 Acc@1=53.75 Acc@5=79.17\n",
            "Training 3420: Loss=1.7 Acc@1=50.0 Acc@5=85.42\n",
            "Training 3450: Loss=1.59 Acc@1=55.0 Acc@5=83.33\n",
            "Training 3480: Loss=1.82 Acc@1=49.17 Acc@5=81.67\n",
            "Training 3510: Loss=1.86 Acc@1=50.0 Acc@5=76.67\n",
            "Training 3540: Loss=1.61 Acc@1=52.92 Acc@5=85.83\n",
            "Training 3570: Loss=1.81 Acc@1=49.17 Acc@5=79.17\n",
            "Training 3600: Loss=2.01 Acc@1=46.67 Acc@5=76.25\n",
            "Training 3630: Loss=1.64 Acc@1=57.08 Acc@5=85.42\n",
            "Training 3660: Loss=1.7 Acc@1=55.0 Acc@5=81.25\n",
            "Training 3690: Loss=1.64 Acc@1=52.92 Acc@5=80.83\n",
            "Training 3720: Loss=1.7 Acc@1=54.58 Acc@5=81.25\n",
            "Training 3750: Loss=1.82 Acc@1=51.25 Acc@5=78.33\n",
            "Training 3780: Loss=1.89 Acc@1=50.42 Acc@5=76.25\n",
            "Training 3810: Loss=1.76 Acc@1=54.58 Acc@5=80.83\n",
            "Training 3840: Loss=1.8 Acc@1=52.92 Acc@5=83.33\n",
            "Training 3870: Loss=1.82 Acc@1=51.67 Acc@5=80.83\n",
            "Training 3900: Loss=1.57 Acc@1=57.5 Acc@5=84.58\n",
            "Training 3930: Loss=1.81 Acc@1=51.25 Acc@5=79.58\n",
            "Training 3960: Loss=1.7 Acc@1=52.92 Acc@5=82.5\n",
            "Training 3990: Loss=1.66 Acc@1=51.67 Acc@5=82.5\n",
            "Training 4020: Loss=1.68 Acc@1=52.92 Acc@5=82.92\n",
            "Training 4050: Loss=1.52 Acc@1=55.83 Acc@5=86.25\n",
            "Training 4080: Loss=1.81 Acc@1=53.33 Acc@5=81.25\n",
            "Training 4110: Loss=1.68 Acc@1=52.5 Acc@5=81.67\n",
            "Training 4140: Loss=1.72 Acc@1=55.42 Acc@5=83.33\n",
            "Training 4170: Loss=1.93 Acc@1=51.25 Acc@5=80.0\n",
            "Training 4200: Loss=1.7 Acc@1=54.58 Acc@5=80.42\n",
            "Training 4230: Loss=1.79 Acc@1=48.75 Acc@5=79.58\n",
            "Training 4260: Loss=1.9 Acc@1=52.08 Acc@5=78.33\n",
            "Training 4290: Loss=1.57 Acc@1=57.92 Acc@5=85.0\n",
            "Training 4320: Loss=1.73 Acc@1=46.67 Acc@5=84.17\n",
            "Training 4350: Loss=1.68 Acc@1=55.42 Acc@5=81.25\n",
            "Training 4380: Loss=1.83 Acc@1=55.83 Acc@5=80.42\n",
            "Training 4410: Loss=1.71 Acc@1=50.83 Acc@5=82.5\n",
            "Training 4440: Loss=1.85 Acc@1=50.42 Acc@5=81.67\n",
            "Training 4470: Loss=1.92 Acc@1=46.67 Acc@5=80.0\n",
            "Training 4500: Loss=1.85 Acc@1=50.42 Acc@5=79.58\n",
            "Training 4530: Loss=1.74 Acc@1=51.25 Acc@5=80.0\n",
            "Training 4560: Loss=1.71 Acc@1=52.08 Acc@5=82.5\n",
            "Training 4590: Loss=1.97 Acc@1=47.92 Acc@5=77.5\n",
            "Training 4620: Loss=1.71 Acc@1=54.17 Acc@5=81.25\n",
            "Training 4650: Loss=1.55 Acc@1=60.42 Acc@5=83.75\n",
            "Training 4680: Loss=1.83 Acc@1=50.0 Acc@5=78.33\n",
            "Training 4710: Loss=1.82 Acc@1=51.25 Acc@5=78.33\n",
            "Training 4740: Loss=1.76 Acc@1=51.25 Acc@5=80.42\n",
            "Training 4770: Loss=1.7 Acc@1=57.92 Acc@5=82.08\n",
            "Training 4800: Loss=1.79 Acc@1=52.08 Acc@5=80.83\n",
            "Training 4830: Loss=1.86 Acc@1=47.08 Acc@5=80.42\n",
            "Training 4860: Loss=1.97 Acc@1=46.67 Acc@5=79.17\n",
            "Training 4890: Loss=1.86 Acc@1=51.67 Acc@5=79.17\n",
            "Training 4920: Loss=1.76 Acc@1=51.25 Acc@5=83.75\n",
            "Training 4950: Loss=1.82 Acc@1=48.75 Acc@5=81.67\n",
            "Training 4980: Loss=1.91 Acc@1=47.92 Acc@5=80.83\n",
            "Training 5010: Loss=1.85 Acc@1=52.92 Acc@5=78.75\n",
            "Training 5040: Loss=1.88 Acc@1=48.33 Acc@5=82.08\n",
            "Training 5070: Loss=1.65 Acc@1=50.83 Acc@5=85.0\n",
            "Training 5100: Loss=1.68 Acc@1=55.83 Acc@5=84.17\n",
            "Training 5130: Loss=1.93 Acc@1=49.58 Acc@5=77.5\n",
            "Training 5160: Loss=1.58 Acc@1=54.58 Acc@5=85.83\n",
            "Training 5190: Loss=1.83 Acc@1=47.08 Acc@5=80.42\n",
            "Training 5220: Loss=1.84 Acc@1=50.0 Acc@5=80.42\n",
            "Training 5250: Loss=1.71 Acc@1=53.75 Acc@5=81.67\n",
            "Training 5280: Loss=1.83 Acc@1=55.83 Acc@5=74.58\n",
            "Training 5310: Loss=1.74 Acc@1=53.33 Acc@5=82.08\n",
            "Training 5340: Loss=1.74 Acc@1=50.42 Acc@5=84.58\n",
            "Training 5370: Loss=1.77 Acc@1=51.67 Acc@5=84.17\n",
            "Training 5400: Loss=1.7 Acc@1=52.08 Acc@5=82.5\n",
            "Training 5430: Loss=1.69 Acc@1=54.17 Acc@5=85.83\n",
            "Training 5460: Loss=1.66 Acc@1=57.08 Acc@5=80.83\n",
            "Training 5490: Loss=1.72 Acc@1=53.33 Acc@5=81.25\n",
            "Training 5520: Loss=1.89 Acc@1=48.75 Acc@5=77.92\n",
            "Training 5550: Loss=1.83 Acc@1=50.0 Acc@5=79.17\n",
            "Training 5580: Loss=1.9 Acc@1=51.25 Acc@5=82.5\n",
            "Training 5610: Loss=1.85 Acc@1=50.83 Acc@5=78.75\n",
            "Training 5640: Loss=1.73 Acc@1=52.08 Acc@5=81.25\n",
            "Training 5670: Loss=1.9 Acc@1=48.33 Acc@5=77.92\n",
            "Training 5700: Loss=1.73 Acc@1=51.25 Acc@5=80.0\n",
            "Training 5730: Loss=1.86 Acc@1=52.5 Acc@5=80.83\n",
            "Training 5760: Loss=1.9 Acc@1=48.33 Acc@5=78.33\n",
            "Training 5790: Loss=1.72 Acc@1=50.42 Acc@5=81.67\n",
            "Training 5820: Loss=1.82 Acc@1=54.17 Acc@5=81.25\n",
            "Training 5850: Loss=1.87 Acc@1=50.83 Acc@5=78.75\n",
            "Training 5880: Loss=1.87 Acc@1=48.75 Acc@5=80.0\n",
            "Training 5910: Loss=1.56 Acc@1=58.75 Acc@5=85.42\n",
            "Training 5940: Loss=1.74 Acc@1=52.08 Acc@5=82.5\n",
            "Training 5970: Loss=1.89 Acc@1=49.17 Acc@5=77.08\n",
            "Training 6000: Loss=1.87 Acc@1=47.5 Acc@5=82.5\n",
            "Training 6030: Loss=1.8 Acc@1=56.67 Acc@5=79.58\n",
            "Training 6060: Loss=1.77 Acc@1=49.17 Acc@5=83.33\n",
            "Training 6090: Loss=1.87 Acc@1=51.67 Acc@5=78.33\n",
            "Training 6120: Loss=2.02 Acc@1=44.17 Acc@5=76.67\n",
            "Training 6150: Loss=1.88 Acc@1=48.33 Acc@5=79.17\n",
            "Training 6180: Loss=1.77 Acc@1=52.5 Acc@5=80.83\n",
            "Training 6210: Loss=1.82 Acc@1=50.0 Acc@5=80.83\n",
            "Training 6240: Loss=1.81 Acc@1=50.83 Acc@5=77.92\n",
            "Full imagenet train set: Acc@1=61.25 Acc@5=88.75\n",
            "Epoch: 15 ######################################################\n",
            "Training 30: Loss=1.47 Acc@1=60.0 Acc@5=86.25\n",
            "Training 60: Loss=1.61 Acc@1=55.83 Acc@5=85.42\n",
            "Training 90: Loss=1.5 Acc@1=56.25 Acc@5=85.83\n",
            "Training 120: Loss=1.56 Acc@1=56.67 Acc@5=85.83\n",
            "Training 150: Loss=1.66 Acc@1=52.92 Acc@5=85.42\n",
            "Training 180: Loss=1.76 Acc@1=50.83 Acc@5=79.58\n",
            "Training 210: Loss=1.65 Acc@1=55.42 Acc@5=82.5\n",
            "Training 240: Loss=1.63 Acc@1=55.83 Acc@5=82.92\n",
            "Training 270: Loss=1.59 Acc@1=56.25 Acc@5=84.58\n",
            "Training 300: Loss=1.71 Acc@1=50.0 Acc@5=81.67\n",
            "Training 330: Loss=1.59 Acc@1=57.5 Acc@5=85.42\n",
            "Training 360: Loss=1.47 Acc@1=57.08 Acc@5=87.5\n",
            "Training 390: Loss=1.59 Acc@1=62.5 Acc@5=84.17\n",
            "Training 420: Loss=1.56 Acc@1=55.42 Acc@5=87.5\n",
            "Training 450: Loss=1.59 Acc@1=54.17 Acc@5=83.33\n",
            "Training 480: Loss=1.55 Acc@1=55.0 Acc@5=84.58\n",
            "Training 510: Loss=1.51 Acc@1=57.92 Acc@5=85.0\n",
            "Training 540: Loss=1.71 Acc@1=52.08 Acc@5=82.92\n",
            "Training 570: Loss=1.62 Acc@1=54.58 Acc@5=82.08\n",
            "Training 600: Loss=1.6 Acc@1=55.42 Acc@5=83.33\n",
            "Training 630: Loss=1.69 Acc@1=54.17 Acc@5=82.08\n",
            "Training 660: Loss=1.42 Acc@1=58.33 Acc@5=87.5\n",
            "Training 690: Loss=1.54 Acc@1=56.25 Acc@5=85.42\n",
            "Training 720: Loss=1.58 Acc@1=57.08 Acc@5=87.5\n",
            "Training 750: Loss=1.73 Acc@1=51.67 Acc@5=81.67\n",
            "Training 780: Loss=1.67 Acc@1=53.75 Acc@5=82.92\n",
            "Training 810: Loss=1.65 Acc@1=51.25 Acc@5=84.58\n",
            "Training 840: Loss=1.65 Acc@1=58.33 Acc@5=81.25\n",
            "Training 870: Loss=1.73 Acc@1=52.92 Acc@5=83.33\n",
            "Training 900: Loss=1.59 Acc@1=59.58 Acc@5=83.33\n",
            "Training 930: Loss=1.53 Acc@1=57.08 Acc@5=85.0\n",
            "Training 960: Loss=1.57 Acc@1=54.58 Acc@5=86.25\n",
            "Training 990: Loss=1.64 Acc@1=55.0 Acc@5=83.33\n",
            "Training 1020: Loss=1.7 Acc@1=54.58 Acc@5=84.17\n",
            "Training 1050: Loss=1.46 Acc@1=57.08 Acc@5=86.67\n",
            "Training 1080: Loss=1.69 Acc@1=53.75 Acc@5=82.92\n",
            "Training 1110: Loss=1.69 Acc@1=55.0 Acc@5=81.25\n",
            "Training 1140: Loss=1.59 Acc@1=53.33 Acc@5=84.17\n",
            "Training 1170: Loss=1.64 Acc@1=54.58 Acc@5=82.92\n",
            "Training 1200: Loss=1.75 Acc@1=51.25 Acc@5=81.25\n",
            "Training 1230: Loss=1.56 Acc@1=57.08 Acc@5=85.42\n",
            "Training 1260: Loss=1.68 Acc@1=49.58 Acc@5=85.0\n",
            "Training 1290: Loss=1.71 Acc@1=55.83 Acc@5=82.08\n",
            "Training 1320: Loss=1.65 Acc@1=57.08 Acc@5=82.08\n",
            "Training 1350: Loss=1.67 Acc@1=53.75 Acc@5=81.25\n",
            "Training 1380: Loss=1.71 Acc@1=51.25 Acc@5=81.25\n",
            "Training 1410: Loss=1.73 Acc@1=55.42 Acc@5=82.5\n",
            "Training 1440: Loss=1.74 Acc@1=54.17 Acc@5=82.08\n",
            "Training 1470: Loss=1.72 Acc@1=55.0 Acc@5=80.83\n",
            "Training 1500: Loss=1.61 Acc@1=55.0 Acc@5=85.83\n",
            "Training 1530: Loss=1.51 Acc@1=55.83 Acc@5=85.0\n",
            "Training 1560: Loss=1.73 Acc@1=52.08 Acc@5=82.08\n",
            "Training 1590: Loss=1.73 Acc@1=52.5 Acc@5=83.75\n",
            "Training 1620: Loss=1.66 Acc@1=55.42 Acc@5=81.25\n",
            "Training 1650: Loss=1.76 Acc@1=50.0 Acc@5=80.83\n",
            "Training 1680: Loss=1.67 Acc@1=52.08 Acc@5=82.08\n",
            "Training 1710: Loss=1.72 Acc@1=53.33 Acc@5=81.25\n",
            "Training 1740: Loss=1.7 Acc@1=59.17 Acc@5=82.08\n",
            "Training 1770: Loss=1.59 Acc@1=54.58 Acc@5=83.33\n",
            "Training 1800: Loss=1.73 Acc@1=50.83 Acc@5=83.33\n",
            "Training 1830: Loss=1.7 Acc@1=50.42 Acc@5=81.67\n",
            "Training 1860: Loss=1.88 Acc@1=47.5 Acc@5=79.17\n",
            "Training 1890: Loss=1.74 Acc@1=52.92 Acc@5=82.08\n",
            "Training 1920: Loss=1.72 Acc@1=52.5 Acc@5=81.25\n",
            "Training 1950: Loss=1.36 Acc@1=62.92 Acc@5=87.5\n",
            "Training 1980: Loss=1.45 Acc@1=62.92 Acc@5=87.08\n",
            "Training 2010: Loss=1.71 Acc@1=52.5 Acc@5=84.17\n",
            "Training 2040: Loss=1.7 Acc@1=55.0 Acc@5=82.5\n",
            "Training 2070: Loss=1.56 Acc@1=55.42 Acc@5=86.25\n",
            "Training 2100: Loss=1.78 Acc@1=52.08 Acc@5=82.5\n",
            "Training 2130: Loss=1.87 Acc@1=50.0 Acc@5=80.83\n",
            "Training 2160: Loss=1.76 Acc@1=48.75 Acc@5=82.92\n",
            "Training 2190: Loss=1.82 Acc@1=48.75 Acc@5=83.75\n",
            "Training 2220: Loss=1.88 Acc@1=46.67 Acc@5=81.25\n",
            "Training 2250: Loss=1.72 Acc@1=57.92 Acc@5=82.08\n",
            "Training 2280: Loss=1.59 Acc@1=54.58 Acc@5=85.42\n",
            "Training 2310: Loss=1.63 Acc@1=53.33 Acc@5=86.25\n",
            "Training 2340: Loss=1.76 Acc@1=51.25 Acc@5=82.92\n",
            "Training 2370: Loss=1.67 Acc@1=55.0 Acc@5=81.67\n",
            "Training 2400: Loss=1.72 Acc@1=54.58 Acc@5=81.67\n",
            "Training 2430: Loss=1.76 Acc@1=45.83 Acc@5=84.58\n",
            "Training 2460: Loss=1.6 Acc@1=53.75 Acc@5=88.33\n",
            "Training 2490: Loss=1.56 Acc@1=52.5 Acc@5=87.92\n",
            "Training 2520: Loss=1.71 Acc@1=54.58 Acc@5=82.92\n",
            "Training 2550: Loss=1.77 Acc@1=50.0 Acc@5=84.17\n",
            "Training 2580: Loss=1.77 Acc@1=50.0 Acc@5=80.42\n",
            "Training 2610: Loss=1.64 Acc@1=53.33 Acc@5=82.5\n",
            "Training 2640: Loss=1.67 Acc@1=55.0 Acc@5=85.0\n",
            "Training 2670: Loss=1.53 Acc@1=60.83 Acc@5=85.42\n",
            "Training 2700: Loss=1.59 Acc@1=55.42 Acc@5=82.92\n",
            "Training 2730: Loss=1.7 Acc@1=53.33 Acc@5=83.75\n",
            "Training 2760: Loss=1.75 Acc@1=51.25 Acc@5=81.67\n",
            "Training 2790: Loss=1.84 Acc@1=50.0 Acc@5=78.33\n",
            "Training 2820: Loss=1.8 Acc@1=52.5 Acc@5=81.25\n",
            "Training 2850: Loss=1.69 Acc@1=51.67 Acc@5=83.75\n",
            "Training 2880: Loss=1.85 Acc@1=51.67 Acc@5=80.42\n",
            "Training 2910: Loss=1.76 Acc@1=50.42 Acc@5=81.25\n",
            "Training 2940: Loss=1.73 Acc@1=49.58 Acc@5=80.0\n",
            "Training 2970: Loss=1.67 Acc@1=53.33 Acc@5=84.58\n",
            "Training 3000: Loss=1.68 Acc@1=56.25 Acc@5=81.25\n",
            "Training 3030: Loss=1.72 Acc@1=52.92 Acc@5=84.58\n",
            "Training 3060: Loss=1.59 Acc@1=60.83 Acc@5=87.08\n",
            "Training 3090: Loss=1.97 Acc@1=49.58 Acc@5=76.67\n",
            "Training 3120: Loss=1.91 Acc@1=45.83 Acc@5=79.58\n",
            "Training 3150: Loss=1.6 Acc@1=54.58 Acc@5=85.83\n",
            "Training 3180: Loss=1.76 Acc@1=49.58 Acc@5=83.33\n",
            "Training 3210: Loss=1.66 Acc@1=53.75 Acc@5=83.33\n",
            "Training 3240: Loss=1.75 Acc@1=50.0 Acc@5=83.75\n",
            "Training 3270: Loss=1.69 Acc@1=54.58 Acc@5=80.42\n",
            "Training 3300: Loss=1.78 Acc@1=52.5 Acc@5=79.17\n",
            "Training 3330: Loss=1.93 Acc@1=45.42 Acc@5=78.33\n",
            "Training 3360: Loss=1.73 Acc@1=53.75 Acc@5=81.67\n",
            "Training 3390: Loss=1.66 Acc@1=55.83 Acc@5=81.67\n",
            "Training 3420: Loss=1.89 Acc@1=50.83 Acc@5=77.5\n",
            "Training 3450: Loss=1.55 Acc@1=56.67 Acc@5=84.58\n",
            "Training 3480: Loss=1.62 Acc@1=55.83 Acc@5=84.58\n",
            "Training 3510: Loss=1.89 Acc@1=48.75 Acc@5=76.67\n",
            "Training 3540: Loss=1.86 Acc@1=50.83 Acc@5=77.5\n",
            "Training 3570: Loss=1.75 Acc@1=50.42 Acc@5=80.0\n",
            "Training 3600: Loss=1.78 Acc@1=53.75 Acc@5=82.08\n",
            "Training 3630: Loss=1.67 Acc@1=57.08 Acc@5=82.08\n",
            "Training 3660: Loss=1.66 Acc@1=56.67 Acc@5=80.42\n",
            "Training 3690: Loss=1.91 Acc@1=46.67 Acc@5=79.58\n",
            "Training 3720: Loss=1.66 Acc@1=55.0 Acc@5=83.33\n",
            "Training 3750: Loss=1.68 Acc@1=53.33 Acc@5=85.42\n",
            "Training 3780: Loss=1.53 Acc@1=54.58 Acc@5=87.5\n",
            "Training 3810: Loss=1.5 Acc@1=59.17 Acc@5=85.0\n",
            "Training 3840: Loss=1.71 Acc@1=54.58 Acc@5=84.17\n",
            "Training 3870: Loss=1.69 Acc@1=57.5 Acc@5=80.83\n",
            "Training 3900: Loss=1.74 Acc@1=50.83 Acc@5=83.33\n",
            "Training 3930: Loss=1.57 Acc@1=55.0 Acc@5=82.92\n",
            "Training 3960: Loss=1.77 Acc@1=53.33 Acc@5=81.25\n",
            "Training 3990: Loss=1.61 Acc@1=57.08 Acc@5=86.25\n",
            "Training 4020: Loss=1.75 Acc@1=52.92 Acc@5=82.08\n",
            "Training 4050: Loss=1.78 Acc@1=51.67 Acc@5=80.83\n",
            "Training 4080: Loss=1.5 Acc@1=57.5 Acc@5=84.58\n",
            "Training 4110: Loss=1.59 Acc@1=57.08 Acc@5=85.42\n",
            "Training 4140: Loss=1.69 Acc@1=55.0 Acc@5=82.08\n",
            "Training 4170: Loss=1.89 Acc@1=51.67 Acc@5=77.5\n",
            "Training 4200: Loss=1.83 Acc@1=50.83 Acc@5=81.67\n",
            "Training 4230: Loss=1.46 Acc@1=59.17 Acc@5=84.58\n",
            "Training 4260: Loss=1.8 Acc@1=50.42 Acc@5=81.25\n",
            "Training 4290: Loss=1.82 Acc@1=49.17 Acc@5=80.83\n",
            "Training 4320: Loss=1.76 Acc@1=48.75 Acc@5=82.08\n",
            "Training 4350: Loss=1.47 Acc@1=60.0 Acc@5=85.42\n",
            "Training 4380: Loss=1.74 Acc@1=50.83 Acc@5=81.25\n",
            "Training 4410: Loss=1.52 Acc@1=59.17 Acc@5=83.33\n",
            "Training 4440: Loss=1.87 Acc@1=46.67 Acc@5=80.83\n",
            "Training 4470: Loss=1.8 Acc@1=51.67 Acc@5=79.58\n",
            "Training 4500: Loss=1.92 Acc@1=43.75 Acc@5=77.08\n",
            "Training 4530: Loss=1.81 Acc@1=51.67 Acc@5=80.42\n",
            "Training 4560: Loss=1.6 Acc@1=55.83 Acc@5=85.83\n",
            "Training 4590: Loss=1.54 Acc@1=55.42 Acc@5=86.67\n",
            "Training 4620: Loss=1.75 Acc@1=51.67 Acc@5=81.67\n",
            "Training 4650: Loss=1.64 Acc@1=54.58 Acc@5=83.75\n",
            "Training 4680: Loss=1.87 Acc@1=49.17 Acc@5=80.42\n",
            "Training 4710: Loss=1.85 Acc@1=50.0 Acc@5=78.33\n",
            "Training 4740: Loss=1.65 Acc@1=53.75 Acc@5=82.92\n",
            "Training 4770: Loss=1.64 Acc@1=53.75 Acc@5=84.17\n",
            "Training 4800: Loss=1.79 Acc@1=52.5 Acc@5=82.5\n",
            "Training 4830: Loss=1.81 Acc@1=47.5 Acc@5=81.67\n",
            "Training 4860: Loss=1.75 Acc@1=52.92 Acc@5=80.0\n",
            "Training 4890: Loss=1.69 Acc@1=55.83 Acc@5=84.17\n",
            "Training 4920: Loss=1.7 Acc@1=52.08 Acc@5=83.75\n",
            "Training 4950: Loss=1.83 Acc@1=50.0 Acc@5=79.58\n",
            "Training 4980: Loss=1.65 Acc@1=54.58 Acc@5=82.08\n",
            "Training 5010: Loss=1.91 Acc@1=46.25 Acc@5=80.42\n",
            "Training 5040: Loss=1.84 Acc@1=51.67 Acc@5=79.17\n",
            "Training 5070: Loss=1.58 Acc@1=51.67 Acc@5=84.17\n",
            "Training 5100: Loss=1.62 Acc@1=54.17 Acc@5=81.67\n",
            "Training 5130: Loss=1.72 Acc@1=52.5 Acc@5=79.58\n",
            "Training 5160: Loss=1.84 Acc@1=50.0 Acc@5=78.75\n",
            "Training 5190: Loss=1.82 Acc@1=50.42 Acc@5=79.58\n",
            "Training 5220: Loss=1.7 Acc@1=52.92 Acc@5=80.0\n",
            "Training 5250: Loss=1.75 Acc@1=48.33 Acc@5=78.75\n",
            "Training 5280: Loss=1.68 Acc@1=52.92 Acc@5=81.67\n",
            "Training 5310: Loss=1.69 Acc@1=57.5 Acc@5=82.08\n",
            "Training 5340: Loss=1.85 Acc@1=49.17 Acc@5=80.42\n",
            "Training 5370: Loss=1.76 Acc@1=51.25 Acc@5=79.58\n",
            "Training 5400: Loss=1.81 Acc@1=50.0 Acc@5=82.08\n",
            "Training 5430: Loss=1.68 Acc@1=54.17 Acc@5=81.67\n",
            "Training 5460: Loss=1.73 Acc@1=52.08 Acc@5=82.5\n",
            "Training 5490: Loss=1.78 Acc@1=53.33 Acc@5=82.08\n",
            "Training 5520: Loss=1.69 Acc@1=57.08 Acc@5=82.92\n",
            "Training 5550: Loss=1.64 Acc@1=52.92 Acc@5=85.0\n",
            "Training 5580: Loss=1.83 Acc@1=51.67 Acc@5=79.58\n",
            "Training 5610: Loss=1.76 Acc@1=53.75 Acc@5=80.42\n",
            "Training 5640: Loss=1.71 Acc@1=48.75 Acc@5=85.0\n",
            "Training 5670: Loss=1.77 Acc@1=50.83 Acc@5=81.67\n",
            "Training 5700: Loss=1.7 Acc@1=53.33 Acc@5=83.33\n",
            "Training 5730: Loss=1.76 Acc@1=52.5 Acc@5=82.5\n",
            "Training 5760: Loss=1.74 Acc@1=54.17 Acc@5=82.08\n",
            "Training 5790: Loss=1.73 Acc@1=52.5 Acc@5=81.25\n",
            "Training 5820: Loss=1.79 Acc@1=49.17 Acc@5=82.5\n",
            "Training 5850: Loss=1.67 Acc@1=57.92 Acc@5=83.33\n",
            "Training 5880: Loss=1.69 Acc@1=51.25 Acc@5=82.08\n",
            "Training 5910: Loss=1.85 Acc@1=53.33 Acc@5=78.75\n",
            "Training 5940: Loss=1.93 Acc@1=48.33 Acc@5=77.92\n",
            "Training 5970: Loss=1.76 Acc@1=53.33 Acc@5=81.67\n",
            "Training 6000: Loss=2.0 Acc@1=48.75 Acc@5=74.58\n",
            "Training 6030: Loss=1.9 Acc@1=52.08 Acc@5=80.42\n",
            "Training 6060: Loss=1.64 Acc@1=55.0 Acc@5=84.17\n",
            "Training 6090: Loss=1.71 Acc@1=52.5 Acc@5=82.92\n",
            "Training 6120: Loss=1.71 Acc@1=55.0 Acc@5=81.67\n",
            "Training 6150: Loss=1.75 Acc@1=52.08 Acc@5=82.5\n",
            "Training 6180: Loss=1.74 Acc@1=51.25 Acc@5=82.5\n",
            "Training 6210: Loss=1.57 Acc@1=55.42 Acc@5=83.75\n",
            "Training 6240: Loss=1.53 Acc@1=59.17 Acc@5=83.75\n",
            "Full imagenet train set: Acc@1=60.0 Acc@5=86.25\n",
            "Epoch: 16 ######################################################\n",
            "Training 30: Loss=1.39 Acc@1=62.92 Acc@5=88.75\n",
            "Training 60: Loss=1.53 Acc@1=57.92 Acc@5=86.25\n",
            "Training 90: Loss=1.6 Acc@1=50.0 Acc@5=87.08\n",
            "Training 120: Loss=1.41 Acc@1=60.0 Acc@5=88.33\n",
            "Training 150: Loss=1.57 Acc@1=58.33 Acc@5=83.33\n",
            "Training 180: Loss=1.65 Acc@1=52.5 Acc@5=81.67\n",
            "Training 210: Loss=1.62 Acc@1=55.0 Acc@5=84.58\n",
            "Training 240: Loss=1.5 Acc@1=60.0 Acc@5=87.5\n",
            "Training 270: Loss=1.62 Acc@1=57.92 Acc@5=84.58\n",
            "Training 300: Loss=1.38 Acc@1=61.25 Acc@5=87.08\n",
            "Training 330: Loss=1.4 Acc@1=59.58 Acc@5=86.25\n",
            "Training 360: Loss=1.51 Acc@1=60.42 Acc@5=85.83\n",
            "Training 390: Loss=1.39 Acc@1=60.83 Acc@5=90.83\n",
            "Training 420: Loss=1.67 Acc@1=51.67 Acc@5=84.17\n",
            "Training 450: Loss=1.49 Acc@1=60.83 Acc@5=87.08\n",
            "Training 480: Loss=1.46 Acc@1=60.0 Acc@5=88.75\n",
            "Training 510: Loss=1.61 Acc@1=55.42 Acc@5=84.58\n",
            "Training 540: Loss=1.6 Acc@1=60.0 Acc@5=81.25\n",
            "Training 570: Loss=1.39 Acc@1=63.75 Acc@5=86.67\n",
            "Training 600: Loss=1.48 Acc@1=59.58 Acc@5=87.92\n",
            "Training 630: Loss=1.33 Acc@1=63.75 Acc@5=87.08\n",
            "Training 660: Loss=1.34 Acc@1=59.17 Acc@5=87.5\n",
            "Training 690: Loss=1.49 Acc@1=62.92 Acc@5=86.67\n",
            "Training 720: Loss=1.66 Acc@1=51.67 Acc@5=83.75\n",
            "Training 750: Loss=1.51 Acc@1=62.08 Acc@5=82.92\n",
            "Training 780: Loss=1.6 Acc@1=61.67 Acc@5=85.0\n",
            "Training 810: Loss=1.51 Acc@1=57.08 Acc@5=86.67\n",
            "Training 840: Loss=1.59 Acc@1=54.17 Acc@5=85.42\n",
            "Training 870: Loss=1.32 Acc@1=60.42 Acc@5=90.83\n",
            "Training 900: Loss=1.65 Acc@1=55.42 Acc@5=81.25\n",
            "Training 930: Loss=1.63 Acc@1=55.42 Acc@5=84.58\n",
            "Training 960: Loss=1.5 Acc@1=56.67 Acc@5=85.42\n",
            "Training 990: Loss=1.54 Acc@1=53.75 Acc@5=85.0\n",
            "Training 1020: Loss=1.69 Acc@1=55.83 Acc@5=80.0\n",
            "Training 1050: Loss=1.64 Acc@1=56.67 Acc@5=81.25\n",
            "Training 1080: Loss=1.65 Acc@1=55.83 Acc@5=82.92\n",
            "Training 1110: Loss=1.66 Acc@1=55.0 Acc@5=80.0\n",
            "Training 1140: Loss=1.85 Acc@1=52.92 Acc@5=80.83\n",
            "Training 1170: Loss=1.45 Acc@1=57.5 Acc@5=89.17\n",
            "Training 1200: Loss=1.65 Acc@1=54.58 Acc@5=84.17\n",
            "Training 1230: Loss=1.54 Acc@1=54.17 Acc@5=85.83\n",
            "Training 1260: Loss=1.67 Acc@1=54.58 Acc@5=84.17\n",
            "Training 1290: Loss=1.67 Acc@1=56.67 Acc@5=82.08\n",
            "Training 1320: Loss=1.54 Acc@1=60.42 Acc@5=83.75\n",
            "Training 1350: Loss=1.56 Acc@1=56.67 Acc@5=86.25\n",
            "Training 1380: Loss=1.65 Acc@1=57.08 Acc@5=82.92\n",
            "Training 1410: Loss=1.53 Acc@1=58.33 Acc@5=87.5\n",
            "Training 1440: Loss=1.55 Acc@1=59.17 Acc@5=85.42\n",
            "Training 1470: Loss=1.49 Acc@1=59.58 Acc@5=84.58\n",
            "Training 1500: Loss=1.77 Acc@1=55.0 Acc@5=79.58\n",
            "Training 1530: Loss=1.73 Acc@1=53.75 Acc@5=80.42\n",
            "Training 1560: Loss=1.7 Acc@1=48.75 Acc@5=83.75\n",
            "Training 1590: Loss=1.61 Acc@1=51.67 Acc@5=86.25\n",
            "Training 1620: Loss=1.58 Acc@1=55.83 Acc@5=83.75\n",
            "Training 1650: Loss=1.61 Acc@1=55.83 Acc@5=83.33\n",
            "Training 1680: Loss=1.7 Acc@1=50.42 Acc@5=82.08\n",
            "Training 1710: Loss=1.63 Acc@1=52.92 Acc@5=85.0\n",
            "Training 1740: Loss=1.71 Acc@1=49.17 Acc@5=85.0\n",
            "Training 1770: Loss=1.67 Acc@1=54.58 Acc@5=83.33\n",
            "Training 1800: Loss=1.69 Acc@1=57.08 Acc@5=85.0\n",
            "Training 1830: Loss=1.58 Acc@1=56.67 Acc@5=85.83\n",
            "Training 1860: Loss=1.65 Acc@1=56.25 Acc@5=83.33\n",
            "Training 1890: Loss=1.65 Acc@1=52.5 Acc@5=81.25\n",
            "Training 1920: Loss=1.65 Acc@1=53.75 Acc@5=83.33\n",
            "Training 1950: Loss=1.6 Acc@1=54.17 Acc@5=83.33\n",
            "Training 1980: Loss=1.76 Acc@1=52.92 Acc@5=79.17\n",
            "Training 2010: Loss=1.63 Acc@1=57.5 Acc@5=83.75\n",
            "Training 2040: Loss=1.66 Acc@1=54.58 Acc@5=81.25\n",
            "Training 2070: Loss=1.66 Acc@1=51.25 Acc@5=81.25\n",
            "Training 2100: Loss=1.55 Acc@1=59.17 Acc@5=84.58\n",
            "Training 2130: Loss=1.67 Acc@1=59.17 Acc@5=81.25\n",
            "Training 2160: Loss=1.71 Acc@1=52.5 Acc@5=84.58\n",
            "Training 2190: Loss=1.73 Acc@1=51.25 Acc@5=84.17\n",
            "Training 2220: Loss=1.62 Acc@1=57.92 Acc@5=83.33\n",
            "Training 2250: Loss=1.56 Acc@1=55.83 Acc@5=85.42\n",
            "Training 2280: Loss=1.7 Acc@1=57.5 Acc@5=82.08\n",
            "Training 2310: Loss=1.69 Acc@1=55.0 Acc@5=81.67\n",
            "Training 2340: Loss=1.69 Acc@1=50.42 Acc@5=81.67\n",
            "Training 2370: Loss=1.66 Acc@1=50.42 Acc@5=83.33\n",
            "Training 2400: Loss=1.42 Acc@1=62.08 Acc@5=87.08\n",
            "Training 2430: Loss=1.62 Acc@1=55.0 Acc@5=86.25\n",
            "Training 2460: Loss=1.52 Acc@1=57.5 Acc@5=83.33\n",
            "Training 2490: Loss=1.6 Acc@1=54.17 Acc@5=83.75\n",
            "Training 2520: Loss=1.6 Acc@1=55.42 Acc@5=83.75\n",
            "Training 2550: Loss=1.72 Acc@1=52.5 Acc@5=83.75\n",
            "Training 2580: Loss=1.54 Acc@1=57.5 Acc@5=87.5\n",
            "Training 2610: Loss=1.6 Acc@1=59.58 Acc@5=85.83\n",
            "Training 2640: Loss=1.62 Acc@1=55.83 Acc@5=84.58\n",
            "Training 2670: Loss=1.71 Acc@1=51.67 Acc@5=82.92\n",
            "Training 2700: Loss=1.69 Acc@1=54.58 Acc@5=84.17\n",
            "Training 2730: Loss=1.78 Acc@1=55.42 Acc@5=82.08\n",
            "Training 2760: Loss=1.5 Acc@1=57.5 Acc@5=83.75\n",
            "Training 2790: Loss=1.62 Acc@1=54.58 Acc@5=82.92\n",
            "Training 2820: Loss=1.62 Acc@1=53.33 Acc@5=83.33\n",
            "Training 2850: Loss=1.57 Acc@1=56.67 Acc@5=84.58\n",
            "Training 2880: Loss=1.55 Acc@1=58.33 Acc@5=86.25\n",
            "Training 2910: Loss=1.59 Acc@1=57.5 Acc@5=84.17\n",
            "Training 2940: Loss=1.71 Acc@1=50.42 Acc@5=82.92\n",
            "Training 2970: Loss=1.56 Acc@1=55.83 Acc@5=85.83\n",
            "Training 3000: Loss=1.74 Acc@1=50.83 Acc@5=85.0\n",
            "Training 3030: Loss=1.69 Acc@1=51.25 Acc@5=80.0\n",
            "Training 3060: Loss=1.48 Acc@1=55.83 Acc@5=87.92\n",
            "Training 3090: Loss=1.72 Acc@1=53.75 Acc@5=82.92\n",
            "Training 3120: Loss=1.61 Acc@1=57.08 Acc@5=83.75\n",
            "Training 3150: Loss=1.88 Acc@1=50.42 Acc@5=79.58\n",
            "Training 3180: Loss=1.73 Acc@1=51.67 Acc@5=80.42\n",
            "Training 3210: Loss=1.6 Acc@1=55.83 Acc@5=82.92\n",
            "Training 3240: Loss=1.6 Acc@1=53.33 Acc@5=84.17\n",
            "Training 3270: Loss=1.69 Acc@1=54.17 Acc@5=85.42\n",
            "Training 3300: Loss=1.56 Acc@1=58.33 Acc@5=83.33\n",
            "Training 3330: Loss=1.77 Acc@1=54.17 Acc@5=79.58\n",
            "Training 3360: Loss=1.77 Acc@1=53.33 Acc@5=79.17\n",
            "Training 3390: Loss=1.88 Acc@1=47.08 Acc@5=80.83\n",
            "Training 3420: Loss=1.54 Acc@1=51.25 Acc@5=86.25\n",
            "Training 3450: Loss=1.7 Acc@1=51.67 Acc@5=82.08\n",
            "Training 3480: Loss=1.74 Acc@1=53.33 Acc@5=83.33\n",
            "Training 3510: Loss=1.55 Acc@1=57.08 Acc@5=85.0\n",
            "Training 3540: Loss=1.74 Acc@1=52.08 Acc@5=80.42\n",
            "Training 3570: Loss=1.55 Acc@1=59.17 Acc@5=83.75\n",
            "Training 3600: Loss=1.85 Acc@1=52.5 Acc@5=79.17\n",
            "Training 3630: Loss=1.73 Acc@1=51.25 Acc@5=82.5\n",
            "Training 3660: Loss=1.6 Acc@1=55.42 Acc@5=83.75\n",
            "Training 3690: Loss=1.72 Acc@1=49.17 Acc@5=85.83\n",
            "Training 3720: Loss=1.59 Acc@1=54.58 Acc@5=86.67\n",
            "Training 3750: Loss=1.64 Acc@1=53.75 Acc@5=85.42\n",
            "Training 3780: Loss=1.67 Acc@1=52.92 Acc@5=84.17\n",
            "Training 3810: Loss=1.78 Acc@1=50.0 Acc@5=82.08\n",
            "Training 3840: Loss=1.72 Acc@1=53.75 Acc@5=81.67\n",
            "Training 3870: Loss=1.51 Acc@1=57.5 Acc@5=87.08\n",
            "Training 3900: Loss=1.7 Acc@1=53.75 Acc@5=80.0\n",
            "Training 3930: Loss=1.58 Acc@1=54.17 Acc@5=85.83\n",
            "Training 3960: Loss=1.63 Acc@1=54.58 Acc@5=83.33\n",
            "Training 3990: Loss=1.65 Acc@1=53.75 Acc@5=83.33\n",
            "Training 4020: Loss=1.79 Acc@1=51.67 Acc@5=82.08\n",
            "Training 4050: Loss=1.65 Acc@1=54.17 Acc@5=84.17\n",
            "Training 4080: Loss=1.69 Acc@1=54.17 Acc@5=82.08\n",
            "Training 4110: Loss=1.38 Acc@1=60.42 Acc@5=87.08\n",
            "Training 4140: Loss=1.79 Acc@1=49.17 Acc@5=80.0\n",
            "Training 4170: Loss=1.77 Acc@1=55.83 Acc@5=82.5\n",
            "Training 4200: Loss=1.61 Acc@1=54.58 Acc@5=84.17\n",
            "Training 4230: Loss=1.7 Acc@1=53.33 Acc@5=82.92\n",
            "Training 4260: Loss=1.72 Acc@1=52.92 Acc@5=81.25\n",
            "Training 4290: Loss=1.7 Acc@1=52.5 Acc@5=83.33\n",
            "Training 4320: Loss=1.67 Acc@1=51.67 Acc@5=82.92\n",
            "Training 4350: Loss=1.55 Acc@1=55.42 Acc@5=85.83\n",
            "Training 4380: Loss=1.6 Acc@1=60.0 Acc@5=84.17\n",
            "Training 4410: Loss=1.58 Acc@1=54.17 Acc@5=83.75\n",
            "Training 4440: Loss=1.71 Acc@1=48.75 Acc@5=81.67\n",
            "Training 4470: Loss=1.5 Acc@1=57.08 Acc@5=86.25\n",
            "Training 4500: Loss=1.48 Acc@1=57.5 Acc@5=85.42\n",
            "Training 4530: Loss=1.48 Acc@1=56.25 Acc@5=87.5\n",
            "Training 4560: Loss=1.69 Acc@1=55.83 Acc@5=82.92\n",
            "Training 4590: Loss=1.58 Acc@1=57.08 Acc@5=85.42\n",
            "Training 4620: Loss=1.66 Acc@1=55.83 Acc@5=82.08\n",
            "Training 4650: Loss=1.81 Acc@1=54.17 Acc@5=82.5\n",
            "Training 4680: Loss=1.66 Acc@1=56.25 Acc@5=80.42\n",
            "Training 4710: Loss=1.54 Acc@1=55.42 Acc@5=85.42\n",
            "Training 4740: Loss=1.59 Acc@1=52.92 Acc@5=84.17\n",
            "Training 4770: Loss=1.64 Acc@1=53.75 Acc@5=83.75\n",
            "Training 4800: Loss=1.81 Acc@1=52.08 Acc@5=77.92\n",
            "Training 4830: Loss=1.92 Acc@1=47.92 Acc@5=80.0\n",
            "Training 4860: Loss=1.72 Acc@1=54.58 Acc@5=81.67\n",
            "Training 4890: Loss=1.77 Acc@1=47.08 Acc@5=78.75\n",
            "Training 4920: Loss=1.55 Acc@1=55.42 Acc@5=82.5\n",
            "Training 4950: Loss=1.63 Acc@1=54.17 Acc@5=81.25\n",
            "Training 4980: Loss=1.8 Acc@1=50.0 Acc@5=78.33\n",
            "Training 5010: Loss=1.55 Acc@1=55.42 Acc@5=86.67\n",
            "Training 5040: Loss=1.54 Acc@1=55.0 Acc@5=82.5\n",
            "Training 5070: Loss=1.68 Acc@1=51.25 Acc@5=79.58\n",
            "Training 5100: Loss=1.9 Acc@1=50.83 Acc@5=76.67\n",
            "Training 5130: Loss=1.59 Acc@1=59.58 Acc@5=84.17\n",
            "Training 5160: Loss=1.74 Acc@1=53.33 Acc@5=83.75\n",
            "Training 5190: Loss=1.51 Acc@1=57.92 Acc@5=85.83\n",
            "Training 5220: Loss=1.56 Acc@1=57.5 Acc@5=85.83\n",
            "Training 5250: Loss=1.47 Acc@1=60.83 Acc@5=87.08\n",
            "Training 5280: Loss=1.68 Acc@1=49.58 Acc@5=81.25\n",
            "Training 5310: Loss=1.75 Acc@1=52.92 Acc@5=80.0\n",
            "Training 5340: Loss=1.67 Acc@1=57.5 Acc@5=81.25\n",
            "Training 5370: Loss=1.66 Acc@1=52.92 Acc@5=80.83\n",
            "Training 5400: Loss=1.58 Acc@1=56.67 Acc@5=82.92\n",
            "Training 5430: Loss=1.69 Acc@1=54.17 Acc@5=79.17\n",
            "Training 5460: Loss=1.65 Acc@1=53.33 Acc@5=83.75\n",
            "Training 5490: Loss=1.74 Acc@1=52.5 Acc@5=81.25\n",
            "Training 5520: Loss=1.62 Acc@1=55.42 Acc@5=82.92\n",
            "Training 5550: Loss=1.72 Acc@1=53.75 Acc@5=81.25\n",
            "Training 5580: Loss=1.81 Acc@1=52.5 Acc@5=82.5\n",
            "Training 5610: Loss=1.65 Acc@1=55.0 Acc@5=83.75\n",
            "Training 5640: Loss=1.8 Acc@1=51.25 Acc@5=80.83\n",
            "Training 5670: Loss=1.59 Acc@1=55.42 Acc@5=86.67\n",
            "Training 5700: Loss=1.72 Acc@1=51.25 Acc@5=84.17\n",
            "Training 5730: Loss=1.66 Acc@1=55.42 Acc@5=82.92\n",
            "Training 5760: Loss=1.92 Acc@1=49.58 Acc@5=79.17\n",
            "Training 5790: Loss=1.87 Acc@1=48.75 Acc@5=77.92\n",
            "Training 5820: Loss=1.69 Acc@1=54.58 Acc@5=79.58\n",
            "Training 5850: Loss=1.74 Acc@1=52.08 Acc@5=82.08\n",
            "Training 5880: Loss=1.55 Acc@1=55.83 Acc@5=85.0\n",
            "Training 5910: Loss=1.78 Acc@1=51.67 Acc@5=80.42\n",
            "Training 5940: Loss=1.72 Acc@1=53.75 Acc@5=86.67\n",
            "Training 5970: Loss=1.59 Acc@1=51.67 Acc@5=85.83\n",
            "Training 6000: Loss=1.67 Acc@1=57.5 Acc@5=81.67\n",
            "Training 6030: Loss=1.65 Acc@1=56.67 Acc@5=83.75\n",
            "Training 6060: Loss=1.52 Acc@1=54.58 Acc@5=85.42\n",
            "Training 6090: Loss=1.62 Acc@1=54.58 Acc@5=83.75\n",
            "Training 6120: Loss=1.63 Acc@1=56.67 Acc@5=84.17\n",
            "Training 6150: Loss=1.66 Acc@1=52.92 Acc@5=80.83\n",
            "Training 6180: Loss=1.61 Acc@1=58.33 Acc@5=83.33\n",
            "Training 6210: Loss=1.83 Acc@1=50.0 Acc@5=79.17\n",
            "Training 6240: Loss=1.63 Acc@1=55.42 Acc@5=85.83\n",
            "Full imagenet train set: Acc@1=70.0 Acc@5=96.25\n",
            "Epoch: 17 ######################################################\n",
            "Training 30: Loss=1.49 Acc@1=53.75 Acc@5=84.58\n",
            "Training 60: Loss=1.59 Acc@1=57.08 Acc@5=83.75\n",
            "Training 90: Loss=1.26 Acc@1=63.33 Acc@5=87.5\n",
            "Training 120: Loss=1.45 Acc@1=62.08 Acc@5=85.83\n",
            "Training 150: Loss=1.45 Acc@1=56.67 Acc@5=86.25\n",
            "Training 180: Loss=1.33 Acc@1=60.42 Acc@5=90.0\n",
            "Training 210: Loss=1.35 Acc@1=58.75 Acc@5=88.75\n",
            "Training 240: Loss=1.41 Acc@1=60.0 Acc@5=88.75\n",
            "Training 270: Loss=1.58 Acc@1=57.08 Acc@5=82.92\n",
            "Training 300: Loss=1.65 Acc@1=51.67 Acc@5=82.92\n",
            "Training 330: Loss=1.62 Acc@1=55.0 Acc@5=87.08\n",
            "Training 360: Loss=1.56 Acc@1=54.58 Acc@5=85.42\n",
            "Training 390: Loss=1.38 Acc@1=57.08 Acc@5=85.83\n",
            "Training 420: Loss=1.45 Acc@1=60.0 Acc@5=84.17\n",
            "Training 450: Loss=1.6 Acc@1=52.92 Acc@5=84.17\n",
            "Training 480: Loss=1.65 Acc@1=55.0 Acc@5=82.08\n",
            "Training 510: Loss=1.43 Acc@1=61.25 Acc@5=85.83\n",
            "Training 540: Loss=1.49 Acc@1=59.58 Acc@5=85.0\n",
            "Training 570: Loss=1.51 Acc@1=55.83 Acc@5=85.0\n",
            "Training 600: Loss=1.55 Acc@1=54.17 Acc@5=86.67\n",
            "Training 630: Loss=1.6 Acc@1=56.25 Acc@5=86.67\n",
            "Training 660: Loss=1.48 Acc@1=57.08 Acc@5=84.58\n",
            "Training 690: Loss=1.61 Acc@1=54.17 Acc@5=84.17\n",
            "Training 720: Loss=1.56 Acc@1=58.75 Acc@5=84.58\n",
            "Training 750: Loss=1.57 Acc@1=56.67 Acc@5=83.33\n",
            "Training 780: Loss=1.56 Acc@1=57.5 Acc@5=85.42\n",
            "Training 810: Loss=1.63 Acc@1=53.75 Acc@5=84.17\n",
            "Training 840: Loss=1.82 Acc@1=54.17 Acc@5=80.42\n",
            "Training 870: Loss=1.71 Acc@1=53.33 Acc@5=81.25\n",
            "Training 900: Loss=1.54 Acc@1=54.17 Acc@5=85.83\n",
            "Training 930: Loss=1.71 Acc@1=51.67 Acc@5=80.83\n",
            "Training 960: Loss=1.43 Acc@1=60.42 Acc@5=85.0\n",
            "Training 990: Loss=1.55 Acc@1=55.42 Acc@5=85.0\n",
            "Training 1020: Loss=1.47 Acc@1=57.92 Acc@5=88.33\n",
            "Training 1050: Loss=1.52 Acc@1=58.75 Acc@5=86.67\n",
            "Training 1080: Loss=1.6 Acc@1=53.33 Acc@5=83.75\n",
            "Training 1110: Loss=1.68 Acc@1=56.25 Acc@5=84.17\n",
            "Training 1140: Loss=1.48 Acc@1=56.67 Acc@5=85.0\n",
            "Training 1170: Loss=1.57 Acc@1=57.08 Acc@5=83.33\n",
            "Training 1200: Loss=1.55 Acc@1=59.58 Acc@5=86.25\n",
            "Training 1230: Loss=1.57 Acc@1=54.58 Acc@5=85.42\n",
            "Training 1260: Loss=1.28 Acc@1=63.33 Acc@5=88.75\n",
            "Training 1290: Loss=1.38 Acc@1=57.92 Acc@5=90.42\n",
            "Training 1320: Loss=1.53 Acc@1=60.0 Acc@5=83.33\n",
            "Training 1350: Loss=1.61 Acc@1=52.5 Acc@5=85.42\n",
            "Training 1380: Loss=1.55 Acc@1=60.83 Acc@5=85.42\n",
            "Training 1410: Loss=1.52 Acc@1=55.42 Acc@5=85.0\n",
            "Training 1440: Loss=1.5 Acc@1=57.92 Acc@5=87.92\n",
            "Training 1470: Loss=1.66 Acc@1=54.58 Acc@5=80.42\n",
            "Training 1500: Loss=1.55 Acc@1=54.17 Acc@5=84.17\n",
            "Training 1530: Loss=1.53 Acc@1=56.25 Acc@5=85.0\n",
            "Training 1560: Loss=1.71 Acc@1=50.42 Acc@5=80.0\n",
            "Training 1590: Loss=1.51 Acc@1=57.08 Acc@5=85.42\n",
            "Training 1620: Loss=1.69 Acc@1=55.42 Acc@5=83.75\n",
            "Training 1650: Loss=1.52 Acc@1=59.58 Acc@5=84.58\n",
            "Training 1680: Loss=1.5 Acc@1=61.67 Acc@5=87.08\n",
            "Training 1710: Loss=1.71 Acc@1=53.33 Acc@5=85.0\n",
            "Training 1740: Loss=1.56 Acc@1=55.42 Acc@5=83.33\n",
            "Training 1770: Loss=1.34 Acc@1=63.33 Acc@5=87.5\n",
            "Training 1800: Loss=1.46 Acc@1=58.33 Acc@5=85.42\n",
            "Training 1830: Loss=1.7 Acc@1=53.33 Acc@5=81.67\n",
            "Training 1860: Loss=1.71 Acc@1=52.5 Acc@5=82.5\n",
            "Training 1890: Loss=1.57 Acc@1=57.5 Acc@5=83.33\n",
            "Training 1920: Loss=1.54 Acc@1=55.83 Acc@5=82.5\n",
            "Training 1950: Loss=1.55 Acc@1=57.92 Acc@5=85.42\n",
            "Training 1980: Loss=1.73 Acc@1=52.5 Acc@5=82.5\n",
            "Training 2010: Loss=1.56 Acc@1=52.92 Acc@5=83.33\n",
            "Training 2040: Loss=1.68 Acc@1=54.58 Acc@5=83.33\n",
            "Training 2070: Loss=1.56 Acc@1=57.92 Acc@5=84.17\n",
            "Training 2100: Loss=1.65 Acc@1=54.17 Acc@5=80.83\n",
            "Training 2130: Loss=1.59 Acc@1=53.33 Acc@5=85.42\n",
            "Training 2160: Loss=1.45 Acc@1=60.0 Acc@5=89.17\n",
            "Training 2190: Loss=1.6 Acc@1=57.08 Acc@5=85.83\n",
            "Training 2220: Loss=1.51 Acc@1=55.83 Acc@5=88.75\n",
            "Training 2250: Loss=1.59 Acc@1=55.83 Acc@5=86.25\n",
            "Training 2280: Loss=1.67 Acc@1=55.0 Acc@5=82.92\n",
            "Training 2310: Loss=1.78 Acc@1=51.67 Acc@5=83.33\n",
            "Training 2340: Loss=1.67 Acc@1=53.75 Acc@5=84.58\n",
            "Training 2370: Loss=1.52 Acc@1=57.5 Acc@5=86.25\n",
            "Training 2400: Loss=1.55 Acc@1=55.42 Acc@5=85.83\n",
            "Training 2430: Loss=1.41 Acc@1=57.92 Acc@5=88.33\n",
            "Training 2460: Loss=1.77 Acc@1=52.92 Acc@5=81.67\n",
            "Training 2490: Loss=1.62 Acc@1=54.17 Acc@5=85.42\n",
            "Training 2520: Loss=1.75 Acc@1=51.25 Acc@5=82.5\n",
            "Training 2550: Loss=1.5 Acc@1=58.33 Acc@5=84.17\n",
            "Training 2580: Loss=1.59 Acc@1=55.0 Acc@5=82.92\n",
            "Training 2610: Loss=1.82 Acc@1=48.75 Acc@5=80.42\n",
            "Training 2640: Loss=1.4 Acc@1=56.25 Acc@5=87.92\n",
            "Training 2670: Loss=1.74 Acc@1=52.08 Acc@5=81.67\n",
            "Training 2700: Loss=1.47 Acc@1=57.08 Acc@5=87.08\n",
            "Training 2730: Loss=1.64 Acc@1=55.42 Acc@5=82.5\n",
            "Training 2760: Loss=1.57 Acc@1=56.25 Acc@5=82.5\n",
            "Training 2790: Loss=1.54 Acc@1=58.75 Acc@5=85.42\n",
            "Training 2820: Loss=1.56 Acc@1=57.5 Acc@5=84.17\n",
            "Training 2850: Loss=1.44 Acc@1=59.58 Acc@5=86.25\n",
            "Training 2880: Loss=1.68 Acc@1=53.75 Acc@5=82.92\n",
            "Training 2910: Loss=1.67 Acc@1=54.17 Acc@5=83.75\n",
            "Training 2940: Loss=1.55 Acc@1=55.83 Acc@5=86.67\n",
            "Training 2970: Loss=1.83 Acc@1=51.67 Acc@5=80.42\n",
            "Training 3000: Loss=1.61 Acc@1=56.67 Acc@5=82.92\n",
            "Training 3030: Loss=1.59 Acc@1=54.17 Acc@5=82.92\n",
            "Training 3060: Loss=1.67 Acc@1=50.0 Acc@5=85.83\n",
            "Training 3090: Loss=1.73 Acc@1=47.92 Acc@5=83.33\n",
            "Training 3120: Loss=1.57 Acc@1=58.33 Acc@5=84.17\n",
            "Training 3150: Loss=1.58 Acc@1=54.17 Acc@5=85.83\n",
            "Training 3180: Loss=1.63 Acc@1=53.75 Acc@5=87.08\n",
            "Training 3210: Loss=1.52 Acc@1=55.0 Acc@5=86.25\n",
            "Training 3240: Loss=1.42 Acc@1=62.08 Acc@5=87.5\n",
            "Training 3270: Loss=1.35 Acc@1=61.67 Acc@5=88.33\n",
            "Training 3300: Loss=1.5 Acc@1=55.42 Acc@5=85.83\n",
            "Training 3330: Loss=1.57 Acc@1=57.92 Acc@5=83.75\n",
            "Training 3360: Loss=1.64 Acc@1=54.17 Acc@5=82.92\n",
            "Training 3390: Loss=1.5 Acc@1=59.17 Acc@5=86.67\n",
            "Training 3420: Loss=1.5 Acc@1=53.75 Acc@5=88.75\n",
            "Training 3450: Loss=1.48 Acc@1=57.92 Acc@5=87.5\n",
            "Training 3480: Loss=1.75 Acc@1=53.75 Acc@5=82.92\n",
            "Training 3510: Loss=1.65 Acc@1=55.0 Acc@5=86.25\n",
            "Training 3540: Loss=1.55 Acc@1=58.33 Acc@5=84.17\n",
            "Training 3570: Loss=1.63 Acc@1=53.75 Acc@5=85.83\n",
            "Training 3600: Loss=1.58 Acc@1=56.25 Acc@5=84.58\n",
            "Training 3630: Loss=1.65 Acc@1=52.5 Acc@5=85.83\n",
            "Training 3660: Loss=1.66 Acc@1=56.25 Acc@5=82.08\n",
            "Training 3690: Loss=1.58 Acc@1=56.25 Acc@5=84.58\n",
            "Training 3720: Loss=1.7 Acc@1=50.83 Acc@5=82.5\n",
            "Training 3750: Loss=1.67 Acc@1=53.75 Acc@5=82.92\n",
            "Training 3780: Loss=1.56 Acc@1=53.75 Acc@5=87.08\n",
            "Training 3810: Loss=1.56 Acc@1=56.67 Acc@5=85.0\n",
            "Training 3840: Loss=1.49 Acc@1=58.33 Acc@5=85.42\n",
            "Training 3870: Loss=1.53 Acc@1=55.83 Acc@5=86.67\n",
            "Training 3900: Loss=1.45 Acc@1=56.25 Acc@5=88.33\n",
            "Training 3930: Loss=1.49 Acc@1=61.25 Acc@5=85.83\n",
            "Training 3960: Loss=1.67 Acc@1=55.0 Acc@5=83.33\n",
            "Training 3990: Loss=1.6 Acc@1=58.33 Acc@5=82.5\n",
            "Training 4020: Loss=1.54 Acc@1=55.42 Acc@5=86.25\n",
            "Training 4050: Loss=1.6 Acc@1=56.67 Acc@5=84.17\n",
            "Training 4080: Loss=1.65 Acc@1=51.67 Acc@5=81.25\n",
            "Training 4110: Loss=1.77 Acc@1=52.92 Acc@5=80.0\n",
            "Training 4140: Loss=1.64 Acc@1=55.83 Acc@5=81.67\n",
            "Training 4170: Loss=1.47 Acc@1=56.25 Acc@5=88.75\n",
            "Training 4200: Loss=1.65 Acc@1=54.58 Acc@5=85.42\n",
            "Training 4230: Loss=1.73 Acc@1=51.25 Acc@5=84.58\n",
            "Training 4260: Loss=1.6 Acc@1=53.75 Acc@5=85.83\n",
            "Training 4290: Loss=1.8 Acc@1=53.33 Acc@5=79.17\n",
            "Training 4320: Loss=1.49 Acc@1=59.17 Acc@5=88.33\n",
            "Training 4350: Loss=1.59 Acc@1=58.75 Acc@5=86.25\n",
            "Training 4380: Loss=1.75 Acc@1=53.33 Acc@5=80.42\n",
            "Training 4410: Loss=1.68 Acc@1=52.92 Acc@5=84.17\n",
            "Training 4440: Loss=1.55 Acc@1=59.17 Acc@5=87.08\n",
            "Training 4470: Loss=1.73 Acc@1=53.75 Acc@5=81.25\n",
            "Training 4500: Loss=1.63 Acc@1=55.83 Acc@5=84.17\n",
            "Training 4530: Loss=1.58 Acc@1=57.92 Acc@5=83.75\n",
            "Training 4560: Loss=1.46 Acc@1=57.08 Acc@5=86.25\n",
            "Training 4590: Loss=1.6 Acc@1=58.33 Acc@5=84.58\n",
            "Training 4620: Loss=1.58 Acc@1=57.5 Acc@5=86.25\n",
            "Training 4650: Loss=1.83 Acc@1=50.0 Acc@5=81.67\n",
            "Training 4680: Loss=1.62 Acc@1=54.17 Acc@5=85.42\n",
            "Training 4710: Loss=1.52 Acc@1=57.5 Acc@5=86.25\n",
            "Training 4740: Loss=1.69 Acc@1=52.92 Acc@5=81.67\n",
            "Training 4770: Loss=1.66 Acc@1=54.58 Acc@5=85.42\n",
            "Training 4800: Loss=1.58 Acc@1=59.58 Acc@5=83.33\n",
            "Training 4830: Loss=1.37 Acc@1=61.67 Acc@5=88.75\n",
            "Training 4860: Loss=1.65 Acc@1=55.0 Acc@5=82.92\n",
            "Training 4890: Loss=1.51 Acc@1=57.92 Acc@5=84.58\n",
            "Training 4920: Loss=1.36 Acc@1=63.75 Acc@5=87.5\n",
            "Training 4950: Loss=1.59 Acc@1=59.17 Acc@5=82.92\n",
            "Training 4980: Loss=1.55 Acc@1=55.83 Acc@5=85.83\n",
            "Training 5010: Loss=1.46 Acc@1=59.58 Acc@5=87.08\n",
            "Training 5040: Loss=1.4 Acc@1=55.0 Acc@5=91.67\n",
            "Training 5070: Loss=1.61 Acc@1=55.0 Acc@5=85.0\n",
            "Training 5100: Loss=1.6 Acc@1=54.58 Acc@5=84.17\n",
            "Training 5130: Loss=1.65 Acc@1=58.33 Acc@5=84.17\n",
            "Training 5160: Loss=1.66 Acc@1=52.5 Acc@5=83.75\n",
            "Training 5190: Loss=1.61 Acc@1=57.08 Acc@5=83.75\n",
            "Training 5220: Loss=1.6 Acc@1=56.25 Acc@5=83.75\n",
            "Training 5250: Loss=1.73 Acc@1=54.17 Acc@5=83.33\n",
            "Training 5280: Loss=1.63 Acc@1=56.25 Acc@5=82.5\n",
            "Training 5310: Loss=1.54 Acc@1=57.5 Acc@5=85.42\n",
            "Training 5340: Loss=1.71 Acc@1=55.83 Acc@5=80.83\n",
            "Training 5370: Loss=1.83 Acc@1=49.58 Acc@5=80.83\n",
            "Training 5400: Loss=1.87 Acc@1=47.5 Acc@5=78.33\n",
            "Training 5430: Loss=1.84 Acc@1=53.33 Acc@5=77.08\n",
            "Training 5460: Loss=1.56 Acc@1=53.75 Acc@5=86.25\n",
            "Training 5490: Loss=1.57 Acc@1=58.75 Acc@5=85.42\n",
            "Training 5520: Loss=1.68 Acc@1=55.42 Acc@5=82.92\n",
            "Training 5550: Loss=1.67 Acc@1=52.92 Acc@5=84.17\n",
            "Training 5580: Loss=1.56 Acc@1=58.33 Acc@5=83.75\n",
            "Training 5610: Loss=1.61 Acc@1=59.58 Acc@5=83.33\n",
            "Training 5640: Loss=1.69 Acc@1=55.0 Acc@5=81.25\n",
            "Training 5670: Loss=1.68 Acc@1=56.25 Acc@5=79.58\n",
            "Training 5700: Loss=1.54 Acc@1=59.17 Acc@5=84.17\n",
            "Training 5730: Loss=1.58 Acc@1=55.42 Acc@5=84.17\n",
            "Training 5760: Loss=1.62 Acc@1=57.5 Acc@5=84.17\n",
            "Training 5790: Loss=1.7 Acc@1=56.67 Acc@5=82.08\n",
            "Training 5820: Loss=1.75 Acc@1=49.58 Acc@5=84.17\n",
            "Training 5850: Loss=1.81 Acc@1=50.83 Acc@5=80.0\n",
            "Training 5880: Loss=1.56 Acc@1=59.17 Acc@5=83.75\n",
            "Training 5910: Loss=1.43 Acc@1=57.5 Acc@5=87.92\n",
            "Training 5940: Loss=1.67 Acc@1=54.17 Acc@5=82.92\n",
            "Training 5970: Loss=1.73 Acc@1=53.33 Acc@5=82.5\n",
            "Training 6000: Loss=1.67 Acc@1=52.08 Acc@5=81.67\n",
            "Training 6030: Loss=1.6 Acc@1=55.0 Acc@5=85.42\n",
            "Training 6060: Loss=1.6 Acc@1=53.75 Acc@5=84.17\n",
            "Training 6090: Loss=1.62 Acc@1=52.92 Acc@5=83.75\n",
            "Training 6120: Loss=1.51 Acc@1=57.5 Acc@5=85.42\n",
            "Training 6150: Loss=1.71 Acc@1=54.17 Acc@5=81.25\n",
            "Training 6180: Loss=1.49 Acc@1=56.67 Acc@5=85.42\n",
            "Training 6210: Loss=1.6 Acc@1=53.75 Acc@5=83.33\n",
            "Training 6240: Loss=1.64 Acc@1=55.0 Acc@5=83.75\n",
            "Full imagenet train set: Acc@1=67.5 Acc@5=96.25\n",
            "Epoch: 18 ######################################################\n",
            "Training 30: Loss=1.57 Acc@1=53.33 Acc@5=82.92\n",
            "Training 60: Loss=1.47 Acc@1=57.92 Acc@5=85.42\n",
            "Training 90: Loss=1.49 Acc@1=58.33 Acc@5=87.92\n",
            "Training 120: Loss=1.39 Acc@1=56.25 Acc@5=88.75\n",
            "Training 150: Loss=1.42 Acc@1=58.75 Acc@5=88.33\n",
            "Training 180: Loss=1.42 Acc@1=57.08 Acc@5=87.08\n",
            "Training 210: Loss=1.47 Acc@1=57.92 Acc@5=84.17\n",
            "Training 240: Loss=1.41 Acc@1=58.75 Acc@5=87.92\n",
            "Training 270: Loss=1.55 Acc@1=58.33 Acc@5=83.33\n",
            "Training 300: Loss=1.47 Acc@1=58.33 Acc@5=85.42\n",
            "Training 330: Loss=1.42 Acc@1=57.92 Acc@5=88.33\n",
            "Training 360: Loss=1.42 Acc@1=62.5 Acc@5=86.67\n",
            "Training 390: Loss=1.33 Acc@1=62.5 Acc@5=90.0\n",
            "Training 420: Loss=1.31 Acc@1=62.08 Acc@5=89.58\n",
            "Training 450: Loss=1.53 Acc@1=59.17 Acc@5=86.67\n",
            "Training 480: Loss=1.5 Acc@1=58.33 Acc@5=86.25\n",
            "Training 510: Loss=1.55 Acc@1=60.42 Acc@5=85.83\n",
            "Training 540: Loss=1.42 Acc@1=60.42 Acc@5=88.33\n",
            "Training 570: Loss=1.33 Acc@1=63.33 Acc@5=86.25\n",
            "Training 600: Loss=1.4 Acc@1=60.0 Acc@5=88.75\n",
            "Training 630: Loss=1.45 Acc@1=59.58 Acc@5=87.08\n",
            "Training 660: Loss=1.38 Acc@1=57.08 Acc@5=87.92\n",
            "Training 690: Loss=1.66 Acc@1=55.0 Acc@5=84.17\n",
            "Training 720: Loss=1.4 Acc@1=59.58 Acc@5=87.08\n",
            "Training 750: Loss=1.34 Acc@1=61.25 Acc@5=90.0\n",
            "Training 780: Loss=1.6 Acc@1=55.0 Acc@5=83.75\n",
            "Training 810: Loss=1.43 Acc@1=57.92 Acc@5=88.75\n",
            "Training 840: Loss=1.43 Acc@1=59.17 Acc@5=85.83\n",
            "Training 870: Loss=1.63 Acc@1=55.0 Acc@5=83.33\n",
            "Training 900: Loss=1.34 Acc@1=60.83 Acc@5=89.17\n",
            "Training 930: Loss=1.54 Acc@1=60.0 Acc@5=85.0\n",
            "Training 960: Loss=1.36 Acc@1=62.08 Acc@5=88.75\n",
            "Training 990: Loss=1.56 Acc@1=58.75 Acc@5=86.67\n",
            "Training 1020: Loss=1.69 Acc@1=56.67 Acc@5=82.08\n",
            "Training 1050: Loss=1.52 Acc@1=57.5 Acc@5=83.75\n",
            "Training 1080: Loss=1.5 Acc@1=58.33 Acc@5=85.42\n",
            "Training 1110: Loss=1.64 Acc@1=60.0 Acc@5=82.92\n",
            "Training 1140: Loss=1.57 Acc@1=57.92 Acc@5=82.5\n",
            "Training 1170: Loss=1.52 Acc@1=58.75 Acc@5=84.17\n",
            "Training 1200: Loss=1.38 Acc@1=62.08 Acc@5=88.33\n",
            "Training 1230: Loss=1.57 Acc@1=57.08 Acc@5=84.58\n",
            "Training 1260: Loss=1.42 Acc@1=57.08 Acc@5=87.92\n",
            "Training 1290: Loss=1.68 Acc@1=52.5 Acc@5=81.67\n",
            "Training 1320: Loss=1.41 Acc@1=60.42 Acc@5=88.75\n",
            "Training 1350: Loss=1.53 Acc@1=58.33 Acc@5=84.17\n",
            "Training 1380: Loss=1.44 Acc@1=58.33 Acc@5=90.0\n",
            "Training 1410: Loss=1.41 Acc@1=61.67 Acc@5=86.67\n",
            "Training 1440: Loss=1.41 Acc@1=60.0 Acc@5=85.83\n",
            "Training 1470: Loss=1.47 Acc@1=60.83 Acc@5=85.42\n",
            "Training 1500: Loss=1.47 Acc@1=58.33 Acc@5=86.67\n",
            "Training 1530: Loss=1.24 Acc@1=64.17 Acc@5=89.17\n",
            "Training 1560: Loss=1.73 Acc@1=53.33 Acc@5=81.67\n",
            "Training 1590: Loss=1.51 Acc@1=60.0 Acc@5=86.25\n",
            "Training 1620: Loss=1.44 Acc@1=60.42 Acc@5=85.0\n",
            "Training 1650: Loss=1.39 Acc@1=60.42 Acc@5=87.5\n",
            "Training 1680: Loss=1.55 Acc@1=55.83 Acc@5=87.5\n",
            "Training 1710: Loss=1.4 Acc@1=62.08 Acc@5=86.67\n",
            "Training 1740: Loss=1.48 Acc@1=59.17 Acc@5=86.25\n",
            "Training 1770: Loss=1.68 Acc@1=52.92 Acc@5=83.33\n",
            "Training 1800: Loss=1.42 Acc@1=58.75 Acc@5=87.5\n",
            "Training 1830: Loss=1.68 Acc@1=53.75 Acc@5=83.33\n",
            "Training 1860: Loss=1.77 Acc@1=52.08 Acc@5=83.33\n",
            "Training 1890: Loss=1.42 Acc@1=56.25 Acc@5=84.58\n",
            "Training 1920: Loss=1.39 Acc@1=61.25 Acc@5=85.83\n",
            "Training 1950: Loss=1.33 Acc@1=62.5 Acc@5=88.75\n",
            "Training 1980: Loss=1.45 Acc@1=59.17 Acc@5=89.58\n",
            "Training 2010: Loss=1.56 Acc@1=56.67 Acc@5=84.58\n",
            "Training 2040: Loss=1.48 Acc@1=56.67 Acc@5=87.92\n",
            "Training 2070: Loss=1.52 Acc@1=61.25 Acc@5=83.75\n",
            "Training 2100: Loss=1.49 Acc@1=57.08 Acc@5=87.08\n",
            "Training 2130: Loss=1.33 Acc@1=62.5 Acc@5=87.08\n",
            "Training 2160: Loss=1.46 Acc@1=57.92 Acc@5=87.08\n",
            "Training 2190: Loss=1.52 Acc@1=57.08 Acc@5=84.58\n",
            "Training 2220: Loss=1.47 Acc@1=57.5 Acc@5=86.67\n",
            "Training 2250: Loss=1.54 Acc@1=57.08 Acc@5=85.0\n",
            "Training 2280: Loss=1.52 Acc@1=58.33 Acc@5=86.25\n",
            "Training 2310: Loss=1.47 Acc@1=57.5 Acc@5=86.67\n",
            "Training 2340: Loss=1.39 Acc@1=61.25 Acc@5=88.33\n",
            "Training 2370: Loss=1.44 Acc@1=60.42 Acc@5=87.92\n",
            "Training 2400: Loss=1.64 Acc@1=56.25 Acc@5=83.33\n",
            "Training 2430: Loss=1.62 Acc@1=56.25 Acc@5=84.17\n",
            "Training 2460: Loss=1.62 Acc@1=55.83 Acc@5=83.75\n",
            "Training 2490: Loss=1.46 Acc@1=59.58 Acc@5=88.33\n",
            "Training 2520: Loss=1.43 Acc@1=60.83 Acc@5=87.92\n",
            "Training 2550: Loss=1.56 Acc@1=57.92 Acc@5=86.67\n",
            "Training 2580: Loss=1.44 Acc@1=60.83 Acc@5=85.83\n",
            "Training 2610: Loss=1.56 Acc@1=55.0 Acc@5=83.33\n",
            "Training 2640: Loss=1.5 Acc@1=61.67 Acc@5=84.58\n",
            "Training 2670: Loss=1.4 Acc@1=56.67 Acc@5=86.25\n",
            "Training 2700: Loss=1.45 Acc@1=59.17 Acc@5=88.75\n",
            "Training 2730: Loss=1.55 Acc@1=56.25 Acc@5=87.08\n",
            "Training 2760: Loss=1.48 Acc@1=56.67 Acc@5=87.5\n",
            "Training 2790: Loss=1.64 Acc@1=55.0 Acc@5=83.33\n",
            "Training 2820: Loss=1.58 Acc@1=56.25 Acc@5=83.75\n",
            "Training 2850: Loss=1.53 Acc@1=57.08 Acc@5=83.75\n",
            "Training 2880: Loss=1.55 Acc@1=59.17 Acc@5=84.17\n",
            "Training 2910: Loss=1.75 Acc@1=52.92 Acc@5=79.58\n",
            "Training 2940: Loss=1.55 Acc@1=58.75 Acc@5=87.08\n",
            "Training 2970: Loss=1.37 Acc@1=64.17 Acc@5=87.92\n",
            "Training 3000: Loss=1.56 Acc@1=59.17 Acc@5=86.67\n",
            "Training 3030: Loss=1.76 Acc@1=47.5 Acc@5=85.0\n",
            "Training 3060: Loss=1.63 Acc@1=52.5 Acc@5=84.17\n",
            "Training 3090: Loss=1.4 Acc@1=58.75 Acc@5=87.08\n",
            "Training 3120: Loss=1.53 Acc@1=57.08 Acc@5=84.17\n",
            "Training 3150: Loss=1.6 Acc@1=55.42 Acc@5=84.17\n",
            "Training 3180: Loss=1.36 Acc@1=64.17 Acc@5=87.92\n",
            "Training 3210: Loss=1.59 Acc@1=59.17 Acc@5=84.17\n",
            "Training 3240: Loss=1.49 Acc@1=56.25 Acc@5=86.67\n",
            "Training 3270: Loss=1.39 Acc@1=62.08 Acc@5=86.67\n",
            "Training 3300: Loss=1.47 Acc@1=56.67 Acc@5=86.25\n",
            "Training 3330: Loss=1.55 Acc@1=56.25 Acc@5=86.25\n",
            "Training 3360: Loss=1.51 Acc@1=54.58 Acc@5=86.25\n",
            "Training 3390: Loss=1.29 Acc@1=65.0 Acc@5=88.33\n",
            "Training 3420: Loss=1.8 Acc@1=55.42 Acc@5=82.5\n",
            "Training 3450: Loss=1.58 Acc@1=53.75 Acc@5=85.42\n",
            "Training 3480: Loss=1.71 Acc@1=52.5 Acc@5=80.0\n",
            "Training 3510: Loss=1.67 Acc@1=53.33 Acc@5=84.58\n",
            "Training 3540: Loss=1.52 Acc@1=58.75 Acc@5=85.83\n",
            "Training 3570: Loss=1.45 Acc@1=57.5 Acc@5=85.83\n",
            "Training 3600: Loss=1.66 Acc@1=54.58 Acc@5=82.92\n",
            "Training 3630: Loss=1.56 Acc@1=57.08 Acc@5=86.67\n",
            "Training 3660: Loss=1.45 Acc@1=58.33 Acc@5=85.83\n",
            "Training 3690: Loss=1.43 Acc@1=56.67 Acc@5=89.17\n",
            "Training 3720: Loss=1.64 Acc@1=59.17 Acc@5=82.5\n",
            "Training 3750: Loss=1.72 Acc@1=52.5 Acc@5=82.08\n",
            "Training 3780: Loss=1.65 Acc@1=51.67 Acc@5=82.92\n",
            "Training 3810: Loss=1.55 Acc@1=57.92 Acc@5=87.08\n",
            "Training 3840: Loss=1.4 Acc@1=60.83 Acc@5=87.08\n",
            "Training 3870: Loss=1.62 Acc@1=58.75 Acc@5=82.08\n",
            "Training 3900: Loss=1.57 Acc@1=58.33 Acc@5=85.42\n",
            "Training 3930: Loss=1.51 Acc@1=55.0 Acc@5=87.08\n",
            "Training 3960: Loss=1.59 Acc@1=57.08 Acc@5=84.58\n",
            "Training 3990: Loss=1.56 Acc@1=62.5 Acc@5=84.58\n",
            "Training 4020: Loss=1.57 Acc@1=58.33 Acc@5=85.0\n",
            "Training 4050: Loss=1.73 Acc@1=51.25 Acc@5=81.67\n",
            "Training 4080: Loss=1.69 Acc@1=52.08 Acc@5=83.75\n",
            "Training 4110: Loss=1.45 Acc@1=58.33 Acc@5=86.25\n",
            "Training 4140: Loss=1.47 Acc@1=58.33 Acc@5=86.25\n",
            "Training 4170: Loss=1.48 Acc@1=61.25 Acc@5=87.08\n",
            "Training 4200: Loss=1.54 Acc@1=58.75 Acc@5=84.17\n",
            "Training 4230: Loss=1.55 Acc@1=59.17 Acc@5=84.17\n",
            "Training 4260: Loss=1.44 Acc@1=61.25 Acc@5=83.75\n",
            "Training 4290: Loss=1.46 Acc@1=61.67 Acc@5=86.25\n",
            "Training 4320: Loss=1.75 Acc@1=51.25 Acc@5=81.67\n",
            "Training 4350: Loss=1.7 Acc@1=50.42 Acc@5=85.0\n",
            "Training 4380: Loss=1.53 Acc@1=57.5 Acc@5=86.67\n",
            "Training 4410: Loss=1.45 Acc@1=58.75 Acc@5=84.58\n",
            "Training 4440: Loss=1.55 Acc@1=55.42 Acc@5=86.25\n",
            "Training 4470: Loss=1.58 Acc@1=55.0 Acc@5=84.17\n",
            "Training 4500: Loss=1.65 Acc@1=55.42 Acc@5=84.58\n",
            "Training 4530: Loss=1.61 Acc@1=55.0 Acc@5=85.42\n",
            "Training 4560: Loss=1.61 Acc@1=55.42 Acc@5=85.42\n",
            "Training 4590: Loss=1.73 Acc@1=55.0 Acc@5=80.42\n",
            "Training 4620: Loss=1.57 Acc@1=59.58 Acc@5=83.75\n",
            "Training 4650: Loss=1.61 Acc@1=55.42 Acc@5=81.67\n",
            "Training 4680: Loss=1.58 Acc@1=56.67 Acc@5=83.33\n",
            "Training 4710: Loss=1.71 Acc@1=50.42 Acc@5=82.92\n",
            "Training 4740: Loss=1.52 Acc@1=56.25 Acc@5=86.25\n",
            "Training 4770: Loss=1.37 Acc@1=61.67 Acc@5=89.17\n",
            "Training 4800: Loss=1.56 Acc@1=48.33 Acc@5=86.25\n",
            "Training 4830: Loss=1.64 Acc@1=53.33 Acc@5=82.5\n",
            "Training 4860: Loss=1.75 Acc@1=53.75 Acc@5=83.75\n",
            "Training 4890: Loss=1.46 Acc@1=58.75 Acc@5=85.83\n",
            "Training 4920: Loss=1.64 Acc@1=56.25 Acc@5=83.75\n",
            "Training 4950: Loss=1.66 Acc@1=56.67 Acc@5=84.17\n",
            "Training 4980: Loss=1.57 Acc@1=57.08 Acc@5=85.0\n",
            "Training 5010: Loss=1.62 Acc@1=55.83 Acc@5=82.92\n",
            "Training 5040: Loss=1.77 Acc@1=51.25 Acc@5=81.67\n",
            "Training 5070: Loss=1.64 Acc@1=52.92 Acc@5=84.58\n",
            "Training 5100: Loss=1.5 Acc@1=60.0 Acc@5=85.42\n",
            "Training 5130: Loss=1.45 Acc@1=61.67 Acc@5=86.67\n",
            "Training 5160: Loss=1.72 Acc@1=53.75 Acc@5=80.83\n",
            "Training 5190: Loss=1.69 Acc@1=51.25 Acc@5=83.75\n",
            "Training 5220: Loss=1.72 Acc@1=53.33 Acc@5=81.67\n",
            "Training 5250: Loss=1.51 Acc@1=59.17 Acc@5=84.17\n",
            "Training 5280: Loss=1.61 Acc@1=52.92 Acc@5=80.83\n",
            "Training 5310: Loss=1.42 Acc@1=59.17 Acc@5=88.33\n",
            "Training 5340: Loss=1.55 Acc@1=55.0 Acc@5=83.75\n",
            "Training 5370: Loss=1.48 Acc@1=60.83 Acc@5=84.58\n",
            "Training 5400: Loss=1.63 Acc@1=54.58 Acc@5=81.67\n",
            "Training 5430: Loss=1.56 Acc@1=57.5 Acc@5=85.0\n",
            "Training 5460: Loss=1.6 Acc@1=51.67 Acc@5=86.25\n",
            "Training 5490: Loss=1.71 Acc@1=51.25 Acc@5=81.67\n",
            "Training 5520: Loss=1.43 Acc@1=56.67 Acc@5=87.5\n",
            "Training 5550: Loss=1.52 Acc@1=57.92 Acc@5=82.5\n",
            "Training 5580: Loss=1.68 Acc@1=52.5 Acc@5=81.25\n",
            "Training 5610: Loss=1.71 Acc@1=54.17 Acc@5=80.42\n",
            "Training 5640: Loss=1.65 Acc@1=50.83 Acc@5=83.75\n",
            "Training 5670: Loss=1.63 Acc@1=56.67 Acc@5=81.67\n",
            "Training 5700: Loss=1.56 Acc@1=58.75 Acc@5=84.17\n",
            "Training 5730: Loss=1.81 Acc@1=53.33 Acc@5=80.0\n",
            "Training 5760: Loss=1.53 Acc@1=56.25 Acc@5=86.67\n",
            "Training 5790: Loss=1.5 Acc@1=57.08 Acc@5=90.0\n",
            "Training 5820: Loss=1.7 Acc@1=54.58 Acc@5=82.08\n",
            "Training 5850: Loss=1.68 Acc@1=51.67 Acc@5=83.75\n",
            "Training 5880: Loss=1.66 Acc@1=50.83 Acc@5=82.08\n",
            "Training 5910: Loss=1.48 Acc@1=66.67 Acc@5=84.17\n",
            "Training 5940: Loss=1.82 Acc@1=52.08 Acc@5=80.0\n",
            "Training 5970: Loss=1.45 Acc@1=53.33 Acc@5=88.33\n",
            "Training 6000: Loss=1.48 Acc@1=59.58 Acc@5=86.25\n",
            "Training 6030: Loss=1.6 Acc@1=52.08 Acc@5=86.67\n",
            "Training 6060: Loss=1.61 Acc@1=56.25 Acc@5=82.92\n",
            "Training 6090: Loss=1.62 Acc@1=57.08 Acc@5=82.5\n",
            "Training 6120: Loss=1.58 Acc@1=60.83 Acc@5=82.92\n",
            "Training 6150: Loss=1.35 Acc@1=62.08 Acc@5=90.42\n",
            "Training 6180: Loss=1.62 Acc@1=54.17 Acc@5=84.17\n",
            "Training 6210: Loss=1.67 Acc@1=52.5 Acc@5=85.42\n",
            "Training 6240: Loss=1.76 Acc@1=53.33 Acc@5=81.25\n",
            "Full imagenet train set: Acc@1=71.25 Acc@5=90.0\n",
            "Epoch: 19 ######################################################\n",
            "Training 30: Loss=1.5 Acc@1=57.08 Acc@5=85.83\n",
            "Training 60: Loss=1.47 Acc@1=59.17 Acc@5=85.83\n",
            "Training 90: Loss=1.22 Acc@1=66.25 Acc@5=91.25\n",
            "Training 120: Loss=1.48 Acc@1=57.08 Acc@5=86.25\n",
            "Training 150: Loss=1.27 Acc@1=66.67 Acc@5=88.33\n",
            "Training 180: Loss=1.23 Acc@1=65.83 Acc@5=90.83\n",
            "Training 210: Loss=1.43 Acc@1=62.5 Acc@5=85.0\n",
            "Training 240: Loss=1.43 Acc@1=60.83 Acc@5=87.08\n",
            "Training 270: Loss=1.28 Acc@1=63.33 Acc@5=90.42\n",
            "Training 300: Loss=1.46 Acc@1=59.58 Acc@5=85.83\n",
            "Training 330: Loss=1.42 Acc@1=58.75 Acc@5=85.83\n",
            "Training 360: Loss=1.39 Acc@1=59.58 Acc@5=87.08\n",
            "Training 390: Loss=1.35 Acc@1=58.33 Acc@5=87.08\n",
            "Training 420: Loss=1.31 Acc@1=61.67 Acc@5=89.58\n",
            "Training 450: Loss=1.36 Acc@1=65.42 Acc@5=86.67\n",
            "Training 480: Loss=1.6 Acc@1=54.58 Acc@5=83.75\n",
            "Training 510: Loss=1.31 Acc@1=62.92 Acc@5=89.58\n",
            "Training 540: Loss=1.38 Acc@1=58.75 Acc@5=87.08\n",
            "Training 570: Loss=1.54 Acc@1=57.92 Acc@5=86.25\n",
            "Training 600: Loss=1.43 Acc@1=57.92 Acc@5=85.42\n",
            "Training 630: Loss=1.46 Acc@1=58.75 Acc@5=89.58\n",
            "Training 660: Loss=1.46 Acc@1=62.92 Acc@5=85.83\n",
            "Training 690: Loss=1.39 Acc@1=60.0 Acc@5=88.33\n",
            "Training 720: Loss=1.48 Acc@1=55.42 Acc@5=87.92\n",
            "Training 750: Loss=1.48 Acc@1=57.08 Acc@5=87.92\n",
            "Training 780: Loss=1.38 Acc@1=61.25 Acc@5=85.83\n",
            "Training 810: Loss=1.34 Acc@1=63.33 Acc@5=90.42\n",
            "Training 840: Loss=1.36 Acc@1=64.58 Acc@5=87.92\n",
            "Training 870: Loss=1.47 Acc@1=57.08 Acc@5=86.67\n",
            "Training 900: Loss=1.52 Acc@1=58.33 Acc@5=83.75\n",
            "Training 930: Loss=1.46 Acc@1=57.08 Acc@5=85.42\n",
            "Training 960: Loss=1.57 Acc@1=54.17 Acc@5=87.92\n",
            "Training 990: Loss=1.33 Acc@1=60.42 Acc@5=88.33\n",
            "Training 1020: Loss=1.46 Acc@1=60.0 Acc@5=85.42\n",
            "Training 1050: Loss=1.5 Acc@1=58.33 Acc@5=85.0\n",
            "Training 1080: Loss=1.46 Acc@1=55.0 Acc@5=89.58\n",
            "Training 1110: Loss=1.42 Acc@1=55.83 Acc@5=89.58\n",
            "Training 1140: Loss=1.32 Acc@1=63.33 Acc@5=87.08\n",
            "Training 1170: Loss=1.35 Acc@1=61.25 Acc@5=85.42\n",
            "Training 1200: Loss=1.54 Acc@1=57.92 Acc@5=87.08\n",
            "Training 1230: Loss=1.31 Acc@1=63.33 Acc@5=89.17\n",
            "Training 1260: Loss=1.24 Acc@1=64.17 Acc@5=90.0\n",
            "Training 1290: Loss=1.51 Acc@1=57.08 Acc@5=86.25\n",
            "Training 1320: Loss=1.36 Acc@1=61.67 Acc@5=89.17\n",
            "Training 1350: Loss=1.58 Acc@1=54.17 Acc@5=85.42\n",
            "Training 1380: Loss=1.41 Acc@1=63.33 Acc@5=87.08\n",
            "Training 1410: Loss=1.38 Acc@1=59.17 Acc@5=87.5\n",
            "Training 1440: Loss=1.3 Acc@1=65.42 Acc@5=88.75\n",
            "Training 1470: Loss=1.32 Acc@1=61.25 Acc@5=87.5\n",
            "Training 1500: Loss=1.31 Acc@1=59.17 Acc@5=86.67\n",
            "Training 1530: Loss=1.4 Acc@1=62.08 Acc@5=87.92\n",
            "Training 1560: Loss=1.53 Acc@1=59.17 Acc@5=85.0\n",
            "Training 1590: Loss=1.27 Acc@1=60.42 Acc@5=90.42\n",
            "Training 1620: Loss=1.36 Acc@1=63.33 Acc@5=85.83\n",
            "Training 1650: Loss=1.51 Acc@1=56.25 Acc@5=87.08\n",
            "Training 1680: Loss=1.3 Acc@1=64.58 Acc@5=87.92\n",
            "Training 1710: Loss=1.43 Acc@1=56.25 Acc@5=90.42\n",
            "Training 1740: Loss=1.54 Acc@1=57.08 Acc@5=85.83\n",
            "Training 1770: Loss=1.43 Acc@1=63.75 Acc@5=88.33\n",
            "Training 1800: Loss=1.54 Acc@1=60.0 Acc@5=82.08\n",
            "Training 1830: Loss=1.6 Acc@1=51.25 Acc@5=84.17\n",
            "Training 1860: Loss=1.51 Acc@1=58.33 Acc@5=86.25\n",
            "Training 1890: Loss=1.54 Acc@1=56.25 Acc@5=85.0\n",
            "Training 1920: Loss=1.83 Acc@1=51.25 Acc@5=80.0\n",
            "Training 1950: Loss=1.36 Acc@1=61.25 Acc@5=85.83\n",
            "Training 1980: Loss=1.61 Acc@1=57.5 Acc@5=82.92\n",
            "Training 2010: Loss=1.48 Acc@1=57.08 Acc@5=85.42\n",
            "Training 2040: Loss=1.36 Acc@1=64.17 Acc@5=84.58\n",
            "Training 2070: Loss=1.35 Acc@1=62.5 Acc@5=86.67\n",
            "Training 2100: Loss=1.61 Acc@1=52.5 Acc@5=87.08\n",
            "Training 2130: Loss=1.43 Acc@1=59.58 Acc@5=86.67\n",
            "Training 2160: Loss=1.5 Acc@1=55.83 Acc@5=87.5\n",
            "Training 2190: Loss=1.5 Acc@1=52.92 Acc@5=88.75\n",
            "Training 2220: Loss=1.33 Acc@1=64.17 Acc@5=87.5\n",
            "Training 2250: Loss=1.36 Acc@1=62.5 Acc@5=88.33\n",
            "Training 2280: Loss=1.24 Acc@1=63.75 Acc@5=90.0\n",
            "Training 2310: Loss=1.49 Acc@1=58.33 Acc@5=87.08\n",
            "Training 2340: Loss=1.45 Acc@1=56.67 Acc@5=86.25\n",
            "Training 2370: Loss=1.62 Acc@1=55.83 Acc@5=81.67\n",
            "Training 2400: Loss=1.35 Acc@1=62.5 Acc@5=89.58\n",
            "Training 2430: Loss=1.36 Acc@1=62.92 Acc@5=88.75\n",
            "Training 2460: Loss=1.53 Acc@1=54.58 Acc@5=85.0\n",
            "Training 2490: Loss=1.4 Acc@1=57.5 Acc@5=88.75\n",
            "Training 2520: Loss=1.28 Acc@1=64.58 Acc@5=90.83\n",
            "Training 2550: Loss=1.47 Acc@1=55.83 Acc@5=87.92\n",
            "Training 2580: Loss=1.55 Acc@1=60.0 Acc@5=82.5\n",
            "Training 2610: Loss=1.5 Acc@1=57.08 Acc@5=86.25\n",
            "Training 2640: Loss=1.54 Acc@1=54.58 Acc@5=86.67\n",
            "Training 2670: Loss=1.55 Acc@1=57.92 Acc@5=85.0\n",
            "Training 2700: Loss=1.46 Acc@1=61.67 Acc@5=82.5\n",
            "Training 2730: Loss=1.35 Acc@1=62.08 Acc@5=90.0\n",
            "Training 2760: Loss=1.46 Acc@1=60.83 Acc@5=87.92\n",
            "Training 2790: Loss=1.7 Acc@1=52.5 Acc@5=83.33\n",
            "Training 2820: Loss=1.71 Acc@1=52.08 Acc@5=81.25\n",
            "Training 2850: Loss=1.45 Acc@1=59.17 Acc@5=88.33\n",
            "Training 2880: Loss=1.55 Acc@1=59.17 Acc@5=84.17\n",
            "Training 2910: Loss=1.58 Acc@1=55.0 Acc@5=81.67\n",
            "Training 2940: Loss=1.47 Acc@1=56.67 Acc@5=85.42\n",
            "Training 2970: Loss=1.45 Acc@1=59.17 Acc@5=87.08\n",
            "Training 3000: Loss=1.53 Acc@1=60.0 Acc@5=86.25\n",
            "Training 3030: Loss=1.41 Acc@1=58.33 Acc@5=88.33\n",
            "Training 3060: Loss=1.52 Acc@1=57.08 Acc@5=84.17\n",
            "Training 3090: Loss=1.6 Acc@1=53.33 Acc@5=82.5\n",
            "Training 3120: Loss=1.45 Acc@1=60.0 Acc@5=85.42\n",
            "Training 3150: Loss=1.59 Acc@1=57.5 Acc@5=85.42\n",
            "Training 3180: Loss=1.44 Acc@1=60.0 Acc@5=86.67\n",
            "Training 3210: Loss=1.48 Acc@1=58.33 Acc@5=86.25\n",
            "Training 3240: Loss=1.48 Acc@1=59.17 Acc@5=85.83\n",
            "Training 3270: Loss=1.45 Acc@1=56.25 Acc@5=87.92\n",
            "Training 3300: Loss=1.43 Acc@1=57.92 Acc@5=87.5\n",
            "Training 3330: Loss=1.4 Acc@1=62.92 Acc@5=85.42\n",
            "Training 3360: Loss=1.6 Acc@1=53.33 Acc@5=85.42\n",
            "Training 3390: Loss=1.49 Acc@1=57.08 Acc@5=86.25\n",
            "Training 3420: Loss=1.57 Acc@1=55.42 Acc@5=87.5\n",
            "Training 3450: Loss=1.36 Acc@1=57.92 Acc@5=88.33\n",
            "Training 3480: Loss=1.41 Acc@1=57.5 Acc@5=87.08\n",
            "Training 3510: Loss=1.46 Acc@1=58.33 Acc@5=86.67\n",
            "Training 3540: Loss=1.42 Acc@1=59.58 Acc@5=85.0\n",
            "Training 3570: Loss=1.42 Acc@1=60.42 Acc@5=85.83\n",
            "Training 3600: Loss=1.31 Acc@1=63.33 Acc@5=88.75\n",
            "Training 3630: Loss=1.34 Acc@1=65.83 Acc@5=86.67\n",
            "Training 3660: Loss=1.39 Acc@1=62.92 Acc@5=87.92\n",
            "Training 3690: Loss=1.53 Acc@1=55.83 Acc@5=85.42\n",
            "Training 3720: Loss=1.33 Acc@1=60.83 Acc@5=87.92\n",
            "Training 3750: Loss=1.41 Acc@1=60.0 Acc@5=86.67\n",
            "Training 3780: Loss=1.46 Acc@1=59.17 Acc@5=86.67\n",
            "Training 3810: Loss=1.43 Acc@1=60.42 Acc@5=88.33\n",
            "Training 3840: Loss=1.39 Acc@1=62.5 Acc@5=85.83\n",
            "Training 3870: Loss=1.57 Acc@1=55.83 Acc@5=84.17\n",
            "Training 3900: Loss=1.6 Acc@1=53.75 Acc@5=85.42\n",
            "Training 3930: Loss=1.44 Acc@1=59.58 Acc@5=86.67\n",
            "Training 3960: Loss=1.45 Acc@1=58.75 Acc@5=87.08\n",
            "Training 3990: Loss=1.63 Acc@1=53.75 Acc@5=87.5\n",
            "Training 4020: Loss=1.41 Acc@1=59.17 Acc@5=87.5\n",
            "Training 4050: Loss=1.34 Acc@1=60.83 Acc@5=90.0\n",
            "Training 4080: Loss=1.6 Acc@1=55.0 Acc@5=85.42\n",
            "Training 4110: Loss=1.71 Acc@1=53.75 Acc@5=81.25\n",
            "Training 4140: Loss=1.37 Acc@1=59.17 Acc@5=89.58\n",
            "Training 4170: Loss=1.55 Acc@1=55.83 Acc@5=87.5\n",
            "Training 4200: Loss=1.56 Acc@1=55.83 Acc@5=85.83\n",
            "Training 4230: Loss=1.56 Acc@1=55.83 Acc@5=87.08\n",
            "Training 4260: Loss=1.51 Acc@1=55.83 Acc@5=84.17\n",
            "Training 4290: Loss=1.32 Acc@1=63.33 Acc@5=87.92\n",
            "Training 4320: Loss=1.44 Acc@1=60.42 Acc@5=85.83\n",
            "Training 4350: Loss=1.58 Acc@1=54.17 Acc@5=87.08\n",
            "Training 4380: Loss=1.47 Acc@1=57.92 Acc@5=86.25\n",
            "Training 4410: Loss=1.54 Acc@1=54.58 Acc@5=82.92\n",
            "Training 4440: Loss=1.52 Acc@1=56.67 Acc@5=86.25\n",
            "Training 4470: Loss=1.37 Acc@1=58.75 Acc@5=90.42\n",
            "Training 4500: Loss=1.49 Acc@1=59.58 Acc@5=85.42\n",
            "Training 4530: Loss=1.51 Acc@1=58.75 Acc@5=84.58\n",
            "Training 4560: Loss=1.48 Acc@1=59.58 Acc@5=85.83\n",
            "Training 4590: Loss=1.45 Acc@1=57.92 Acc@5=85.83\n",
            "Training 4620: Loss=1.53 Acc@1=55.83 Acc@5=85.0\n",
            "Training 4650: Loss=1.58 Acc@1=53.75 Acc@5=85.0\n",
            "Training 4680: Loss=1.59 Acc@1=55.83 Acc@5=85.42\n",
            "Training 4710: Loss=1.53 Acc@1=57.92 Acc@5=86.25\n",
            "Training 4740: Loss=1.53 Acc@1=57.5 Acc@5=85.0\n",
            "Training 4770: Loss=1.63 Acc@1=54.58 Acc@5=82.5\n",
            "Training 4800: Loss=1.55 Acc@1=57.08 Acc@5=84.17\n",
            "Training 4830: Loss=1.6 Acc@1=54.17 Acc@5=87.5\n",
            "Training 4860: Loss=1.73 Acc@1=51.25 Acc@5=83.75\n",
            "Training 4890: Loss=1.59 Acc@1=52.92 Acc@5=87.5\n",
            "Training 4920: Loss=1.6 Acc@1=59.58 Acc@5=82.5\n",
            "Training 4950: Loss=1.59 Acc@1=55.0 Acc@5=84.58\n",
            "Training 4980: Loss=1.52 Acc@1=58.75 Acc@5=85.42\n",
            "Training 5010: Loss=1.23 Acc@1=62.92 Acc@5=87.92\n",
            "Training 5040: Loss=1.48 Acc@1=59.58 Acc@5=85.83\n",
            "Training 5070: Loss=1.47 Acc@1=62.08 Acc@5=85.83\n",
            "Training 5100: Loss=1.46 Acc@1=59.17 Acc@5=89.17\n",
            "Training 5130: Loss=1.47 Acc@1=56.67 Acc@5=88.75\n",
            "Training 5160: Loss=1.39 Acc@1=63.75 Acc@5=86.67\n",
            "Training 5190: Loss=1.51 Acc@1=57.5 Acc@5=84.17\n",
            "Training 5220: Loss=1.48 Acc@1=58.33 Acc@5=87.08\n",
            "Training 5250: Loss=1.65 Acc@1=51.67 Acc@5=84.58\n",
            "Training 5280: Loss=1.63 Acc@1=54.58 Acc@5=84.17\n",
            "Training 5310: Loss=1.5 Acc@1=58.33 Acc@5=86.25\n",
            "Training 5340: Loss=1.4 Acc@1=60.83 Acc@5=87.5\n",
            "Training 5370: Loss=1.37 Acc@1=59.58 Acc@5=90.0\n",
            "Training 5400: Loss=1.58 Acc@1=53.75 Acc@5=86.67\n",
            "Training 5430: Loss=1.53 Acc@1=59.17 Acc@5=83.33\n",
            "Training 5460: Loss=1.5 Acc@1=55.83 Acc@5=87.92\n",
            "Training 5490: Loss=1.52 Acc@1=57.5 Acc@5=85.42\n",
            "Training 5520: Loss=1.6 Acc@1=53.33 Acc@5=83.33\n",
            "Training 5550: Loss=1.53 Acc@1=56.25 Acc@5=84.17\n",
            "Training 5580: Loss=1.56 Acc@1=57.92 Acc@5=85.0\n",
            "Training 5610: Loss=1.58 Acc@1=52.92 Acc@5=83.75\n",
            "Training 5640: Loss=1.46 Acc@1=58.75 Acc@5=84.17\n",
            "Training 5670: Loss=1.62 Acc@1=55.0 Acc@5=84.58\n",
            "Training 5700: Loss=1.47 Acc@1=62.5 Acc@5=85.83\n",
            "Training 5730: Loss=1.52 Acc@1=54.17 Acc@5=85.0\n",
            "Training 5760: Loss=1.45 Acc@1=63.33 Acc@5=85.83\n",
            "Training 5790: Loss=1.53 Acc@1=60.0 Acc@5=85.0\n",
            "Training 5820: Loss=1.28 Acc@1=64.17 Acc@5=88.75\n",
            "Training 5850: Loss=1.53 Acc@1=56.67 Acc@5=83.75\n",
            "Training 5880: Loss=1.54 Acc@1=55.42 Acc@5=83.75\n",
            "Training 5910: Loss=1.42 Acc@1=62.5 Acc@5=85.42\n",
            "Training 5940: Loss=1.48 Acc@1=56.25 Acc@5=85.42\n",
            "Training 5970: Loss=1.43 Acc@1=60.83 Acc@5=87.92\n",
            "Training 6000: Loss=1.45 Acc@1=57.5 Acc@5=86.25\n",
            "Training 6030: Loss=1.53 Acc@1=56.25 Acc@5=87.5\n",
            "Training 6060: Loss=1.53 Acc@1=57.5 Acc@5=82.5\n",
            "Training 6090: Loss=1.88 Acc@1=50.0 Acc@5=76.67\n",
            "Training 6120: Loss=1.51 Acc@1=60.42 Acc@5=84.17\n",
            "Training 6150: Loss=1.62 Acc@1=53.75 Acc@5=83.33\n",
            "Training 6180: Loss=1.56 Acc@1=54.58 Acc@5=86.25\n",
            "Training 6210: Loss=1.5 Acc@1=59.17 Acc@5=88.75\n",
            "Training 6240: Loss=1.45 Acc@1=60.0 Acc@5=88.75\n",
            "Full imagenet train set: Acc@1=72.5 Acc@5=97.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufRzfyF2ai2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'resnet18.pth')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OprlOfE_eDkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "train, test = get_loaders('imagenet_1k')\n",
        "st = time.time()\n",
        "top1, top5 = evaluate(model, criterion, test, 'cpu')\n",
        "print(f'Finall accuracy: {top1} {top5} in {time.time() - st} sec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb-pnnSFendX",
        "colab_type": "text"
      },
      "source": [
        "### Dynamic quantization\n",
        "Currently supported only for nn.Linear, nn.LSTM modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo2S9LTAeexg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model_size = print_size_of_model(model)\n",
        "print(base_model_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HitthGIeE2P-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.quantization\n",
        "\n",
        "base = load_model('resnet18.pth').eval().to('cpu')\n",
        "# we will se DynamicQuantizedLinear module in the end instead of Linear\n",
        "dyn_quantized_model = torch.quantization.quantize_dynamic(base, {nn.Linear}, dtype=torch.qint8)\n",
        "print(list(dyn_quantized_model.modules())[-3:])\n",
        "\n",
        "base_model_size = print_size_of_model(dyn_quantized_model)\n",
        "print(base_model_size)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train, test = get_loaders('imagenet_1k')\n",
        "st = time.time()\n",
        "top1, top5 = evaluate(dyn_quantized_model, criterion, test, 'cpu')\n",
        "print(f'Finall accuracy: {top1} {top5} in {time.time() - st} sec')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_yB0RlFikoc",
        "colab_type": "text"
      },
      "source": [
        "### Static quantization\n",
        "\n",
        "Quantization is based on Observer class, which main purpose is to find best parameters to fit float32 into int8. So to give some info about weights and biases distribution we need to inference some amount of data through the model. We do this after the `prepare` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nktMZjteiz_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "stat_quant = load_model('resnet18.pth').eval().to('cpu')\n",
        "\n",
        "# Fuse Conv, bn and relu\n",
        "stat_quant.fuse_model()\n",
        "# we will not see Batch Norm instead will see replaced it with Identity\n",
        "print(stat_quant)\n",
        "\n",
        "stat_quant.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "print(stat_quant.qconfig)\n",
        "\n",
        "# this aware quantization engine thet we are going to inference few inputs \n",
        "# so Observer can get enough data for building optimiation maps\n",
        "torch.quantization.prepare(stat_quant, inplace=True)\n",
        "train, test = get_loaders('imagenet_1k')\n",
        "evaluate(stat_quant, criterion, test, 'cpu')\n",
        "# now we converting our model to int8\n",
        "torch.quantization.convert(stat_quant, inplace=True)\n",
        "\n",
        "base_model_size = print_size_of_model(stat_quant)\n",
        "print(base_model_size)\n",
        "\n",
        "st = time.time()\n",
        "top1, top5 = evaluate(stat_quant, criterion, test, 'cpu')\n",
        "print(f'Finall accuracy: {top1} {top5} in {time.time() - st} sec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGS2AkbTj6Cz",
        "colab_type": "text"
      },
      "source": [
        "So we have small accuracy drop, but we lower size of our model in 4 times and inference times droped in twice. Not bad for few lines of code :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QGFjBExkSji",
        "colab_type": "text"
      },
      "source": [
        "## Quantization-aware training\n",
        "So this works preatty simple. QAT converts all weights and activations to *fake quantized*, so during forward and backward passes float values are rounded to mimic int8 values. Thus during training we optimize values of weights and activations so they better fit to the int8 values distribution. And after training we just fix that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THZlaer9ji__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "qat_model = load_model('resnet18.pth')\n",
        "optimizer = torch.optim.SGD(qat_model.parameters(), momentum=0.9, lr=5e-4)\n",
        "qat_model.fuse_model()\n",
        "\n",
        "qat_model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
        "torch.quantization.prepare_qat(qat_model, inplace=True)\n",
        "\n",
        "train, test = get_loaders('imagenet_1k')\n",
        "# Train and check accuracy after each epoch\n",
        "for epoch in range(5):\n",
        "    train_one_epoch(qat_model, criterion, optimizer, train, 'cuda')\n",
        "    if epoch > 3:\n",
        "        # Freeze quantizer parameters\n",
        "        qat_model.apply(torch.quantization.disable_observer)\n",
        "    if epoch > 2:\n",
        "        # Freeze batch norm mean and variance estimates\n",
        "        qat_model.apply(torch.nn.intrinsic.qat.freeze_bn_stats)\n",
        "\n",
        "    # Check the accuracy after each epoch\n",
        "    quantized_model = torch.quantization.convert(qat_model.eval().to('cpu'), inplace=False)\n",
        "    quantized_model.eval()\n",
        "    top1, top5 = evaluate(quantized_model, criterion, test, 'cpu')\n",
        "    print(f'Epoch {epoch}: {top1} {top5}')\n",
        "\n",
        "base_model_size = print_size_of_model(stat_quant)\n",
        "print(base_model_size)\n",
        "\n",
        "st = time.time()\n",
        "top1, top5 = evaluate(stat_quant, criterion, test, 'cpu')\n",
        "print(f'Finall accuracy: {top1} {top5} in {time.time() - st} sec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG4N9XNe6QPE",
        "colab_type": "text"
      },
      "source": [
        "## Nvidia APEX\n",
        "\n",
        "This lib is a quite cool stuff to get additional boost just with few lines, or more wih more advanced techniques.\n",
        "What it do is same Quantized Aware Training. It give you ability to use mixed float precision with float32/float16, or fully float16 precision.\n",
        "\n",
        "This is usefull because many edge device have much better float16 support than float32, also new Nvidia cards have preatty good optimization on float16. Here is example of Nvidia T4 card:\n",
        "\n",
        "<img src='https://github.com/learnml-today/object-detection-with-pytorch/blob/master/imgs/nvidiat4.png?raw=true' />\n",
        "\n",
        "As you see difference betwen float32 and float16 is more than 8x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJfyA3TD7ipH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    from apex import amp\n",
        "except ImportError:\n",
        "    raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to run this example.\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-IhJtcbK1dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_one_epoch_with_apex(model, criterion, optimizer, data_loader, device, log_steps=30):\n",
        "    model.train().to(device)\n",
        "    top1 = MeanMetric('Acc@1')\n",
        "    top5 = MeanMetric('Acc@5')\n",
        "    avgloss = MeanMetric('Loss')\n",
        "\n",
        "    cnt = 0\n",
        "    for image, target in data_loader:\n",
        "        start_time = time.time()\n",
        "        cnt += 1\n",
        "        \n",
        "        image, target = image.to(device), target.to(device)\n",
        "        output = model(image)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        with amp.scale_loss(loss, optimizer) as scaled_loss:           \n",
        "            scaled_loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0].detach().cpu().item())\n",
        "        top5.update(acc5[0].detach().cpu().item())\n",
        "        avgloss.update(loss.detach().cpu().item())\n",
        "\n",
        "        if cnt % log_steps == 0 and cnt:\n",
        "            print(f'Training {cnt}: {avgloss} {top1} {top5}')\n",
        "            \n",
        "            avgloss.clear()\n",
        "            top1.clear()\n",
        "            top5.clear()\n",
        "\n",
        "                \n",
        "    top1, top5 = evaluate(model, criterion, data_loader, device)\n",
        "    print(f'Full imagenet train set: {top1} {top5}')\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjfXUEYd6ZfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_level = 'O1' # mixed float32 and float16 precision\n",
        "model = resnet18(pretrained=False, num_classes=100).to('cuda')\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=5e-4)\n",
        "# Loss scaling here can be used to preserve small gradient values. if not set used dynamic\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
        "\n",
        "st = time.time()\n",
        "for i in range(1):\n",
        "    print(f'Epoch: {i} ######################################################')\n",
        "    model = train_one_epoch_with_apex(model, criterion, optimizer, train, device='cuda')\n",
        "print('Total time:', time.time()-st)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWCSId4t8Op7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "train, test = get_loaders('imagenet_1k')\n",
        "st = time.time()\n",
        "top1, top5 = evaluate(model, criterion, test, 'cuda')\n",
        "print(f'Finall accuracy: {top1} {top5} in {time.time() - st} sec')\n",
        "\n",
        "base_model_size = print_size_of_model(model)\n",
        "print(base_model_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buYIkeSIoz8r",
        "colab_type": "text"
      },
      "source": [
        "So as we see size not changes much, but the inference speed becomes faster."
      ]
    }
  ]
}